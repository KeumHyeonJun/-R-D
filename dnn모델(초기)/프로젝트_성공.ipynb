{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"프로젝트_성공.ipynb","provenance":[],"collapsed_sections":["BLUwVO1T_6WZ","fufnbPq2_0ZF"],"mount_file_id":"1Auc4V_yRaE6Q1vhLvtWeRFBu3iOxoruZ","authorship_tag":"ABX9TyOIS6sM4gc6ZIgQq51mvbzN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"96Gxoli3C7sy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634282057053,"user_tz":-540,"elapsed":58465,"user":{"displayName":"현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06235385304799063880"}},"outputId":"d5afaa60-9293-4508-db97-81bbf8188dc0"},"source":["from google.colab import drive\n","drive.mount('/gdrive',force_remount=True)"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n"]}]},{"cell_type":"markdown","metadata":{"id":"dcqiw_6Y20Zc"},"source":["# 라이브러리 import"]},{"cell_type":"code","metadata":{"id":"DidIAB0VihkO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634282066558,"user_tz":-540,"elapsed":9514,"user":{"displayName":"현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06235385304799063880"}},"outputId":"fd61fd1b-c2aa-45cf-d250-20f306d05a01"},"source":["!pip install pymysql\n","!pip install -q sklearn\n","!pip install tensorflow_addons \n","!pip install pyyaml h5py  # HDF5 포맷으로 모델을 저장하기 위해서 필요합니다\n"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pymysql in /usr/local/lib/python3.7/dist-packages (1.0.2)\n","Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.7/dist-packages (0.14.0)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (3.13)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n","Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py) (1.19.5)\n"]}]},{"cell_type":"code","metadata":{"id":"-YL5Mu3VHVDu","executionInfo":{"status":"ok","timestamp":1634282066559,"user_tz":-540,"elapsed":11,"user":{"displayName":"현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06235385304799063880"}}},"source":["!mkdir -p saved_model"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"oMsLJe9EimpR","executionInfo":{"status":"ok","timestamp":1634282066560,"user_tz":-540,"elapsed":9,"user":{"displayName":"현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06235385304799063880"}}},"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow import feature_column\n","from tensorflow.keras import layers\n","import tensorflow_addons as tfa\n","\n","\n","import os\n","import tempfile\n","\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","\n","import sklearn\n","from sklearn.metrics import confusion_matrix\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"pNyta2n5ivgL","executionInfo":{"status":"ok","timestamp":1634282066561,"user_tz":-540,"elapsed":9,"user":{"displayName":"현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06235385304799063880"}}},"source":["import pymysql\n"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"34UAFJ6bxG81"},"source":["# 데이터 전처리"]},{"cell_type":"code","metadata":{"id":"Jf4FgLo2inl_","colab":{"base_uri":"https://localhost:8080/","height":438},"executionInfo":{"status":"ok","timestamp":1634282085838,"user_tz":-540,"elapsed":19284,"user":{"displayName":"현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06235385304799063880"}},"outputId":"b12862c8-bd79-4157-9bc5-c7779f7d07e0"},"source":["conn = pymysql.connect(\n","    user = 'orlab',\n","    passwd = 'orlabghkdlxld123!',\n","    host = 'orlab.cl9jlcc8q0pr.ap-northeast-2.rds.amazonaws.com',\n","    db = 'Dataset_final',\n","    charset = 'utf8'\n",")\n","curs = conn.cursor(pymysql.cursors.DictCursor)\n","curs1 = conn.cursor(pymysql.cursors.DictCursor)\n","\n","curs.execute(\"select * from Dataset_4_2016\")\n","\n","df = curs.fetchall()\n","df = pd.DataFrame(df)\n","df"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>Project_ID</th>\n","      <th>Year</th>\n","      <th>N_of_SCI</th>\n","      <th>N_of_Paper</th>\n","      <th>N_Patent_App</th>\n","      <th>N_Patent_Reg</th>\n","      <th>N_of_Korean_Patent</th>\n","      <th>N_of_Inter_Patent</th>\n","      <th>N_of_Patent</th>\n","      <th>Multi_Year</th>\n","      <th>RnD_Org</th>\n","      <th>Region</th>\n","      <th>STP_Code_11</th>\n","      <th>STP_Code_1_Weight</th>\n","      <th>STP_Code_21</th>\n","      <th>STP_Code_2_Weight</th>\n","      <th>Application_Area_1</th>\n","      <th>Application_Area_1_Weight</th>\n","      <th>Application_Area_2</th>\n","      <th>Application_Area_2_Weight</th>\n","      <th>Application_Area_3</th>\n","      <th>Application_Area_3_Weight</th>\n","      <th>Green_Tech</th>\n","      <th>SixT_2</th>\n","      <th>Econ_Social</th>\n","      <th>National_Strategy_2</th>\n","      <th>RnD_Stage</th>\n","      <th>Cowork_Cor</th>\n","      <th>Cowork_Uni</th>\n","      <th>Cowork_Inst</th>\n","      <th>Cowork_Abroad</th>\n","      <th>Cowork_etc</th>\n","      <th>Log_RnD_Fund</th>\n","      <th>Log_Duration</th>\n","      <th>Comm_Success</th>\n","      <th>Comm_Success_1</th>\n","      <th>Comm_Success_2</th>\n","      <th>Comm_Success_Code1_4</th>\n","      <th>Comm_Success_Code2_5</th>\n","      <th>Comm_Success_Code3_6</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1055000474</td>\n","      <td>2013.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>OC03</td>\n","      <td>100.0</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>X99</td>\n","      <td>100.0</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>999</td>\n","      <td>70000</td>\n","      <td>13</td>\n","      <td>60000</td>\n","      <td>4</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>21.365120</td>\n","      <td>5.897157</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1055000475</td>\n","      <td>2013.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>OC03</td>\n","      <td>100.0</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>X99</td>\n","      <td>100.0</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>999</td>\n","      <td>70000</td>\n","      <td>13</td>\n","      <td>60000</td>\n","      <td>4</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>19.568083</td>\n","      <td>5.897157</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>1055000476</td>\n","      <td>2014.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>OC03</td>\n","      <td>100.0</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>X99</td>\n","      <td>100.0</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>999</td>\n","      <td>70000</td>\n","      <td>13</td>\n","      <td>60000</td>\n","      <td>4</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>21.365120</td>\n","      <td>5.897157</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>1055000477</td>\n","      <td>2014.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>SB12</td>\n","      <td>100.0</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>X99</td>\n","      <td>100.0</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>999</td>\n","      <td>70000</td>\n","      <td>13</td>\n","      <td>60000</td>\n","      <td>4</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>19.673444</td>\n","      <td>5.808145</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>1055000478</td>\n","      <td>2014.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>19</td>\n","      <td>ZZ</td>\n","      <td>0.0</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>X99</td>\n","      <td>100.0</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>999</td>\n","      <td>70000</td>\n","      <td>13</td>\n","      <td>60000</td>\n","      <td>4</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>17.504390</td>\n","      <td>4.804029</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>192874</th>\n","      <td>192874</td>\n","      <td>9991006121</td>\n","      <td>2016.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>8</td>\n","      <td>LC03</td>\n","      <td>50.0</td>\n","      <td>LC03</td>\n","      <td>30.0</td>\n","      <td>X01</td>\n","      <td>50.0</td>\n","      <td>X99</td>\n","      <td>30.0</td>\n","      <td>X02</td>\n","      <td>20.0</td>\n","      <td>999</td>\n","      <td>20200</td>\n","      <td>11</td>\n","      <td>40100</td>\n","      <td>2</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>20.723266</td>\n","      <td>6.302621</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>192875</th>\n","      <td>192875</td>\n","      <td>9991006122</td>\n","      <td>2016.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>8</td>\n","      <td>1</td>\n","      <td>LC03</td>\n","      <td>100.0</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>X02</td>\n","      <td>100.0</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>999</td>\n","      <td>20200</td>\n","      <td>4</td>\n","      <td>60000</td>\n","      <td>3</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>21.920324</td>\n","      <td>6.302621</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>192876</th>\n","      <td>192876</td>\n","      <td>9991006124</td>\n","      <td>2016.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>8</td>\n","      <td>EB02</td>\n","      <td>80.0</td>\n","      <td>EA03</td>\n","      <td>20.0</td>\n","      <td>Y08</td>\n","      <td>60.0</td>\n","      <td>Y09</td>\n","      <td>40.0</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>999</td>\n","      <td>30200</td>\n","      <td>7</td>\n","      <td>10500</td>\n","      <td>3</td>\n","      <td>Y</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>20.482467</td>\n","      <td>6.998511</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>192877</th>\n","      <td>192877</td>\n","      <td>9991006125</td>\n","      <td>2016.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>8</td>\n","      <td>ED10</td>\n","      <td>100.0</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>Y05</td>\n","      <td>100.0</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>999</td>\n","      <td>30200</td>\n","      <td>7</td>\n","      <td>10500</td>\n","      <td>3</td>\n","      <td>Y</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>20.430236</td>\n","      <td>6.998511</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>192878</th>\n","      <td>192878</td>\n","      <td>9991006126</td>\n","      <td>2016.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>8</td>\n","      <td>NC09</td>\n","      <td>50.0</td>\n","      <td>NC10</td>\n","      <td>30.0</td>\n","      <td>Y13</td>\n","      <td>50.0</td>\n","      <td>Y05</td>\n","      <td>50.0</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>424</td>\n","      <td>50100</td>\n","      <td>7</td>\n","      <td>30200</td>\n","      <td>4</td>\n","      <td>Y</td>\n","      <td>Y</td>\n","      <td>Y</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>20.584004</td>\n","      <td>6.998511</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>192879 rows × 41 columns</p>\n","</div>"],"text/plain":["         index  Project_ID  ...  Comm_Success_Code2_5  Comm_Success_Code3_6\n","0            0  1055000474  ...                   0.0                   0.0\n","1            1  1055000475  ...                   0.0                   0.0\n","2            2  1055000476  ...                   0.0                   0.0\n","3            3  1055000477  ...                   0.0                   0.0\n","4            4  1055000478  ...                   0.0                   0.0\n","...        ...         ...  ...                   ...                   ...\n","192874  192874  9991006121  ...                   0.0                   0.0\n","192875  192875  9991006122  ...                   0.0                   0.0\n","192876  192876  9991006124  ...                   0.0                   0.0\n","192877  192877  9991006125  ...                   1.0                   0.0\n","192878  192878  9991006126  ...                   0.0                   0.0\n","\n","[192879 rows x 41 columns]"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"_dK1T2_BIZ9e","executionInfo":{"status":"ok","timestamp":1634282086283,"user_tz":-540,"elapsed":489,"user":{"displayName":"현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06235385304799063880"}}},"source":["df.drop(['index','Project_ID'],axis = 1, inplace = True)"],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BLUwVO1T_6WZ"},"source":["# feature columns 생성"]},{"cell_type":"code","metadata":{"id":"Av4KNrTh2-yf","executionInfo":{"status":"ok","timestamp":1634282087314,"user_tz":-540,"elapsed":1033,"user":{"displayName":"현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06235385304799063880"}}},"source":["\n","feature_columns = []\n","\n","for header in ['Log_RnD_Fund','Log_Duration','N_of_SCI','N_of_Paper','N_Patent_App','N_Patent_Reg','N_of_Korean_Patent','N_of_Inter_Patent',\n","               'N_of_Patent','STP_Code_1_Weight','STP_Code_2_Weight','Application_Area_1_Weight','Application_Area_2_Weight','Application_Area_3_Weight']:\n","    feature_columns.append(feature_column.numeric_column(header, dtype=tf.dtypes.float64, ))\n","\n","# 범주형 열(Categorical column)은 특정 문자열을 수치형으로 매핑하여 전달\n","\n","#Year\n","df[\"Year\"] = df[\"Year\"].apply(str)\n","Year = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'Year', df['Year'].unique() )\n","Year_hot = tf.feature_column.indicator_column(Year)\n","feature_columns.append(Year_hot)\n","\n","\n","#Multi_Year\n","df[\"Multi_Year\"] = df[\"Multi_Year\"].apply(str)\n","Multi_Year = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'Multi_Year', df['Multi_Year'].unique() )\n","Multi_Year_one_hot = tf.feature_column.indicator_column(Multi_Year)\n","feature_columns.append(Multi_Year_one_hot)\n","\n","\n","#RnD_Org\n","df[\"RnD_Org\"] = df[\"RnD_Org\"].apply(str)\n","RnD_Org = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'RnD_Org', df['RnD_Org'].unique() )\n","RnD_Org_one_hot = tf.feature_column.indicator_column(RnD_Org)\n","feature_columns.append(RnD_Org_one_hot)\n","\n","#Region\n","df[\"Region\"] = df[\"Region\"].apply(str)\n","\n","Region = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'Region', df['Region'].unique() )\n","Region_one_hot = tf.feature_column.indicator_column(Region)\n","feature_columns.append(Region_one_hot)\n","\n","#STP_Code_11\n","df[\"STP_Code_11\"] = df[\"STP_Code_11\"].apply(str)\n","\n","STP_Code_11 = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'STP_Code_11', df['STP_Code_11'].unique() )\n","STP_Code_11_one_hot = tf.feature_column.indicator_column(STP_Code_11)\n","feature_columns.append(STP_Code_11_one_hot)\n","\n","\n","#STP_Code_21\n","df[\"STP_Code_21\"] = df[\"STP_Code_21\"].apply(str)\n","\n","STP_Code_21 = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'STP_Code_21', df['STP_Code_21'].unique() )\n","STP_Code_21_one_hot = tf.feature_column.indicator_column(STP_Code_21)\n","feature_columns.append(STP_Code_21_one_hot)\n","\n","\n","\n","#Application_Area_1\n","df[\"Application_Area_1\"] = df[\"Application_Area_1\"].apply(str)\n","\n","Application_Area_1 = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'Application_Area_1', df['Application_Area_1'].unique() )\n","Application_Area_1_one_hot = tf.feature_column.indicator_column(Application_Area_1)\n","feature_columns.append(Application_Area_1_one_hot)\n","\n","\n","\n","#Application_Area_2\n","df[\"Application_Area_2\"] = df[\"Application_Area_2\"].apply(str)\n","\n","Application_Area_2 = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'Application_Area_2', df['Application_Area_2'].unique() )\n","Application_Area_2_one_hot = tf.feature_column.indicator_column(Application_Area_2)\n","feature_columns.append(Application_Area_2_one_hot)\n","\n","#Application_Area_3\n","df[\"Application_Area_3\"] = df[\"Application_Area_3\"].apply(str)\n","\n","Application_Area_3 = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'Application_Area_3', df['Application_Area_3'].unique() )\n","Application_Area_3_one_hot = tf.feature_column.indicator_column(Application_Area_3)\n","feature_columns.append(Application_Area_3_one_hot)\n","\n","\n","\n","#Green_Tech\n","df[\"Green_Tech\"] = df[\"Green_Tech\"].apply(str)\n","\n","Green_Tech = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'Green_Tech', df['Green_Tech'].unique() )\n","Green_Tech_one_hot = tf.feature_column.indicator_column(Green_Tech)\n","feature_columns.append(Green_Tech_one_hot)\n","\n","\n","\n","#SixT_2\n","df[\"SixT_2\"] = df[\"SixT_2\"].apply(str)\n","SixT_2 = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'SixT_2', df['SixT_2'].unique() )\n","SixT_2_one_hot = tf.feature_column.indicator_column(SixT_2)\n","feature_columns.append(SixT_2_one_hot)\n","\n","\n","#Econ_Social\n","df[\"Econ_Social\"] = df[\"Econ_Social\"].apply(str)\n","Econ_Social = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'Econ_Social', df['Econ_Social'].unique() )\n","Econ_Social_one_hot = tf.feature_column.indicator_column(Econ_Social)\n","feature_columns.append(Econ_Social_one_hot)\n","\n","#National_Strategy_2\n","df[\"National_Strategy_2\"] = df[\"National_Strategy_2\"].apply(str)\n","National_Strategy_2 = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'National_Strategy_2', df['National_Strategy_2'].unique() )\n","National_Strategy_2_one_hot = tf.feature_column.indicator_column(National_Strategy_2)\n","feature_columns.append(National_Strategy_2_one_hot)\n","\n","#RnD_Stage\n","df[\"RnD_Stage\"] = df[\"RnD_Stage\"].apply(str)\n","RnD_Stage = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'RnD_Stage', df['RnD_Stage'].unique() )\n","RnD_Stage_one_hot = tf.feature_column.indicator_column(RnD_Stage)\n","feature_columns.append(RnD_Stage_one_hot)\n","\n","#Cowork_Cor\n","df[\"Cowork_Cor\"] = df[\"Cowork_Cor\"].apply(str)\n","Cowork_Cor = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'Cowork_Cor', df['Cowork_Cor'].unique() )\n","Cowork_Cor_one_hot = tf.feature_column.indicator_column(Cowork_Cor)\n","feature_columns.append(Cowork_Cor_one_hot)\n","\n","#Cowork_Uni\n","df[\"Cowork_Uni\"] = df[\"Cowork_Uni\"].apply(str)\n","Cowork_Uni = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'Cowork_Uni', df['Cowork_Uni'].unique() )\n","Cowork_Uni_one_hot = tf.feature_column.indicator_column(Cowork_Uni)\n","feature_columns.append(Cowork_Uni_one_hot)\n","\n","#Cowork_Inst\n","df[\"Cowork_Inst\"] = df[\"Cowork_Inst\"].apply(str)\n","Cowork_Inst = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'Cowork_Inst', df['Cowork_Inst'].unique() )\n","Cowork_Inst_one_hot = tf.feature_column.indicator_column(Cowork_Inst)\n","feature_columns.append(Cowork_Inst_one_hot)\n","\n","#Cowork_Abroad\n","df[\"Cowork_Abroad\"] = df[\"Cowork_Abroad\"].apply(str)\n","Cowork_Abroad = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'Cowork_Abroad', df['Cowork_Abroad'].unique() )\n","Cowork_Abroad_one_hot = tf.feature_column.indicator_column(Cowork_Abroad)\n","feature_columns.append(Cowork_Abroad_one_hot)\n","\n","#Cowork_etc\n","df[\"Cowork_etc\"] = df[\"Cowork_etc\"].apply(str)\n","Cowork_etc = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'Cowork_etc', df['Cowork_etc'].unique() )\n","Cowork_etc_one_hot = tf.feature_column.indicator_column(Cowork_etc)\n","feature_columns.append(Cowork_etc_one_hot)\n","\n","\n"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"YeFTa1NA6yVD","executionInfo":{"status":"ok","timestamp":1634282087315,"user_tz":-540,"elapsed":11,"user":{"displayName":"현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06235385304799063880"}}},"source":["feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HaWHIcma6zry","executionInfo":{"status":"ok","timestamp":1634282087315,"user_tz":-540,"elapsed":10,"user":{"displayName":"현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06235385304799063880"}},"outputId":"992a3207-1ef6-459b-e7d8-510a39444c7d"},"source":["feature_columns"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[NumericColumn(key='Log_RnD_Fund', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n"," NumericColumn(key='Log_Duration', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n"," NumericColumn(key='N_of_SCI', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n"," NumericColumn(key='N_of_Paper', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n"," NumericColumn(key='N_Patent_App', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n"," NumericColumn(key='N_Patent_Reg', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n"," NumericColumn(key='N_of_Korean_Patent', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n"," NumericColumn(key='N_of_Inter_Patent', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n"," NumericColumn(key='N_of_Patent', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n"," NumericColumn(key='STP_Code_1_Weight', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n"," NumericColumn(key='STP_Code_2_Weight', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n"," NumericColumn(key='Application_Area_1_Weight', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n"," NumericColumn(key='Application_Area_2_Weight', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n"," NumericColumn(key='Application_Area_3_Weight', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Year', vocabulary_list=('2013.0', '2014.0', '2015.0', '2016.0'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Multi_Year', vocabulary_list=('2', '1'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='RnD_Org', vocabulary_list=('2', '3', '99', '5', '8', '1', '6', '4'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Region', vocabulary_list=('1', '19', '99', '2', '10', '6', '7', '11', '15', '13', '14', '5', '4', '8', '3', '12', '17', '9', '16'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='STP_Code_11', vocabulary_list=('OC03', 'SB12', 'ZZ', 'EG99', 'EG04', 'EG07', 'EE13', 'ND99', 'ND01', 'EF99', 'LC14', 'EG06', 'EH14', 'EA01', 'EH10', 'LC08', 'EF06', 'EG02', 'EG01', 'LA02', 'LA01', 'SA01', 'LA05', 'LA07', 'NA09', 'EE99', 'NC03', 'HE04', 'EH01', 'LA11', 'EA04', 'EE01', 'SI07', 'NA08', 'SB08', 'LA99', 'SG03', 'EE10', 'LC01', 'LB04', 'NB04', 'NC04', 'NC05', 'NC99', 'EA09', 'EB07', 'LC99', 'EE03', 'ED99', 'LC02', 'EE02', 'LC04', 'ED03', 'NB09', 'EI99', 'EI11', 'EA02', 'EC11', 'ND07', 'EI09', 'SB06', 'EH02', 'EB04', 'LB16', 'LC15', 'EA10', 'ED10', 'NC10', 'SC08', 'OC99', 'ED08', 'SB99', 'SD02', 'ED07', 'LC13', 'LC03', 'SA99', 'EC99', 'EI08', 'EB01', 'HE14', 'EH11', 'LB12', 'NA04', 'SB09', 'LB17', 'SG02', 'LB13', 'EI05', 'NB05', 'EA99', 'EA14', 'EE12', 'ND12', 'EE06', 'LA03', 'EG09', 'NC02', 'EA11', 'ED04', 'EA06', 'EB03', 'EE04', 'EC02', 'EF04', 'LC10', 'EC01', 'EA12', 'EB02', 'NC07', 'LC06', 'EH05', 'NC01', 'NA02', 'LA04', 'SC09', 'NA99', 'NB06', 'NB01', 'LB02', 'EI04', 'EH03', 'LA06', 'ED01', 'EA13', 'OA01', 'EE11', 'LB18', 'LA09', 'EE08', 'EG05', 'EA07', 'NC09', 'EB99', 'OA04', 'EH09', 'OA02', 'ED11', 'EH04', 'EI03', 'OB01', 'ED05', 'NC08', 'LB09', 'EC04', 'EI12', 'EA05', 'LC07', 'LB07', 'ND11', 'SE06', 'NA05', 'LB03', 'NA06', 'EG03', 'LB01', 'LA08', 'LC05', 'EE14', 'ND06', 'NC06', 'HE06', 'EG10', 'EA08', 'EC05', 'EC03', 'EI02', 'LC09', 'EE09', 'NA03', 'EE07', 'EH15', 'ND10', 'SC12', 'ND04', 'ND13', 'EH06', 'SE05', 'ND03', 'EA03', 'NA01', 'ND08', 'EB08', 'EG08', 'EB06', 'ED06', 'NB02', 'EF05', 'NA07', 'ZZ99', 'EH07', 'EB05', 'EE05', 'NB07', 'LB05', 'ED02', 'LA10', 'EA15', 'LB10', 'EC07', 'LB06', 'SI05', 'EF01', 'EC08', 'ND14', 'NB03', 'ED09', 'ND02', 'SC10', 'LC12', 'HC06', 'EH99', 'SC11', 'EI06', 'EI10', 'NA10', 'EH13', 'OB99', 'EI01', 'SA07', 'LB15', 'EF03', 'SH01', 'OA99', 'SC07', 'NB08', 'OC04', 'OB02', 'OA03', 'SG07', 'SF01', 'SH02', 'ND05', 'SC13', 'EF02', 'SH06', 'OC01', 'HE13', 'LB11', 'HE03', 'LB14', 'SH07', 'NB99', 'SC01', 'HB04', 'HC01', 'EH08', 'LB08', 'SG05', 'EC06', 'SF02', 'SB11', 'EC09', 'SD07', 'SB07', 'LC11', 'SI01', 'EH12', 'SH99', 'SC99', 'SC05', 'HE15', 'ND09', 'HE09', 'LB19', 'LB20', 'LB99', 'SI99', 'SI02', 'SI03', 'HA01', 'HD08', 'SD03', 'SD04', 'HC02', 'HD02', 'HD10', 'HB08', 'HA03', 'SF07', 'SD99', 'HD06', 'SC16', 'HA05', 'SH04', 'HE10', 'HA02', 'SA04', 'HD03', 'SC02', 'SD08', 'HE01', 'HD07', 'SG06', 'HA04', 'SB10', 'SC06', 'SA02', 'HD99', 'SA05', 'SC14', 'SD05', 'EI07', 'HE12', 'HE08', 'HC05', 'SA06', 'SG01', 'SC03', 'HC03', 'HE02', 'SF04', 'SD09', 'SB01', 'HA06', 'SE04', 'HB03', 'SF03', 'SG04', 'HE05', 'HB07', 'HD04', 'HA99', 'HC09', 'HC07', 'SB02', 'HB05', 'HC08', 'HE99', 'SC15', 'HB01', 'SH08', 'HD09', 'SI04', 'HD05', 'SC04', 'SA03', 'SE03', 'HE11', 'HC12', 'HD01', 'SD06', 'HE07', 'HC99', 'SB05', 'HB09', 'SD01', 'HB10', 'SE99', 'HC04', 'SF05', 'SF99', 'HB06', 'SE02', 'HB02', 'SH03', 'HA07', 'EC10', 'SG99', 'OC02', 'SF06', 'SE01', 'SI06'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='STP_Code_21', vocabulary_list=('None', 'EE10', 'EE02', 'EG07', 'EG10', 'EF99', 'EI99', 'EG99', 'EG04', 'OC03', 'ND02', 'EA14', 'EH13', 'EG02', 'EG06', 'LC14', 'LA01', 'LA02', 'LA99', 'LC02', 'LB12', 'HE99', 'EB07', 'EE11', 'SI07', 'EE01', 'HE14', 'SA01', 'NC09', 'EF06', 'NC04', 'LC01', 'LC04', 'NB09', 'EC11', 'EE13', 'SB11', 'HE04', 'ND07', 'EI11', 'ND05', 'EH08', 'LC13', 'NC06', 'SI02', 'EH11', 'OC01', 'EA05', 'LC03', 'EC02', 'SI99', 'NC01', 'EA02', 'NC10', 'NA08', 'LA04', 'EI01', 'ED01', 'EA09', 'LA06', 'LB03', 'NB05', 'EI05', 'ND06', 'EE07', 'LB18', 'NC02', 'EA07', 'EA04', 'NB06', 'NA07', 'NC08', 'EA15', 'ED05', 'EI12', 'EC03', 'LB07', 'ED03', 'LA07', 'LA08', 'ED11', 'EE03', 'ED04', 'ND13', 'LA03', 'NA01', 'EG01', 'LC10', 'EB01', 'EI04', 'EH02', 'NB01', 'LA10', 'EE14', 'EA08', 'ED10', 'EB03', 'OB01', 'EF05', 'NA05', 'LB05', 'EG09', 'EB02', 'OA01', 'LC07', 'EE06', 'ND03', 'SF01', 'LC08', 'EC04', 'NB08', 'EH03', 'NC03', 'NB04', 'EE99', 'EG08', 'EE09', 'NA09', 'EC01', 'EE05', 'NC05', 'HE08', 'OA04', 'EC05', 'EA06', 'EA01', 'EG03', 'SC09', 'ND14', 'LA05', 'ND08', 'LC05', 'EE04', 'EB99', 'SI05', 'OA02', 'EE12', 'EA10', 'EF04', 'EA11', 'EI02', 'EH07', 'NA06', 'LC15', 'OA03', 'LB17', 'NB07', 'ED08', 'NB02', 'ED07', 'ED99', 'LA09', 'EH06', 'ED02', 'EB08', 'EH01', 'EH09', 'EI03', 'ND01', 'NA02', 'EA12', 'ED09', 'LC12', 'EA13', 'HC02', 'EH05', 'EB05', 'LB13', 'SD01', 'EF01', 'EB04', 'EC06', 'EH12', 'EE08', 'EC99', 'EB06', 'SC11', 'EI10', 'OB02', 'LB06', 'LB04', 'ND10', 'LB01', 'SH01', 'HA06', 'SF02', 'EH10', 'NC07', 'SE06', 'SD04', 'NA10', 'LC06', 'EC09', 'EF03', 'EF02', 'SB12', 'SA07', 'NA04', 'HA05', 'ND12', 'SC10', 'HE10', 'OC99', 'SG07', 'EI06', 'SC12', 'EA03', 'LA11', 'SD08', 'SG04', 'LC11', 'NA03', 'SH03', 'SF07', 'EI09', 'SF03', 'OA99', 'SB02', 'LB16', 'LB10', 'OB99', 'SG02', 'SH07', 'SC07', 'ED06', 'LC09', 'SC02', 'HE05', 'NB03', 'HE13', 'LB99', 'SG05', 'ND04', 'SD99', 'SI01', 'LB14', 'EI08', 'LB09', 'NB99', 'EH04', 'SH02', 'HE15', 'ND11', 'SE03', 'EA99', 'LC99', 'HE12', 'SH06', 'HE11', 'LB11', 'SC06', 'ND09', 'EH14', 'SI03', 'LB15', 'HA01', 'SH08', 'SC13', 'NC99', 'EH15', 'SH99', 'LB02', 'SF99', 'EH99', 'HC01', 'SC04', 'HA02', 'SC16', 'EC10', 'HA99', 'SC99', 'SD03', 'SG03', 'SD02', 'EG05', 'HE06', 'EC07', 'SD07', 'SC01', 'HC05', 'HB02', 'SF05', 'HB05', 'SC08', 'HB03', 'HD02', 'HB01', 'HB08', 'HD03', 'SD09', 'SD05', 'HB04', 'SH04', 'SB06', 'SC15', 'HE02', 'HB10', 'SA06', 'HE09', 'SD06', 'HD99', 'NA99', 'HE01', 'HA04', 'HD06', 'SC03', 'HE03', 'HD05', 'SB05', 'SG99', 'SE05', 'SG06', 'EC08', 'HE07', 'LB20', 'SC05', 'OC02', 'HA07', 'SG01', 'HA03', 'SC14', 'HD01', 'SA05', 'SB10', 'SB01', 'LB08', 'HC03', 'LB19', 'SE99', 'OC04', 'SE04', 'ND99', 'EI07', 'HC12', 'SB08', 'SF04', 'SI04', 'SA99'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Application_Area_1', vocabulary_list=('X99', 'X04', 'Y99', 'X05', 'X01', 'X10', 'X02', 'Y16', 'X09', 'X12', 'Y09', 'Y17', 'X08', 'Y12', 'Y05', 'Y03', 'Y15', 'Y01', 'X11', 'Y02', 'Y19', 'X07', 'Y18', 'Y11', 'X03', 'Y04', 'Y10', 'Y08', 'X06', 'Y06', 'Y14', 'Y13', 'Y07'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Application_Area_2', vocabulary_list=('None', 'X99', 'X05', 'X10', 'X04', 'Y10', 'X09', 'Y09', 'Y16', 'X03', 'X12', 'X01', 'X08', 'Y05', 'Y04', 'Y14', 'X02', 'Y08', 'Y06', 'Y11', 'Y07', 'Y03', 'Y99', 'Y01', 'Y13', 'Y15', 'X11', 'Y18', 'Y17', 'X07', 'X06', 'Y02', 'Y12', 'Y19'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Application_Area_3', vocabulary_list=('None', 'X99', 'X04', 'Y16', 'X12', 'X08', 'X10', 'Y18', 'Y10', 'Y05', 'X01', 'Y17', 'Y08', 'Y99', 'Y04', 'Y09', 'Y13', 'Y15', 'X03', 'Y19', 'Y06', 'Y02', 'X05', 'X11', 'X02', 'X09', 'Y07', 'Y03', 'Y11', 'Y01', 'X07', 'Y14', 'Y12', 'X06'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Green_Tech', vocabulary_list=('999', '231', '237', '441', '235', '442', '900', '234', '511', '112', '421', '213', '241', '222', '226', '354', '245', '211', '214', '351', '326', '323', '321', '236', '352', '344', '244', '343', '324', '411', '224', '325', '341', '232', '431', '422', '111', '227', '215', '342', '424', '221', '233', '322', '432', '332', '331', '311', '353', '223', '225', '242', '327', '423', '412', '243', '212', '312', '413', '313'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='SixT_2', vocabulary_list=('70000', '10300', '10400', '50100', '20200', '50200', '20100', '60200', '60300', '30200', '40100', '50300', '20300', '50400', '10100', '60100', '30400', '10200', '40300', '30100', '40200', '40400', '30300'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Econ_Social', vocabulary_list=('13', '8', '7', '5', '11', '4', '3', '14', '2', '6', '1', '12', '9'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='National_Strategy_2', vocabulary_list=('60000', '50200', '20100', '30200', '10100', '20300', '50300', '40100', '10500', '10300', '20200', '10400', '30400', '40200', '10200', '20400', '50100', '40300', '30100', '30300', '20500'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='RnD_Stage', vocabulary_list=('4', '1', '2', '3'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Cowork_Cor', vocabulary_list=('N', 'Y'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Cowork_Uni', vocabulary_list=('N', 'Y'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Cowork_Inst', vocabulary_list=('N', 'Y'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Cowork_Abroad', vocabulary_list=('N', 'Y'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Cowork_etc', vocabulary_list=('N', 'Y'), dtype=tf.string, default_value=-1, num_oov_buckets=0))]"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4HxTvKkMd1lH","executionInfo":{"status":"ok","timestamp":1634282087316,"user_tz":-540,"elapsed":6,"user":{"displayName":"현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06235385304799063880"}},"outputId":"f50b7af6-d2d7-42e2-cb17-4bda8145f683"},"source":["len(df['Green_Tech'].value_counts())"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["60"]},"metadata":{},"execution_count":27}]},{"cell_type":"markdown","metadata":{"id":"fufnbPq2_0ZF"},"source":["# train, test, val split"]},{"cell_type":"code","metadata":{"id":"SBGhjogzL7Xo","executionInfo":{"status":"ok","timestamp":1634282087781,"user_tz":-540,"elapsed":470,"user":{"displayName":"현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06235385304799063880"}}},"source":["# Use a utility from sklearn to split and shuffle our dataset.\n","train_df, test_df = train_test_split(df, test_size=0.2)\n","train_df, val_df = train_test_split(train_df, test_size=0.2)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"PGZUSYx3ed80","executionInfo":{"status":"ok","timestamp":1634282087782,"user_tz":-540,"elapsed":6,"user":{"displayName":"현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06235385304799063880"}}},"source":["# train\n","x_train = train_df.loc[:,['Year', 'N_of_SCI', 'N_of_Paper', 'N_Patent_App', 'N_Patent_Reg',\n","       'N_of_Korean_Patent', 'N_of_Inter_Patent', 'N_of_Patent', 'Multi_Year',\n","       'RnD_Org', 'Region', 'STP_Code_11', 'STP_Code_1_Weight', 'STP_Code_21',\n","       'STP_Code_2_Weight', 'Application_Area_1', 'Application_Area_1_Weight',\n","       'Application_Area_2', 'Application_Area_2_Weight', 'Application_Area_3',\n","       'Application_Area_3_Weight', 'Green_Tech', 'SixT_2', 'Econ_Social',\n","       'National_Strategy_2', 'RnD_Stage', 'Cowork_Cor', 'Cowork_Uni',\n","       'Cowork_Inst', 'Cowork_Abroad', 'Cowork_etc', 'Log_RnD_Fund',\n","       'Log_Duration']]\n","y_train = train_df.loc[:,['Comm_Success']]\n","x_train = dict(x_train)\n","\n","# val\n","x_val = val_df.loc[:,['Year', 'N_of_SCI', 'N_of_Paper', 'N_Patent_App', 'N_Patent_Reg',\n","       'N_of_Korean_Patent', 'N_of_Inter_Patent', 'N_of_Patent', 'Multi_Year',\n","       'RnD_Org', 'Region', 'STP_Code_11', 'STP_Code_1_Weight', 'STP_Code_21',\n","       'STP_Code_2_Weight', 'Application_Area_1', 'Application_Area_1_Weight',\n","       'Application_Area_2', 'Application_Area_2_Weight', 'Application_Area_3',\n","       'Application_Area_3_Weight', 'Green_Tech', 'SixT_2', 'Econ_Social',\n","       'National_Strategy_2', 'RnD_Stage', 'Cowork_Cor', 'Cowork_Uni',\n","       'Cowork_Inst', 'Cowork_Abroad', 'Cowork_etc', 'Log_RnD_Fund',\n","       'Log_Duration']]\n","y_val = val_df.loc[:,['Comm_Success']]\n","x_val = dict(x_val)\n","\n","# test\n","x_test = test_df.loc[:,['Year', 'N_of_SCI', 'N_of_Paper', 'N_Patent_App', 'N_Patent_Reg',\n","       'N_of_Korean_Patent', 'N_of_Inter_Patent', 'N_of_Patent', 'Multi_Year',\n","       'RnD_Org', 'Region', 'STP_Code_11', 'STP_Code_1_Weight', 'STP_Code_21',\n","       'STP_Code_2_Weight', 'Application_Area_1', 'Application_Area_1_Weight',\n","       'Application_Area_2', 'Application_Area_2_Weight', 'Application_Area_3',\n","       'Application_Area_3_Weight', 'Green_Tech', 'SixT_2', 'Econ_Social',\n","       'National_Strategy_2', 'RnD_Stage', 'Cowork_Cor', 'Cowork_Uni',\n","       'Cowork_Inst', 'Cowork_Abroad', 'Cowork_etc', 'Log_RnD_Fund',\n","       'Log_Duration']]\n","y_test = test_df.loc[:,['Comm_Success']]\n","x_test = dict(x_test)\n"],"execution_count":29,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j5Xx9G-mxeKe"},"source":["#모델생성"]},{"cell_type":"markdown","metadata":{"id":"74MgKKq6C8k2"},"source":["## 825"]},{"cell_type":"code","metadata":{"id":"6UHLXP7AC8me","executionInfo":{"status":"ok","timestamp":1634282087782,"user_tz":-540,"elapsed":5,"user":{"displayName":"현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06235385304799063880"}}},"source":["from sklearn.metrics import precision_recall_fscore_support\n","from keras.callbacks import ModelCheckpoint"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"6DnORJyqC8mf","executionInfo":{"status":"ok","timestamp":1634282087782,"user_tz":-540,"elapsed":4,"user":{"displayName":"현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06235385304799063880"}}},"source":["METRICS = [\n","      keras.metrics.BinaryAccuracy(name='accuracy'),\n","      keras.metrics.Precision(name='precision'),\n","      keras.metrics.Recall(name='recall'),\n","      keras.metrics.AUC(name='auc'),\n","      tfa.metrics.F1Score(num_classes=1, threshold=0.5)\n","\n","]\n"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"h-Rb6CpZC8mf","executionInfo":{"status":"ok","timestamp":1634282087783,"user_tz":-540,"elapsed":5,"user":{"displayName":"현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06235385304799063880"}}},"source":[""],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"WAf0ipYfC8mf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634292221123,"user_tz":-540,"elapsed":10133345,"user":{"displayName":"현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06235385304799063880"}},"outputId":"8fae7f00-0e29-4ce3-af61-20a5b77037c1"},"source":["cb = tf.keras.callbacks.EarlyStopping( monitor='val_loss', min_delta = 0,  patience=500, verbose=1, mode='min', baseline=None, restore_best_weights=True )\n","\n","def creat_model():\n","  model = tf.keras.models.Sequential([\n","    tf.keras.layers.DenseFeatures(feature_columns=feature_columns),\n","    tf.keras.layers.Dense(units=1000, activation='relu'),\n","    tf.keras.layers.Dropout(rate=0.1),\n","    tf.keras.layers.Dense(units=300, activation='relu'),\n","    tf.keras.layers.Dropout(rate=0.1),\n","    tf.keras.layers.Dense(units=300, activation='relu'),\n","    tf.keras.layers.Dropout(rate=0.1),\n","    tf.keras.layers.Dense(units=1, activation='sigmoid')\n","  ])\n","\n","  model.compile(optimizer='adam',\n","                loss= tfa.losses.SigmoidFocalCrossEntropy(gamma = 2, alpha=0.825),\n","                metrics=METRICS)\n","  \n","  return model\n","\n","\n","model = creat_model()\n","\n","\n","model.fit(\n","    x_train, y_train,\n","    batch_size=256,\n","    epochs=300,\n","    validation_data=(x_val, y_val),\n","    callbacks=cb\n",")\n","\n","\n","print('-----------------------테스트 결과---------------------------')\n","loss, BinaryAccuracy ,Precision, Recall,AUC,F1Score= model.evaluate(x_test,y_test)\n","\n","print('')\n","print('')\n","# 모델 저장 경로\n","model.save('/gdrive/My Drive/Colab Notebooks/DNN/alpha/modelsave/프로젝트_성공_0.825')"],"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/300\n","WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Year': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=string>, 'N_of_SCI': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float64>, 'N_of_Paper': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float64>, 'N_Patent_App': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float64>, 'N_Patent_Reg': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float64>, 'N_of_Korean_Patent': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float64>, 'N_of_Inter_Patent': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float64>, 'N_of_Patent': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float64>, 'Multi_Year': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=string>, 'RnD_Org': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=string>, 'Region': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=string>, 'STP_Code_11': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'STP_Code_1_Weight': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float64>, 'STP_Code_21': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=string>, 'STP_Code_2_Weight': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float64>, 'Application_Area_1': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=string>, 'Application_Area_1_Weight': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float64>, 'Application_Area_2': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=string>, 'Application_Area_2_Weight': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float64>, 'Application_Area_3': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=string>, 'Application_Area_3_Weight': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float64>, 'Green_Tech': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=string>, 'SixT_2': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=string>, 'Econ_Social': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=string>, 'National_Strategy_2': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=string>, 'RnD_Stage': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=string>, 'Cowork_Cor': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=string>, 'Cowork_Uni': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'Cowork_Inst': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=string>, 'Cowork_Abroad': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=string>, 'Cowork_etc': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'Log_RnD_Fund': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float64>, 'Log_Duration': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=float64>}\n","Consider rewriting this model with the Functional API.\n","WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Year': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=string>, 'N_of_SCI': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float64>, 'N_of_Paper': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float64>, 'N_Patent_App': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float64>, 'N_Patent_Reg': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float64>, 'N_of_Korean_Patent': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float64>, 'N_of_Inter_Patent': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float64>, 'N_of_Patent': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float64>, 'Multi_Year': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=string>, 'RnD_Org': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=string>, 'Region': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=string>, 'STP_Code_11': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'STP_Code_1_Weight': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float64>, 'STP_Code_21': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=string>, 'STP_Code_2_Weight': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float64>, 'Application_Area_1': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=string>, 'Application_Area_1_Weight': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float64>, 'Application_Area_2': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=string>, 'Application_Area_2_Weight': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float64>, 'Application_Area_3': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=string>, 'Application_Area_3_Weight': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float64>, 'Green_Tech': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=string>, 'SixT_2': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=string>, 'Econ_Social': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=string>, 'National_Strategy_2': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=string>, 'RnD_Stage': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=string>, 'Cowork_Cor': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=string>, 'Cowork_Uni': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'Cowork_Inst': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=string>, 'Cowork_Abroad': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=string>, 'Cowork_etc': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'Log_RnD_Fund': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float64>, 'Log_Duration': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=float64>}\n","Consider rewriting this model with the Functional API.\n","482/483 [============================>.] - ETA: 0s - loss: 0.0428 - accuracy: 0.7579 - precision: 0.3113 - recall: 0.7701 - auc: 0.8303 - f1_score: 0.4434WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Year': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=string>, 'N_of_SCI': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float64>, 'N_of_Paper': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float64>, 'N_Patent_App': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float64>, 'N_Patent_Reg': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float64>, 'N_of_Korean_Patent': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float64>, 'N_of_Inter_Patent': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float64>, 'N_of_Patent': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float64>, 'Multi_Year': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=string>, 'RnD_Org': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=string>, 'Region': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=string>, 'STP_Code_11': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=string>, 'STP_Code_1_Weight': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float64>, 'STP_Code_21': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=string>, 'STP_Code_2_Weight': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=float64>, 'Application_Area_1': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=string>, 'Application_Area_1_Weight': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float64>, 'Application_Area_2': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=string>, 'Application_Area_2_Weight': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float64>, 'Application_Area_3': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=string>, 'Application_Area_3_Weight': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float64>, 'Green_Tech': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=string>, 'SixT_2': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=string>, 'Econ_Social': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=string>, 'National_Strategy_2': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=string>, 'RnD_Stage': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=string>, 'Cowork_Cor': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=string>, 'Cowork_Uni': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=string>, 'Cowork_Inst': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=string>, 'Cowork_Abroad': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=string>, 'Cowork_etc': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'Log_RnD_Fund': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float64>, 'Log_Duration': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=float64>}\n","Consider rewriting this model with the Functional API.\n","483/483 [==============================] - 34s 65ms/step - loss: 0.0428 - accuracy: 0.7579 - precision: 0.3113 - recall: 0.7702 - auc: 0.8304 - f1_score: 0.4434 - val_loss: 0.0260 - val_accuracy: 0.7366 - val_precision: 0.3177 - val_recall: 0.9444 - val_auc: 0.8968 - val_f1_score: 0.4755\n","Epoch 2/300\n","483/483 [==============================] - 31s 63ms/step - loss: 0.0252 - accuracy: 0.7910 - precision: 0.3598 - recall: 0.8587 - auc: 0.8922 - f1_score: 0.5071 - val_loss: 0.0249 - val_accuracy: 0.8271 - val_precision: 0.4063 - val_recall: 0.7967 - val_auc: 0.9067 - val_f1_score: 0.5381\n","Epoch 3/300\n","483/483 [==============================] - 30s 63ms/step - loss: 0.0240 - accuracy: 0.7930 - precision: 0.3644 - recall: 0.8775 - auc: 0.9050 - f1_score: 0.5150 - val_loss: 0.0239 - val_accuracy: 0.8010 - val_precision: 0.3761 - val_recall: 0.8713 - val_auc: 0.9099 - val_f1_score: 0.5254\n","Epoch 4/300\n","483/483 [==============================] - 30s 62ms/step - loss: 0.0235 - accuracy: 0.7972 - precision: 0.3697 - recall: 0.8793 - auc: 0.9095 - f1_score: 0.5206 - val_loss: 0.0232 - val_accuracy: 0.8279 - val_precision: 0.4115 - val_recall: 0.8408 - val_auc: 0.9176 - val_f1_score: 0.5526\n","Epoch 5/300\n","483/483 [==============================] - 30s 62ms/step - loss: 0.0226 - accuracy: 0.8079 - precision: 0.3835 - recall: 0.8797 - auc: 0.9169 - f1_score: 0.5342 - val_loss: 0.0226 - val_accuracy: 0.8096 - val_precision: 0.3891 - val_recall: 0.8885 - val_auc: 0.9211 - val_f1_score: 0.5412\n","Epoch 6/300\n","483/483 [==============================] - 30s 63ms/step - loss: 0.0223 - accuracy: 0.8154 - precision: 0.3938 - recall: 0.8798 - auc: 0.9200 - f1_score: 0.5441 - val_loss: 0.0239 - val_accuracy: 0.7598 - val_precision: 0.3385 - val_recall: 0.9433 - val_auc: 0.9171 - val_f1_score: 0.4982\n","Epoch 7/300\n","483/483 [==============================] - 31s 64ms/step - loss: 0.0221 - accuracy: 0.8186 - precision: 0.3980 - recall: 0.8755 - auc: 0.9209 - f1_score: 0.5473 - val_loss: 0.0229 - val_accuracy: 0.7959 - val_precision: 0.3741 - val_recall: 0.9128 - val_auc: 0.9225 - val_f1_score: 0.5307\n","Epoch 8/300\n","483/483 [==============================] - 30s 63ms/step - loss: 0.0216 - accuracy: 0.8262 - precision: 0.4092 - recall: 0.8749 - auc: 0.9249 - f1_score: 0.5576 - val_loss: 0.0231 - val_accuracy: 0.8280 - val_precision: 0.4134 - val_recall: 0.8600 - val_auc: 0.9205 - val_f1_score: 0.5584\n","Epoch 9/300\n","483/483 [==============================] - 31s 64ms/step - loss: 0.0215 - accuracy: 0.8315 - precision: 0.4171 - recall: 0.8697 - auc: 0.9260 - f1_score: 0.5638 - val_loss: 0.0227 - val_accuracy: 0.8551 - val_precision: 0.4587 - val_recall: 0.8134 - val_auc: 0.9256 - val_f1_score: 0.5866\n","Epoch 10/300\n","483/483 [==============================] - 31s 65ms/step - loss: 0.0213 - accuracy: 0.8348 - precision: 0.4228 - recall: 0.8739 - auc: 0.9279 - f1_score: 0.5699 - val_loss: 0.0224 - val_accuracy: 0.8113 - val_precision: 0.3923 - val_recall: 0.8972 - val_auc: 0.9246 - val_f1_score: 0.5459\n","Epoch 11/300\n","483/483 [==============================] - 31s 65ms/step - loss: 0.0211 - accuracy: 0.8380 - precision: 0.4277 - recall: 0.8702 - auc: 0.9291 - f1_score: 0.5735 - val_loss: 0.0233 - val_accuracy: 0.8100 - val_precision: 0.3895 - val_recall: 0.8867 - val_auc: 0.9196 - val_f1_score: 0.5412\n","Epoch 12/300\n","483/483 [==============================] - 31s 64ms/step - loss: 0.0209 - accuracy: 0.8369 - precision: 0.4265 - recall: 0.8784 - auc: 0.9297 - f1_score: 0.5742 - val_loss: 0.0230 - val_accuracy: 0.7891 - val_precision: 0.3674 - val_recall: 0.9262 - val_auc: 0.9239 - val_f1_score: 0.5261\n","Epoch 13/300\n","483/483 [==============================] - 31s 64ms/step - loss: 0.0206 - accuracy: 0.8399 - precision: 0.4320 - recall: 0.8835 - auc: 0.9321 - f1_score: 0.5802 - val_loss: 0.0230 - val_accuracy: 0.8439 - val_precision: 0.4396 - val_recall: 0.8539 - val_auc: 0.9273 - val_f1_score: 0.5804\n","Epoch 14/300\n","483/483 [==============================] - 32s 66ms/step - loss: 0.0205 - accuracy: 0.8404 - precision: 0.4325 - recall: 0.8808 - auc: 0.9328 - f1_score: 0.5801 - val_loss: 0.0225 - val_accuracy: 0.8340 - val_precision: 0.4244 - val_recall: 0.8795 - val_auc: 0.9283 - val_f1_score: 0.5725\n","Epoch 15/300\n","483/483 [==============================] - 31s 65ms/step - loss: 0.0204 - accuracy: 0.8453 - precision: 0.4409 - recall: 0.8783 - auc: 0.9340 - f1_score: 0.5871 - val_loss: 0.0220 - val_accuracy: 0.8511 - val_precision: 0.4522 - val_recall: 0.8416 - val_auc: 0.9271 - val_f1_score: 0.5883\n","Epoch 16/300\n","483/483 [==============================] - 31s 65ms/step - loss: 0.0203 - accuracy: 0.8430 - precision: 0.4372 - recall: 0.8839 - auc: 0.9342 - f1_score: 0.5850 - val_loss: 0.0235 - val_accuracy: 0.8178 - val_precision: 0.4016 - val_recall: 0.9003 - val_auc: 0.9259 - val_f1_score: 0.5554\n","Epoch 17/300\n","483/483 [==============================] - 31s 64ms/step - loss: 0.0202 - accuracy: 0.8452 - precision: 0.4412 - recall: 0.8848 - auc: 0.9347 - f1_score: 0.5888 - val_loss: 0.0252 - val_accuracy: 0.8727 - val_precision: 0.4976 - val_recall: 0.7719 - val_auc: 0.9267 - val_f1_score: 0.6051\n","Epoch 18/300\n","483/483 [==============================] - 31s 64ms/step - loss: 0.0201 - accuracy: 0.8446 - precision: 0.4403 - recall: 0.8890 - auc: 0.9358 - f1_score: 0.5889 - val_loss: 0.0248 - val_accuracy: 0.8678 - val_precision: 0.4858 - val_recall: 0.7885 - val_auc: 0.9258 - val_f1_score: 0.6012\n","Epoch 19/300\n","483/483 [==============================] - 31s 64ms/step - loss: 0.0199 - accuracy: 0.8483 - precision: 0.4466 - recall: 0.8864 - auc: 0.9369 - f1_score: 0.5940 - val_loss: 0.0235 - val_accuracy: 0.8560 - val_precision: 0.4615 - val_recall: 0.8352 - val_auc: 0.9283 - val_f1_score: 0.5945\n","Epoch 20/300\n","483/483 [==============================] - 31s 65ms/step - loss: 0.0196 - accuracy: 0.8513 - precision: 0.4523 - recall: 0.8894 - auc: 0.9385 - f1_score: 0.5997 - val_loss: 0.0255 - val_accuracy: 0.8505 - val_precision: 0.4513 - val_recall: 0.8457 - val_auc: 0.9285 - val_f1_score: 0.5885\n","Epoch 21/300\n","483/483 [==============================] - 32s 65ms/step - loss: 0.0196 - accuracy: 0.8491 - precision: 0.4483 - recall: 0.8887 - auc: 0.9381 - f1_score: 0.5959 - val_loss: 0.0243 - val_accuracy: 0.8285 - val_precision: 0.4160 - val_recall: 0.8834 - val_auc: 0.9271 - val_f1_score: 0.5657\n","Epoch 22/300\n","483/483 [==============================] - 32s 67ms/step - loss: 0.0196 - accuracy: 0.8511 - precision: 0.4519 - recall: 0.8911 - auc: 0.9389 - f1_score: 0.5997 - val_loss: 0.0231 - val_accuracy: 0.8403 - val_precision: 0.4340 - val_recall: 0.8670 - val_auc: 0.9285 - val_f1_score: 0.5785\n","Epoch 23/300\n","483/483 [==============================] - 32s 67ms/step - loss: 0.0193 - accuracy: 0.8503 - precision: 0.4508 - recall: 0.8943 - auc: 0.9400 - f1_score: 0.5994 - val_loss: 0.0261 - val_accuracy: 0.8814 - val_precision: 0.5231 - val_recall: 0.6973 - val_auc: 0.9240 - val_f1_score: 0.5977\n","Epoch 24/300\n","483/483 [==============================] - 32s 66ms/step - loss: 0.0192 - accuracy: 0.8530 - precision: 0.4556 - recall: 0.8938 - auc: 0.9406 - f1_score: 0.6036 - val_loss: 0.0236 - val_accuracy: 0.8356 - val_precision: 0.4267 - val_recall: 0.8749 - val_auc: 0.9278 - val_f1_score: 0.5736\n","Epoch 25/300\n","483/483 [==============================] - 32s 65ms/step - loss: 0.0191 - accuracy: 0.8551 - precision: 0.4594 - recall: 0.8922 - auc: 0.9417 - f1_score: 0.6065 - val_loss: 0.0229 - val_accuracy: 0.8402 - val_precision: 0.4339 - val_recall: 0.8664 - val_auc: 0.9277 - val_f1_score: 0.5782\n","Epoch 26/300\n","483/483 [==============================] - 31s 65ms/step - loss: 0.0191 - accuracy: 0.8536 - precision: 0.4569 - recall: 0.8976 - auc: 0.9414 - f1_score: 0.6056 - val_loss: 0.0225 - val_accuracy: 0.8194 - val_precision: 0.4045 - val_recall: 0.9077 - val_auc: 0.9289 - val_f1_score: 0.5597\n","Epoch 27/300\n","483/483 [==============================] - 31s 65ms/step - loss: 0.0191 - accuracy: 0.8548 - precision: 0.4590 - recall: 0.8945 - auc: 0.9419 - f1_score: 0.6067 - val_loss: 0.0243 - val_accuracy: 0.8630 - val_precision: 0.4758 - val_recall: 0.8241 - val_auc: 0.9295 - val_f1_score: 0.6033\n","Epoch 28/300\n","483/483 [==============================] - 31s 65ms/step - loss: 0.0187 - accuracy: 0.8548 - precision: 0.4592 - recall: 0.8998 - auc: 0.9433 - f1_score: 0.6081 - val_loss: 0.0232 - val_accuracy: 0.8226 - val_precision: 0.4090 - val_recall: 0.9064 - val_auc: 0.9297 - val_f1_score: 0.5636\n","Epoch 29/300\n","483/483 [==============================] - 31s 65ms/step - loss: 0.0187 - accuracy: 0.8579 - precision: 0.4652 - recall: 0.9013 - auc: 0.9441 - f1_score: 0.6136 - val_loss: 0.0247 - val_accuracy: 0.8304 - val_precision: 0.4194 - val_recall: 0.8903 - val_auc: 0.9296 - val_f1_score: 0.5702\n","Epoch 30/300\n","483/483 [==============================] - 31s 65ms/step - loss: 0.0187 - accuracy: 0.8560 - precision: 0.4615 - recall: 0.9001 - auc: 0.9436 - f1_score: 0.6101 - val_loss: 0.0230 - val_accuracy: 0.8481 - val_precision: 0.4468 - val_recall: 0.8470 - val_auc: 0.9278 - val_f1_score: 0.5850\n","Epoch 31/300\n","483/483 [==============================] - 31s 65ms/step - loss: 0.0185 - accuracy: 0.8588 - precision: 0.4670 - recall: 0.9001 - auc: 0.9451 - f1_score: 0.6149 - val_loss: 0.0258 - val_accuracy: 0.8329 - val_precision: 0.4229 - val_recall: 0.8836 - val_auc: 0.9288 - val_f1_score: 0.5721\n","Epoch 32/300\n","483/483 [==============================] - 32s 65ms/step - loss: 0.0184 - accuracy: 0.8586 - precision: 0.4666 - recall: 0.9042 - auc: 0.9452 - f1_score: 0.6156 - val_loss: 0.0254 - val_accuracy: 0.8389 - val_precision: 0.4323 - val_recall: 0.8754 - val_auc: 0.9294 - val_f1_score: 0.5788\n","Epoch 33/300\n","483/483 [==============================] - 31s 65ms/step - loss: 0.0183 - accuracy: 0.8612 - precision: 0.4717 - recall: 0.9046 - auc: 0.9459 - f1_score: 0.6201 - val_loss: 0.0251 - val_accuracy: 0.8568 - val_precision: 0.4637 - val_recall: 0.8498 - val_auc: 0.9304 - val_f1_score: 0.6000\n","Epoch 34/300\n","483/483 [==============================] - 31s 65ms/step - loss: 0.0182 - accuracy: 0.8606 - precision: 0.4705 - recall: 0.9055 - auc: 0.9468 - f1_score: 0.6193 - val_loss: 0.0258 - val_accuracy: 0.8318 - val_precision: 0.4214 - val_recall: 0.8862 - val_auc: 0.9277 - val_f1_score: 0.5712\n","Epoch 35/300\n","483/483 [==============================] - 31s 65ms/step - loss: 0.0181 - accuracy: 0.8626 - precision: 0.4745 - recall: 0.9060 - auc: 0.9476 - f1_score: 0.6228 - val_loss: 0.0246 - val_accuracy: 0.8561 - val_precision: 0.4620 - val_recall: 0.8439 - val_auc: 0.9300 - val_f1_score: 0.5971\n","Epoch 36/300\n","483/483 [==============================] - 31s 65ms/step - loss: 0.0181 - accuracy: 0.8634 - precision: 0.4761 - recall: 0.9048 - auc: 0.9476 - f1_score: 0.6239 - val_loss: 0.0250 - val_accuracy: 0.8640 - val_precision: 0.4768 - val_recall: 0.7803 - val_auc: 0.9223 - val_f1_score: 0.5919\n","Epoch 37/300\n","483/483 [==============================] - 32s 65ms/step - loss: 0.0183 - accuracy: 0.8591 - precision: 0.4678 - recall: 0.9075 - auc: 0.9464 - f1_score: 0.6174 - val_loss: 0.0258 - val_accuracy: 0.8477 - val_precision: 0.4472 - val_recall: 0.8670 - val_auc: 0.9298 - val_f1_score: 0.5900\n","Epoch 38/300\n","483/483 [==============================] - 31s 65ms/step - loss: 0.0182 - accuracy: 0.8592 - precision: 0.4680 - recall: 0.9089 - auc: 0.9467 - f1_score: 0.6179 - val_loss: 0.0292 - val_accuracy: 0.8344 - val_precision: 0.4237 - val_recall: 0.8611 - val_auc: 0.9219 - val_f1_score: 0.5680\n","Epoch 39/300\n","483/483 [==============================] - 31s 65ms/step - loss: 0.0180 - accuracy: 0.8645 - precision: 0.4783 - recall: 0.9072 - auc: 0.9484 - f1_score: 0.6264 - val_loss: 0.0285 - val_accuracy: 0.8607 - val_precision: 0.4713 - val_recall: 0.8390 - val_auc: 0.9293 - val_f1_score: 0.6036\n","Epoch 40/300\n","483/483 [==============================] - 31s 65ms/step - loss: 0.0176 - accuracy: 0.8646 - precision: 0.4786 - recall: 0.9077 - auc: 0.9497 - f1_score: 0.6268 - val_loss: 0.0234 - val_accuracy: 0.8420 - val_precision: 0.4372 - val_recall: 0.8698 - val_auc: 0.9260 - val_f1_score: 0.5819\n","Epoch 41/300\n","483/483 [==============================] - 31s 65ms/step - loss: 0.0177 - accuracy: 0.8645 - precision: 0.4784 - recall: 0.9079 - auc: 0.9495 - f1_score: 0.6267 - val_loss: 0.0289 - val_accuracy: 0.8476 - val_precision: 0.4465 - val_recall: 0.8585 - val_auc: 0.9281 - val_f1_score: 0.5875\n","Epoch 42/300\n","483/483 [==============================] - 31s 64ms/step - loss: 0.0177 - accuracy: 0.8647 - precision: 0.4788 - recall: 0.9117 - auc: 0.9499 - f1_score: 0.6278 - val_loss: 0.0278 - val_accuracy: 0.8604 - val_precision: 0.4705 - val_recall: 0.8336 - val_auc: 0.9294 - val_f1_score: 0.6015\n","Epoch 43/300\n","483/483 [==============================] - 31s 65ms/step - loss: 0.0175 - accuracy: 0.8665 - precision: 0.4823 - recall: 0.9091 - auc: 0.9505 - f1_score: 0.6303 - val_loss: 0.0322 - val_accuracy: 0.8531 - val_precision: 0.4562 - val_recall: 0.8447 - val_auc: 0.9281 - val_f1_score: 0.5924\n","Epoch 44/300\n","483/483 [==============================] - 31s 65ms/step - loss: 0.0176 - accuracy: 0.8660 - precision: 0.4815 - recall: 0.9112 - auc: 0.9506 - f1_score: 0.6301 - val_loss: 0.0274 - val_accuracy: 0.8646 - val_precision: 0.4796 - val_recall: 0.8377 - val_auc: 0.9303 - val_f1_score: 0.6100\n","Epoch 45/300\n","483/483 [==============================] - 32s 66ms/step - loss: 0.0174 - accuracy: 0.8677 - precision: 0.4849 - recall: 0.9141 - auc: 0.9512 - f1_score: 0.6336 - val_loss: 0.0276 - val_accuracy: 0.8593 - val_precision: 0.4685 - val_recall: 0.8411 - val_auc: 0.9283 - val_f1_score: 0.6018\n","Epoch 46/300\n","483/483 [==============================] - 31s 64ms/step - loss: 0.0173 - accuracy: 0.8684 - precision: 0.4863 - recall: 0.9137 - auc: 0.9517 - f1_score: 0.6348 - val_loss: 0.0281 - val_accuracy: 0.8406 - val_precision: 0.4351 - val_recall: 0.8754 - val_auc: 0.9280 - val_f1_score: 0.5813\n","Epoch 47/300\n","483/483 [==============================] - 31s 64ms/step - loss: 0.0172 - accuracy: 0.8690 - precision: 0.4877 - recall: 0.9152 - auc: 0.9523 - f1_score: 0.6363 - val_loss: 0.0260 - val_accuracy: 0.8386 - val_precision: 0.4317 - val_recall: 0.8739 - val_auc: 0.9253 - val_f1_score: 0.5779\n","Epoch 48/300\n","483/483 [==============================] - 32s 66ms/step - loss: 0.0172 - accuracy: 0.8697 - precision: 0.4892 - recall: 0.9160 - auc: 0.9525 - f1_score: 0.6377 - val_loss: 0.0291 - val_accuracy: 0.8686 - val_precision: 0.4883 - val_recall: 0.8193 - val_auc: 0.9306 - val_f1_score: 0.6119\n","Epoch 49/300\n","483/483 [==============================] - 32s 67ms/step - loss: 0.0170 - accuracy: 0.8712 - precision: 0.4924 - recall: 0.9184 - auc: 0.9533 - f1_score: 0.6411 - val_loss: 0.0324 - val_accuracy: 0.8596 - val_precision: 0.4687 - val_recall: 0.8300 - val_auc: 0.9270 - val_f1_score: 0.5991\n","Epoch 50/300\n","483/483 [==============================] - 32s 67ms/step - loss: 0.0170 - accuracy: 0.8713 - precision: 0.4926 - recall: 0.9195 - auc: 0.9537 - f1_score: 0.6415 - val_loss: 0.0257 - val_accuracy: 0.8542 - val_precision: 0.4587 - val_recall: 0.8534 - val_auc: 0.9303 - val_f1_score: 0.5966\n","Epoch 51/300\n","483/483 [==============================] - 32s 66ms/step - loss: 0.0170 - accuracy: 0.8700 - precision: 0.4898 - recall: 0.9185 - auc: 0.9531 - f1_score: 0.6389 - val_loss: 0.0253 - val_accuracy: 0.8583 - val_precision: 0.4665 - val_recall: 0.8436 - val_auc: 0.9291 - val_f1_score: 0.6008\n","Epoch 52/300\n","483/483 [==============================] - 32s 66ms/step - loss: 0.0169 - accuracy: 0.8708 - precision: 0.4916 - recall: 0.9196 - auc: 0.9540 - f1_score: 0.6407 - val_loss: 0.0318 - val_accuracy: 0.8646 - val_precision: 0.4793 - val_recall: 0.8265 - val_auc: 0.9289 - val_f1_score: 0.6067\n","Epoch 53/300\n","483/483 [==============================] - 32s 66ms/step - loss: 0.0168 - accuracy: 0.8719 - precision: 0.4937 - recall: 0.9215 - auc: 0.9546 - f1_score: 0.6430 - val_loss: 0.0282 - val_accuracy: 0.8613 - val_precision: 0.4723 - val_recall: 0.8288 - val_auc: 0.9287 - val_f1_score: 0.6017\n","Epoch 54/300\n","483/483 [==============================] - 32s 66ms/step - loss: 0.0167 - accuracy: 0.8729 - precision: 0.4959 - recall: 0.9170 - auc: 0.9551 - f1_score: 0.6437 - val_loss: 0.0295 - val_accuracy: 0.8572 - val_precision: 0.4629 - val_recall: 0.8118 - val_auc: 0.9224 - val_f1_score: 0.5896\n","Epoch 55/300\n","483/483 [==============================] - 32s 66ms/step - loss: 0.0170 - accuracy: 0.8688 - precision: 0.4873 - recall: 0.9211 - auc: 0.9536 - f1_score: 0.6374 - val_loss: 0.0272 - val_accuracy: 0.8587 - val_precision: 0.4675 - val_recall: 0.8449 - val_auc: 0.9290 - val_f1_score: 0.6019\n","Epoch 56/300\n","483/483 [==============================] - 32s 66ms/step - loss: 0.0166 - accuracy: 0.8730 - precision: 0.4963 - recall: 0.9259 - auc: 0.9558 - f1_score: 0.6462 - val_loss: 0.0276 - val_accuracy: 0.8477 - val_precision: 0.4472 - val_recall: 0.8654 - val_auc: 0.9271 - val_f1_score: 0.5896\n","Epoch 57/300\n","483/483 [==============================] - 32s 67ms/step - loss: 0.0166 - accuracy: 0.8736 - precision: 0.4974 - recall: 0.9193 - auc: 0.9557 - f1_score: 0.6456 - val_loss: 0.0359 - val_accuracy: 0.8710 - val_precision: 0.4938 - val_recall: 0.8059 - val_auc: 0.9274 - val_f1_score: 0.6124\n","Epoch 58/300\n","483/483 [==============================] - 33s 67ms/step - loss: 0.0165 - accuracy: 0.8759 - precision: 0.5024 - recall: 0.9183 - auc: 0.9562 - f1_score: 0.6495 - val_loss: 0.0360 - val_accuracy: 0.8752 - val_precision: 0.5041 - val_recall: 0.7890 - val_auc: 0.9273 - val_f1_score: 0.6152\n","Epoch 59/300\n","483/483 [==============================] - 32s 67ms/step - loss: 0.0166 - accuracy: 0.8728 - precision: 0.4958 - recall: 0.9222 - auc: 0.9553 - f1_score: 0.6449 - val_loss: 0.0405 - val_accuracy: 0.8719 - val_precision: 0.4958 - val_recall: 0.7793 - val_auc: 0.9228 - val_f1_score: 0.6060\n","Epoch 60/300\n","483/483 [==============================] - 32s 66ms/step - loss: 0.0164 - accuracy: 0.8741 - precision: 0.4986 - recall: 0.9232 - auc: 0.9567 - f1_score: 0.6475 - val_loss: 0.0308 - val_accuracy: 0.8436 - val_precision: 0.4397 - val_recall: 0.8644 - val_auc: 0.9258 - val_f1_score: 0.5829\n","Epoch 61/300\n","483/483 [==============================] - 32s 66ms/step - loss: 0.0162 - accuracy: 0.8754 - precision: 0.5014 - recall: 0.9259 - auc: 0.9571 - f1_score: 0.6505 - val_loss: 0.0331 - val_accuracy: 0.8620 - val_precision: 0.4741 - val_recall: 0.8416 - val_auc: 0.9292 - val_f1_score: 0.6065\n","Epoch 62/300\n","483/483 [==============================] - 32s 66ms/step - loss: 0.0164 - accuracy: 0.8746 - precision: 0.4996 - recall: 0.9240 - auc: 0.9566 - f1_score: 0.6485 - val_loss: 0.0341 - val_accuracy: 0.8596 - val_precision: 0.4696 - val_recall: 0.8557 - val_auc: 0.9301 - val_f1_score: 0.6064\n","Epoch 63/300\n","483/483 [==============================] - 32s 67ms/step - loss: 0.0162 - accuracy: 0.8783 - precision: 0.5077 - recall: 0.9252 - auc: 0.9578 - f1_score: 0.6556 - val_loss: 0.0270 - val_accuracy: 0.8517 - val_precision: 0.4543 - val_recall: 0.8623 - val_auc: 0.9295 - val_f1_score: 0.5951\n","Epoch 64/300\n","483/483 [==============================] - 32s 67ms/step - loss: 0.0161 - accuracy: 0.8779 - precision: 0.5067 - recall: 0.9284 - auc: 0.9582 - f1_score: 0.6556 - val_loss: 0.0355 - val_accuracy: 0.8548 - val_precision: 0.4593 - val_recall: 0.8393 - val_auc: 0.9243 - val_f1_score: 0.5937\n","Epoch 65/300\n","483/483 [==============================] - 32s 66ms/step - loss: 0.0160 - accuracy: 0.8773 - precision: 0.5055 - recall: 0.9253 - auc: 0.9583 - f1_score: 0.6538 - val_loss: 0.0323 - val_accuracy: 0.8688 - val_precision: 0.4885 - val_recall: 0.7998 - val_auc: 0.9265 - val_f1_score: 0.6065\n","Epoch 66/300\n","483/483 [==============================] - 32s 66ms/step - loss: 0.0160 - accuracy: 0.8783 - precision: 0.5076 - recall: 0.9263 - auc: 0.9584 - f1_score: 0.6558 - val_loss: 0.0282 - val_accuracy: 0.8524 - val_precision: 0.4547 - val_recall: 0.8418 - val_auc: 0.9253 - val_f1_score: 0.5904\n","Epoch 67/300\n","483/483 [==============================] - 32s 66ms/step - loss: 0.0162 - accuracy: 0.8760 - precision: 0.5027 - recall: 0.9257 - auc: 0.9575 - f1_score: 0.6516 - val_loss: 0.0305 - val_accuracy: 0.8512 - val_precision: 0.4531 - val_recall: 0.8557 - val_auc: 0.9289 - val_f1_score: 0.5925\n","Epoch 68/300\n","483/483 [==============================] - 32s 66ms/step - loss: 0.0159 - accuracy: 0.8790 - precision: 0.5092 - recall: 0.9290 - auc: 0.9591 - f1_score: 0.6579 - val_loss: 0.0302 - val_accuracy: 0.8616 - val_precision: 0.4733 - val_recall: 0.8403 - val_auc: 0.9293 - val_f1_score: 0.6055\n","Epoch 69/300\n","483/483 [==============================] - 32s 67ms/step - loss: 0.0159 - accuracy: 0.8806 - precision: 0.5129 - recall: 0.9268 - auc: 0.9593 - f1_score: 0.6603 - val_loss: 0.0276 - val_accuracy: 0.8399 - val_precision: 0.4333 - val_recall: 0.8657 - val_auc: 0.9236 - val_f1_score: 0.5776\n","Epoch 70/300\n","483/483 [==============================] - 32s 66ms/step - loss: 0.0157 - accuracy: 0.8790 - precision: 0.5091 - recall: 0.9309 - auc: 0.9598 - f1_score: 0.6583 - val_loss: 0.0361 - val_accuracy: 0.8681 - val_precision: 0.4870 - val_recall: 0.8149 - val_auc: 0.9291 - val_f1_score: 0.6096\n","Epoch 71/300\n","483/483 [==============================] - 33s 68ms/step - loss: 0.0157 - accuracy: 0.8807 - precision: 0.5130 - recall: 0.9331 - auc: 0.9602 - f1_score: 0.6621 - val_loss: 0.0336 - val_accuracy: 0.8592 - val_precision: 0.4682 - val_recall: 0.8411 - val_auc: 0.9264 - val_f1_score: 0.6016\n","Epoch 72/300\n","483/483 [==============================] - 32s 67ms/step - loss: 0.0156 - accuracy: 0.8802 - precision: 0.5119 - recall: 0.9305 - auc: 0.9602 - f1_score: 0.6605 - val_loss: 0.0305 - val_accuracy: 0.8533 - val_precision: 0.4570 - val_recall: 0.8523 - val_auc: 0.9285 - val_f1_score: 0.5950\n","Epoch 73/300\n","483/483 [==============================] - 32s 67ms/step - loss: 0.0157 - accuracy: 0.8809 - precision: 0.5135 - recall: 0.9288 - auc: 0.9601 - f1_score: 0.6614 - val_loss: 0.0360 - val_accuracy: 0.8629 - val_precision: 0.4754 - val_recall: 0.8213 - val_auc: 0.9264 - val_f1_score: 0.6023\n","Epoch 74/300\n","483/483 [==============================] - 32s 67ms/step - loss: 0.0155 - accuracy: 0.8830 - precision: 0.5183 - recall: 0.9327 - auc: 0.9609 - f1_score: 0.6663 - val_loss: 0.0358 - val_accuracy: 0.8673 - val_precision: 0.4853 - val_recall: 0.8272 - val_auc: 0.9286 - val_f1_score: 0.6118\n","Epoch 75/300\n","483/483 [==============================] - 32s 66ms/step - loss: 0.0154 - accuracy: 0.8814 - precision: 0.5145 - recall: 0.9341 - auc: 0.9611 - f1_score: 0.6635 - val_loss: 0.0318 - val_accuracy: 0.8608 - val_precision: 0.4714 - val_recall: 0.8331 - val_auc: 0.9264 - val_f1_score: 0.6021\n","Epoch 76/300\n","483/483 [==============================] - 33s 69ms/step - loss: 0.0154 - accuracy: 0.8832 - precision: 0.5187 - recall: 0.9326 - auc: 0.9616 - f1_score: 0.6667 - val_loss: 0.0345 - val_accuracy: 0.8683 - val_precision: 0.4875 - val_recall: 0.8167 - val_auc: 0.9274 - val_f1_score: 0.6106\n","Epoch 77/300\n","483/483 [==============================] - 33s 69ms/step - loss: 0.0154 - accuracy: 0.8827 - precision: 0.5175 - recall: 0.9328 - auc: 0.9617 - f1_score: 0.6657 - val_loss: 0.0354 - val_accuracy: 0.8607 - val_precision: 0.4711 - val_recall: 0.8308 - val_auc: 0.9274 - val_f1_score: 0.6012\n","Epoch 78/300\n","483/483 [==============================] - 33s 68ms/step - loss: 0.0152 - accuracy: 0.8853 - precision: 0.5235 - recall: 0.9348 - auc: 0.9623 - f1_score: 0.6712 - val_loss: 0.0316 - val_accuracy: 0.8622 - val_precision: 0.4735 - val_recall: 0.8049 - val_auc: 0.9244 - val_f1_score: 0.5963\n","Epoch 79/300\n","483/483 [==============================] - 33s 68ms/step - loss: 0.0152 - accuracy: 0.8851 - precision: 0.5232 - recall: 0.9323 - auc: 0.9625 - f1_score: 0.6703 - val_loss: 0.0333 - val_accuracy: 0.8706 - val_precision: 0.4929 - val_recall: 0.8111 - val_auc: 0.9285 - val_f1_score: 0.6132\n","Epoch 80/300\n","483/483 [==============================] - 33s 68ms/step - loss: 0.0150 - accuracy: 0.8866 - precision: 0.5265 - recall: 0.9355 - auc: 0.9632 - f1_score: 0.6738 - val_loss: 0.0363 - val_accuracy: 0.8649 - val_precision: 0.4798 - val_recall: 0.8208 - val_auc: 0.9262 - val_f1_score: 0.6056\n","Epoch 81/300\n","483/483 [==============================] - 33s 68ms/step - loss: 0.0152 - accuracy: 0.8850 - precision: 0.5229 - recall: 0.9343 - auc: 0.9628 - f1_score: 0.6705 - val_loss: 0.0330 - val_accuracy: 0.8676 - val_precision: 0.4858 - val_recall: 0.8162 - val_auc: 0.9286 - val_f1_score: 0.6091\n","Epoch 82/300\n","483/483 [==============================] - 33s 68ms/step - loss: 0.0149 - accuracy: 0.8864 - precision: 0.5260 - recall: 0.9341 - auc: 0.9636 - f1_score: 0.6730 - val_loss: 0.0353 - val_accuracy: 0.8735 - val_precision: 0.4998 - val_recall: 0.8090 - val_auc: 0.9286 - val_f1_score: 0.6179\n","Epoch 83/300\n","483/483 [==============================] - 32s 67ms/step - loss: 0.0150 - accuracy: 0.8855 - precision: 0.5240 - recall: 0.9366 - auc: 0.9634 - f1_score: 0.6720 - val_loss: 0.0387 - val_accuracy: 0.8809 - val_precision: 0.5192 - val_recall: 0.7767 - val_auc: 0.9269 - val_f1_score: 0.6224\n","Epoch 84/300\n","483/483 [==============================] - 33s 68ms/step - loss: 0.0149 - accuracy: 0.8871 - precision: 0.5276 - recall: 0.9382 - auc: 0.9638 - f1_score: 0.6754 - val_loss: 0.0365 - val_accuracy: 0.8737 - val_precision: 0.5002 - val_recall: 0.7908 - val_auc: 0.9238 - val_f1_score: 0.6128\n","Epoch 85/300\n","483/483 [==============================] - 32s 67ms/step - loss: 0.0149 - accuracy: 0.8884 - precision: 0.5308 - recall: 0.9368 - auc: 0.9640 - f1_score: 0.6776 - val_loss: 0.0340 - val_accuracy: 0.8651 - val_precision: 0.4804 - val_recall: 0.8213 - val_auc: 0.9260 - val_f1_score: 0.6062\n","Epoch 86/300\n","483/483 [==============================] - 32s 67ms/step - loss: 0.0148 - accuracy: 0.8872 - precision: 0.5278 - recall: 0.9372 - auc: 0.9643 - f1_score: 0.6753 - val_loss: 0.0411 - val_accuracy: 0.8703 - val_precision: 0.4921 - val_recall: 0.8095 - val_auc: 0.9251 - val_f1_score: 0.6121\n","Epoch 87/300\n","483/483 [==============================] - 32s 67ms/step - loss: 0.0147 - accuracy: 0.8882 - precision: 0.5304 - recall: 0.9378 - auc: 0.9648 - f1_score: 0.6776 - val_loss: 0.0356 - val_accuracy: 0.8599 - val_precision: 0.4696 - val_recall: 0.8385 - val_auc: 0.9266 - val_f1_score: 0.6021\n","Epoch 88/300\n","483/483 [==============================] - 32s 67ms/step - loss: 0.0146 - accuracy: 0.8901 - precision: 0.5347 - recall: 0.9411 - auc: 0.9652 - f1_score: 0.6820 - val_loss: 0.0355 - val_accuracy: 0.8634 - val_precision: 0.4768 - val_recall: 0.8267 - val_auc: 0.9273 - val_f1_score: 0.6048\n","Epoch 89/300\n","483/483 [==============================] - 32s 67ms/step - loss: 0.0146 - accuracy: 0.8896 - precision: 0.5335 - recall: 0.9407 - auc: 0.9652 - f1_score: 0.6809 - val_loss: 0.0347 - val_accuracy: 0.8645 - val_precision: 0.4791 - val_recall: 0.8257 - val_auc: 0.9251 - val_f1_score: 0.6064\n","Epoch 90/300\n","483/483 [==============================] - 32s 67ms/step - loss: 0.0148 - accuracy: 0.8898 - precision: 0.5340 - recall: 0.9388 - auc: 0.9646 - f1_score: 0.6808 - val_loss: 0.0403 - val_accuracy: 0.8727 - val_precision: 0.4977 - val_recall: 0.7895 - val_auc: 0.9255 - val_f1_score: 0.6106\n","Epoch 91/300\n","483/483 [==============================] - 32s 67ms/step - loss: 0.0148 - accuracy: 0.8861 - precision: 0.5253 - recall: 0.9384 - auc: 0.9644 - f1_score: 0.6735 - val_loss: 0.0302 - val_accuracy: 0.8447 - val_precision: 0.4417 - val_recall: 0.8664 - val_auc: 0.9241 - val_f1_score: 0.5851\n","Epoch 92/300\n","483/483 [==============================] - 32s 67ms/step - loss: 0.0145 - accuracy: 0.8907 - precision: 0.5362 - recall: 0.9409 - auc: 0.9657 - f1_score: 0.6832 - val_loss: 0.0374 - val_accuracy: 0.8656 - val_precision: 0.4811 - val_recall: 0.8111 - val_auc: 0.9245 - val_f1_score: 0.6040\n","Epoch 93/300\n","483/483 [==============================] - 33s 67ms/step - loss: 0.0149 - accuracy: 0.8869 - precision: 0.5272 - recall: 0.9357 - auc: 0.9639 - f1_score: 0.6744 - val_loss: 0.0325 - val_accuracy: 0.8619 - val_precision: 0.4738 - val_recall: 0.8375 - val_auc: 0.9278 - val_f1_score: 0.6052\n","Epoch 94/300\n","483/483 [==============================] - 32s 67ms/step - loss: 0.0143 - accuracy: 0.8931 - precision: 0.5420 - recall: 0.9420 - auc: 0.9670 - f1_score: 0.6881 - val_loss: 0.0330 - val_accuracy: 0.8605 - val_precision: 0.4708 - val_recall: 0.8377 - val_auc: 0.9265 - val_f1_score: 0.6028\n","Epoch 95/300\n","483/483 [==============================] - 33s 68ms/step - loss: 0.0145 - accuracy: 0.8915 - precision: 0.5383 - recall: 0.9403 - auc: 0.9658 - f1_score: 0.6846 - val_loss: 0.0311 - val_accuracy: 0.8772 - val_precision: 0.5092 - val_recall: 0.7790 - val_auc: 0.9273 - val_f1_score: 0.6159\n","Epoch 96/300\n","483/483 [==============================] - 33s 68ms/step - loss: 0.0143 - accuracy: 0.8929 - precision: 0.5416 - recall: 0.9409 - auc: 0.9665 - f1_score: 0.6875 - val_loss: 0.0347 - val_accuracy: 0.8730 - val_precision: 0.4985 - val_recall: 0.7972 - val_auc: 0.9271 - val_f1_score: 0.6134\n","Epoch 97/300\n","483/483 [==============================] - 33s 68ms/step - loss: 0.0143 - accuracy: 0.8919 - precision: 0.5390 - recall: 0.9426 - auc: 0.9662 - f1_score: 0.6858 - val_loss: 0.0336 - val_accuracy: 0.8582 - val_precision: 0.4656 - val_recall: 0.8241 - val_auc: 0.9246 - val_f1_score: 0.5950\n","Epoch 98/300\n","483/483 [==============================] - 32s 67ms/step - loss: 0.0143 - accuracy: 0.8922 - precision: 0.5397 - recall: 0.9425 - auc: 0.9670 - f1_score: 0.6864 - val_loss: 0.0316 - val_accuracy: 0.8626 - val_precision: 0.4750 - val_recall: 0.8254 - val_auc: 0.9265 - val_f1_score: 0.6030\n","Epoch 99/300\n","483/483 [==============================] - 32s 67ms/step - loss: 0.0142 - accuracy: 0.8945 - precision: 0.5457 - recall: 0.9398 - auc: 0.9669 - f1_score: 0.6905 - val_loss: 0.0385 - val_accuracy: 0.8725 - val_precision: 0.4974 - val_recall: 0.7954 - val_auc: 0.9259 - val_f1_score: 0.6120\n","Epoch 100/300\n","483/483 [==============================] - 33s 67ms/step - loss: 0.0142 - accuracy: 0.8945 - precision: 0.5456 - recall: 0.9418 - auc: 0.9672 - f1_score: 0.6909 - val_loss: 0.0372 - val_accuracy: 0.8740 - val_precision: 0.5009 - val_recall: 0.8067 - val_auc: 0.9260 - val_f1_score: 0.6180\n","Epoch 101/300\n","483/483 [==============================] - 33s 68ms/step - loss: 0.0141 - accuracy: 0.8950 - precision: 0.5467 - recall: 0.9440 - auc: 0.9680 - f1_score: 0.6924 - val_loss: 0.0304 - val_accuracy: 0.8622 - val_precision: 0.4741 - val_recall: 0.8254 - val_auc: 0.9267 - val_f1_score: 0.6023\n","Epoch 102/300\n","483/483 [==============================] - 33s 68ms/step - loss: 0.0140 - accuracy: 0.8967 - precision: 0.5510 - recall: 0.9443 - auc: 0.9682 - f1_score: 0.6960 - val_loss: 0.0392 - val_accuracy: 0.8747 - val_precision: 0.5027 - val_recall: 0.7944 - val_auc: 0.9255 - val_f1_score: 0.6157\n","Epoch 103/300\n","483/483 [==============================] - 32s 67ms/step - loss: 0.0140 - accuracy: 0.8940 - precision: 0.5443 - recall: 0.9425 - auc: 0.9680 - f1_score: 0.6901 - val_loss: 0.0373 - val_accuracy: 0.8705 - val_precision: 0.4925 - val_recall: 0.8052 - val_auc: 0.9267 - val_f1_score: 0.6111\n","Epoch 104/300\n","483/483 [==============================] - 33s 68ms/step - loss: 0.0139 - accuracy: 0.8943 - precision: 0.5450 - recall: 0.9442 - auc: 0.9682 - f1_score: 0.6911 - val_loss: 0.0354 - val_accuracy: 0.8617 - val_precision: 0.4733 - val_recall: 0.8326 - val_auc: 0.9254 - val_f1_score: 0.6035\n","Epoch 105/300\n","483/483 [==============================] - 33s 68ms/step - loss: 0.0141 - accuracy: 0.8947 - precision: 0.5459 - recall: 0.9436 - auc: 0.9678 - f1_score: 0.6917 - val_loss: 0.0364 - val_accuracy: 0.8712 - val_precision: 0.4940 - val_recall: 0.7942 - val_auc: 0.9249 - val_f1_score: 0.6091\n","Epoch 106/300\n","483/483 [==============================] - 33s 67ms/step - loss: 0.0137 - accuracy: 0.8969 - precision: 0.5515 - recall: 0.9451 - auc: 0.9691 - f1_score: 0.6966 - val_loss: 0.0422 - val_accuracy: 0.8709 - val_precision: 0.4933 - val_recall: 0.7983 - val_auc: 0.9259 - val_f1_score: 0.6098\n","Epoch 107/300\n","483/483 [==============================] - 33s 68ms/step - loss: 0.0140 - accuracy: 0.8960 - precision: 0.5492 - recall: 0.9441 - auc: 0.9685 - f1_score: 0.6944 - val_loss: 0.0375 - val_accuracy: 0.8732 - val_precision: 0.4991 - val_recall: 0.7865 - val_auc: 0.9242 - val_f1_score: 0.6107\n","Epoch 108/300\n","483/483 [==============================] - 33s 68ms/step - loss: 0.0139 - accuracy: 0.8953 - precision: 0.5476 - recall: 0.9440 - auc: 0.9685 - f1_score: 0.6931 - val_loss: 0.0373 - val_accuracy: 0.8661 - val_precision: 0.4822 - val_recall: 0.8039 - val_auc: 0.9250 - val_f1_score: 0.6028\n","Epoch 109/300\n","483/483 [==============================] - 33s 68ms/step - loss: 0.0138 - accuracy: 0.8973 - precision: 0.5525 - recall: 0.9440 - auc: 0.9694 - f1_score: 0.6971 - val_loss: 0.0374 - val_accuracy: 0.8739 - val_precision: 0.5006 - val_recall: 0.8013 - val_auc: 0.9278 - val_f1_score: 0.6163\n","Epoch 110/300\n","483/483 [==============================] - 33s 68ms/step - loss: 0.0136 - accuracy: 0.9004 - precision: 0.5607 - recall: 0.9456 - auc: 0.9703 - f1_score: 0.7039 - val_loss: 0.0412 - val_accuracy: 0.8810 - val_precision: 0.5198 - val_recall: 0.7678 - val_auc: 0.9264 - val_f1_score: 0.6199\n","Epoch 111/300\n","483/483 [==============================] - 33s 67ms/step - loss: 0.0137 - accuracy: 0.8992 - precision: 0.5577 - recall: 0.9447 - auc: 0.9697 - f1_score: 0.7013 - val_loss: 0.0360 - val_accuracy: 0.8713 - val_precision: 0.4944 - val_recall: 0.7939 - val_auc: 0.9272 - val_f1_score: 0.6093\n","Epoch 112/300\n","483/483 [==============================] - 33s 68ms/step - loss: 0.0135 - accuracy: 0.9001 - precision: 0.5598 - recall: 0.9450 - auc: 0.9703 - f1_score: 0.7031 - val_loss: 0.0339 - val_accuracy: 0.8692 - val_precision: 0.4894 - val_recall: 0.8095 - val_auc: 0.9263 - val_f1_score: 0.6100\n","Epoch 113/300\n","483/483 [==============================] - 33s 68ms/step - loss: 0.0135 - accuracy: 0.8986 - precision: 0.5557 - recall: 0.9475 - auc: 0.9702 - f1_score: 0.7005 - val_loss: 0.0427 - val_accuracy: 0.8764 - val_precision: 0.5073 - val_recall: 0.7888 - val_auc: 0.9260 - val_f1_score: 0.6174\n","Epoch 114/300\n","483/483 [==============================] - 33s 68ms/step - loss: 0.0135 - accuracy: 0.9007 - precision: 0.5615 - recall: 0.9447 - auc: 0.9707 - f1_score: 0.7044 - val_loss: 0.0388 - val_accuracy: 0.8790 - val_precision: 0.5140 - val_recall: 0.7839 - val_auc: 0.9281 - val_f1_score: 0.6209\n","Epoch 115/300\n","483/483 [==============================] - 33s 67ms/step - loss: 0.0135 - accuracy: 0.9001 - precision: 0.5601 - recall: 0.9436 - auc: 0.9707 - f1_score: 0.7029 - val_loss: 0.0396 - val_accuracy: 0.8765 - val_precision: 0.5074 - val_recall: 0.7972 - val_auc: 0.9264 - val_f1_score: 0.6201\n","Epoch 116/300\n","483/483 [==============================] - 32s 67ms/step - loss: 0.0135 - accuracy: 0.8996 - precision: 0.5583 - recall: 0.9477 - auc: 0.9702 - f1_score: 0.7026 - val_loss: 0.0442 - val_accuracy: 0.8810 - val_precision: 0.5201 - val_recall: 0.7611 - val_auc: 0.9242 - val_f1_score: 0.6180\n","Epoch 117/300\n","483/483 [==============================] - 33s 67ms/step - loss: 0.0132 - accuracy: 0.9029 - precision: 0.5672 - recall: 0.9463 - auc: 0.9717 - f1_score: 0.7093 - val_loss: 0.0357 - val_accuracy: 0.8693 - val_precision: 0.4897 - val_recall: 0.8129 - val_auc: 0.9269 - val_f1_score: 0.6112\n","Epoch 118/300\n","483/483 [==============================] - 33s 68ms/step - loss: 0.0133 - accuracy: 0.9012 - precision: 0.5624 - recall: 0.9484 - auc: 0.9713 - f1_score: 0.7061 - val_loss: 0.0379 - val_accuracy: 0.8706 - val_precision: 0.4928 - val_recall: 0.8149 - val_auc: 0.9269 - val_f1_score: 0.6142\n","Epoch 119/300\n","483/483 [==============================] - 33s 68ms/step - loss: 0.0134 - accuracy: 0.9021 - precision: 0.5652 - recall: 0.9469 - auc: 0.9710 - f1_score: 0.7079 - val_loss: 0.0361 - val_accuracy: 0.8725 - val_precision: 0.4973 - val_recall: 0.7998 - val_auc: 0.9257 - val_f1_score: 0.6133\n","Epoch 120/300\n","483/483 [==============================] - 33s 67ms/step - loss: 0.0132 - accuracy: 0.9030 - precision: 0.5672 - recall: 0.9485 - auc: 0.9717 - f1_score: 0.7099 - val_loss: 0.0416 - val_accuracy: 0.8655 - val_precision: 0.4808 - val_recall: 0.8026 - val_auc: 0.9226 - val_f1_score: 0.6014\n","Epoch 121/300\n","483/483 [==============================] - 33s 69ms/step - loss: 0.0134 - accuracy: 0.8985 - precision: 0.5554 - recall: 0.9483 - auc: 0.9710 - f1_score: 0.7005 - val_loss: 0.0379 - val_accuracy: 0.8786 - val_precision: 0.5133 - val_recall: 0.7644 - val_auc: 0.9255 - val_f1_score: 0.6141\n","Epoch 122/300\n","483/483 [==============================] - 33s 69ms/step - loss: 0.0132 - accuracy: 0.9040 - precision: 0.5704 - recall: 0.9468 - auc: 0.9718 - f1_score: 0.7119 - val_loss: 0.0415 - val_accuracy: 0.8783 - val_precision: 0.5124 - val_recall: 0.7662 - val_auc: 0.9232 - val_f1_score: 0.6141\n","Epoch 123/300\n","483/483 [==============================] - 34s 70ms/step - loss: 0.0130 - accuracy: 0.9042 - precision: 0.5706 - recall: 0.9492 - auc: 0.9726 - f1_score: 0.7127 - val_loss: 0.0428 - val_accuracy: 0.8765 - val_precision: 0.5077 - val_recall: 0.7475 - val_auc: 0.9192 - val_f1_score: 0.6047\n","Epoch 124/300\n","483/483 [==============================] - 33s 69ms/step - loss: 0.0132 - accuracy: 0.9033 - precision: 0.5681 - recall: 0.9480 - auc: 0.9718 - f1_score: 0.7105 - val_loss: 0.0376 - val_accuracy: 0.8746 - val_precision: 0.5026 - val_recall: 0.7990 - val_auc: 0.9251 - val_f1_score: 0.6170\n","Epoch 125/300\n","483/483 [==============================] - 33s 68ms/step - loss: 0.0131 - accuracy: 0.9032 - precision: 0.5680 - recall: 0.9473 - auc: 0.9721 - f1_score: 0.7102 - val_loss: 0.0392 - val_accuracy: 0.8750 - val_precision: 0.5035 - val_recall: 0.7821 - val_auc: 0.9248 - val_f1_score: 0.6127\n","Epoch 126/300\n","483/483 [==============================] - 33s 69ms/step - loss: 0.0132 - accuracy: 0.9011 - precision: 0.5622 - recall: 0.9504 - auc: 0.9714 - f1_score: 0.7065 - val_loss: 0.0398 - val_accuracy: 0.8766 - val_precision: 0.5077 - val_recall: 0.7783 - val_auc: 0.9259 - val_f1_score: 0.6145\n","Epoch 127/300\n","483/483 [==============================] - 33s 69ms/step - loss: 0.0133 - accuracy: 0.9036 - precision: 0.5689 - recall: 0.9486 - auc: 0.9717 - f1_score: 0.7112 - val_loss: 0.0362 - val_accuracy: 0.8696 - val_precision: 0.4904 - val_recall: 0.7977 - val_auc: 0.9243 - val_f1_score: 0.6074\n","Epoch 128/300\n","483/483 [==============================] - 33s 68ms/step - loss: 0.0130 - accuracy: 0.9040 - precision: 0.5701 - recall: 0.9475 - auc: 0.9724 - f1_score: 0.7119 - val_loss: 0.0374 - val_accuracy: 0.8726 - val_precision: 0.4976 - val_recall: 0.7944 - val_auc: 0.9256 - val_f1_score: 0.6119\n","Epoch 129/300\n","483/483 [==============================] - 33s 69ms/step - loss: 0.0133 - accuracy: 0.9026 - precision: 0.5663 - recall: 0.9473 - auc: 0.9716 - f1_score: 0.7089 - val_loss: 0.0360 - val_accuracy: 0.8696 - val_precision: 0.4904 - val_recall: 0.7947 - val_auc: 0.9246 - val_f1_score: 0.6065\n","Epoch 130/300\n","483/483 [==============================] - 33s 69ms/step - loss: 0.0129 - accuracy: 0.9049 - precision: 0.5725 - recall: 0.9504 - auc: 0.9729 - f1_score: 0.7146 - val_loss: 0.0402 - val_accuracy: 0.8704 - val_precision: 0.4921 - val_recall: 0.7929 - val_auc: 0.9234 - val_f1_score: 0.6073\n","Epoch 131/300\n","483/483 [==============================] - 33s 69ms/step - loss: 0.0128 - accuracy: 0.9068 - precision: 0.5778 - recall: 0.9485 - auc: 0.9733 - f1_score: 0.7181 - val_loss: 0.0366 - val_accuracy: 0.8663 - val_precision: 0.4830 - val_recall: 0.8154 - val_auc: 0.9274 - val_f1_score: 0.6067\n","Epoch 132/300\n","483/483 [==============================] - 33s 69ms/step - loss: 0.0129 - accuracy: 0.9058 - precision: 0.5751 - recall: 0.9491 - auc: 0.9731 - f1_score: 0.7162 - val_loss: 0.0414 - val_accuracy: 0.8749 - val_precision: 0.5033 - val_recall: 0.7934 - val_auc: 0.9249 - val_f1_score: 0.6159\n","Epoch 133/300\n","483/483 [==============================] - 33s 68ms/step - loss: 0.0128 - accuracy: 0.9069 - precision: 0.5779 - recall: 0.9518 - auc: 0.9737 - f1_score: 0.7192 - val_loss: 0.0438 - val_accuracy: 0.8762 - val_precision: 0.5068 - val_recall: 0.7703 - val_auc: 0.9234 - val_f1_score: 0.6114\n","Epoch 134/300\n","483/483 [==============================] - 33s 69ms/step - loss: 0.0130 - accuracy: 0.9047 - precision: 0.5720 - recall: 0.9497 - auc: 0.9729 - f1_score: 0.7140 - val_loss: 0.0350 - val_accuracy: 0.8691 - val_precision: 0.4892 - val_recall: 0.8042 - val_auc: 0.9244 - val_f1_score: 0.6083\n","Epoch 135/300\n","483/483 [==============================] - 33s 69ms/step - loss: 0.0129 - accuracy: 0.9063 - precision: 0.5763 - recall: 0.9492 - auc: 0.9733 - f1_score: 0.7172 - val_loss: 0.0360 - val_accuracy: 0.8649 - val_precision: 0.4795 - val_recall: 0.8059 - val_auc: 0.9247 - val_f1_score: 0.6013\n","Epoch 136/300\n","483/483 [==============================] - 33s 69ms/step - loss: 0.0127 - accuracy: 0.9073 - precision: 0.5789 - recall: 0.9508 - auc: 0.9740 - f1_score: 0.7197 - val_loss: 0.0386 - val_accuracy: 0.8782 - val_precision: 0.5120 - val_recall: 0.7747 - val_auc: 0.9270 - val_f1_score: 0.6165\n","Epoch 137/300\n","483/483 [==============================] - 33s 69ms/step - loss: 0.0127 - accuracy: 0.9083 - precision: 0.5822 - recall: 0.9486 - auc: 0.9743 - f1_score: 0.7216 - val_loss: 0.0398 - val_accuracy: 0.8732 - val_precision: 0.4989 - val_recall: 0.7854 - val_auc: 0.9238 - val_f1_score: 0.6102\n","Epoch 138/300\n","483/483 [==============================] - 33s 69ms/step - loss: 0.0126 - accuracy: 0.9079 - precision: 0.5809 - recall: 0.9490 - auc: 0.9744 - f1_score: 0.7207 - val_loss: 0.0382 - val_accuracy: 0.8756 - val_precision: 0.5052 - val_recall: 0.7795 - val_auc: 0.9253 - val_f1_score: 0.6131\n","Epoch 139/300\n","483/483 [==============================] - 34s 70ms/step - loss: 0.0127 - accuracy: 0.9068 - precision: 0.5777 - recall: 0.9515 - auc: 0.9740 - f1_score: 0.7189 - val_loss: 0.0368 - val_accuracy: 0.8780 - val_precision: 0.5115 - val_recall: 0.7785 - val_auc: 0.9266 - val_f1_score: 0.6174\n","Epoch 140/300\n","483/483 [==============================] - 34s 70ms/step - loss: 0.0125 - accuracy: 0.9099 - precision: 0.5865 - recall: 0.9501 - auc: 0.9747 - f1_score: 0.7253 - val_loss: 0.0431 - val_accuracy: 0.8742 - val_precision: 0.5015 - val_recall: 0.7844 - val_auc: 0.9233 - val_f1_score: 0.6118\n","Epoch 141/300\n","483/483 [==============================] - 34s 70ms/step - loss: 0.0125 - accuracy: 0.9081 - precision: 0.5813 - recall: 0.9513 - auc: 0.9746 - f1_score: 0.7217 - val_loss: 0.0386 - val_accuracy: 0.8705 - val_precision: 0.4924 - val_recall: 0.7957 - val_auc: 0.9245 - val_f1_score: 0.6083\n","Epoch 142/300\n","483/483 [==============================] - 34s 70ms/step - loss: 0.0128 - accuracy: 0.9075 - precision: 0.5798 - recall: 0.9488 - auc: 0.9740 - f1_score: 0.7198 - val_loss: 0.0476 - val_accuracy: 0.8867 - val_precision: 0.5375 - val_recall: 0.7396 - val_auc: 0.9268 - val_f1_score: 0.6226\n","Epoch 143/300\n","483/483 [==============================] - 34s 71ms/step - loss: 0.0123 - accuracy: 0.9105 - precision: 0.5879 - recall: 0.9535 - auc: 0.9754 - f1_score: 0.7273 - val_loss: 0.0423 - val_accuracy: 0.8743 - val_precision: 0.5018 - val_recall: 0.7842 - val_auc: 0.9248 - val_f1_score: 0.6120\n","Epoch 144/300\n","483/483 [==============================] - 34s 71ms/step - loss: 0.0124 - accuracy: 0.9102 - precision: 0.5874 - recall: 0.9511 - auc: 0.9750 - f1_score: 0.7263 - val_loss: 0.0421 - val_accuracy: 0.8832 - val_precision: 0.5265 - val_recall: 0.7549 - val_auc: 0.9248 - val_f1_score: 0.6203\n","Epoch 145/300\n","483/483 [==============================] - 34s 70ms/step - loss: 0.0125 - accuracy: 0.9098 - precision: 0.5864 - recall: 0.9486 - auc: 0.9746 - f1_score: 0.7248 - val_loss: 0.0482 - val_accuracy: 0.8845 - val_precision: 0.5308 - val_recall: 0.7416 - val_auc: 0.9224 - val_f1_score: 0.6188\n","Epoch 146/300\n","483/483 [==============================] - 34s 70ms/step - loss: 0.0126 - accuracy: 0.9081 - precision: 0.5816 - recall: 0.9495 - auc: 0.9742 - f1_score: 0.7213 - val_loss: 0.0387 - val_accuracy: 0.8672 - val_precision: 0.4846 - val_recall: 0.7965 - val_auc: 0.9231 - val_f1_score: 0.6026\n","Epoch 147/300\n","483/483 [==============================] - 34s 70ms/step - loss: 0.0127 - accuracy: 0.9090 - precision: 0.5839 - recall: 0.9510 - auc: 0.9744 - f1_score: 0.7236 - val_loss: 0.0366 - val_accuracy: 0.8723 - val_precision: 0.4967 - val_recall: 0.7990 - val_auc: 0.9265 - val_f1_score: 0.6126\n","Epoch 148/300\n","483/483 [==============================] - 33s 69ms/step - loss: 0.0123 - accuracy: 0.9115 - precision: 0.5910 - recall: 0.9513 - auc: 0.9755 - f1_score: 0.7290 - val_loss: 0.0379 - val_accuracy: 0.8740 - val_precision: 0.5010 - val_recall: 0.7803 - val_auc: 0.9243 - val_f1_score: 0.6102\n","Epoch 149/300\n","483/483 [==============================] - 33s 69ms/step - loss: 0.0123 - accuracy: 0.9113 - precision: 0.5901 - recall: 0.9540 - auc: 0.9757 - f1_score: 0.7292 - val_loss: 0.0480 - val_accuracy: 0.8796 - val_precision: 0.5159 - val_recall: 0.7690 - val_auc: 0.9236 - val_f1_score: 0.6175\n","Epoch 150/300\n","483/483 [==============================] - 34s 69ms/step - loss: 0.0124 - accuracy: 0.9100 - precision: 0.5868 - recall: 0.9498 - auc: 0.9754 - f1_score: 0.7255 - val_loss: 0.0446 - val_accuracy: 0.8780 - val_precision: 0.5113 - val_recall: 0.7826 - val_auc: 0.9255 - val_f1_score: 0.6185\n","Epoch 151/300\n","483/483 [==============================] - 34s 69ms/step - loss: 0.0124 - accuracy: 0.9096 - precision: 0.5855 - recall: 0.9512 - auc: 0.9753 - f1_score: 0.7248 - val_loss: 0.0403 - val_accuracy: 0.8793 - val_precision: 0.5149 - val_recall: 0.7785 - val_auc: 0.9244 - val_f1_score: 0.6199\n","Epoch 152/300\n","483/483 [==============================] - 34s 70ms/step - loss: 0.0123 - accuracy: 0.9125 - precision: 0.5937 - recall: 0.9541 - auc: 0.9759 - f1_score: 0.7320 - val_loss: 0.0432 - val_accuracy: 0.8709 - val_precision: 0.4932 - val_recall: 0.7770 - val_auc: 0.9236 - val_f1_score: 0.6034\n","Epoch 153/300\n","483/483 [==============================] - 34s 69ms/step - loss: 0.0122 - accuracy: 0.9121 - precision: 0.5927 - recall: 0.9518 - auc: 0.9758 - f1_score: 0.7305 - val_loss: 0.0419 - val_accuracy: 0.8864 - val_precision: 0.5352 - val_recall: 0.7690 - val_auc: 0.9276 - val_f1_score: 0.6312\n","Epoch 154/300\n","483/483 [==============================] - 33s 69ms/step - loss: 0.0120 - accuracy: 0.9143 - precision: 0.5994 - recall: 0.9517 - auc: 0.9770 - f1_score: 0.7356 - val_loss: 0.0430 - val_accuracy: 0.8823 - val_precision: 0.5233 - val_recall: 0.7729 - val_auc: 0.9253 - val_f1_score: 0.6241\n","Epoch 155/300\n","483/483 [==============================] - 34s 70ms/step - loss: 0.0121 - accuracy: 0.9129 - precision: 0.5952 - recall: 0.9522 - auc: 0.9763 - f1_score: 0.7325 - val_loss: 0.0396 - val_accuracy: 0.8751 - val_precision: 0.5037 - val_recall: 0.7821 - val_auc: 0.9242 - val_f1_score: 0.6128\n","Epoch 156/300\n","483/483 [==============================] - 33s 69ms/step - loss: 0.0123 - accuracy: 0.9109 - precision: 0.5894 - recall: 0.9501 - auc: 0.9757 - f1_score: 0.7275 - val_loss: 0.0428 - val_accuracy: 0.8826 - val_precision: 0.5248 - val_recall: 0.7542 - val_auc: 0.9255 - val_f1_score: 0.6189\n","Epoch 157/300\n","483/483 [==============================] - 33s 69ms/step - loss: 0.0121 - accuracy: 0.9136 - precision: 0.5972 - recall: 0.9530 - auc: 0.9768 - f1_score: 0.7343 - val_loss: 0.0407 - val_accuracy: 0.8745 - val_precision: 0.5023 - val_recall: 0.7877 - val_auc: 0.9255 - val_f1_score: 0.6134\n","Epoch 158/300\n","483/483 [==============================] - 34s 70ms/step - loss: 0.0121 - accuracy: 0.9120 - precision: 0.5925 - recall: 0.9519 - auc: 0.9762 - f1_score: 0.7304 - val_loss: 0.0443 - val_accuracy: 0.8845 - val_precision: 0.5314 - val_recall: 0.7311 - val_auc: 0.9240 - val_f1_score: 0.6155\n","Epoch 159/300\n","483/483 [==============================] - 34s 71ms/step - loss: 0.0122 - accuracy: 0.9107 - precision: 0.5885 - recall: 0.9546 - auc: 0.9760 - f1_score: 0.7281 - val_loss: 0.0401 - val_accuracy: 0.8753 - val_precision: 0.5045 - val_recall: 0.7695 - val_auc: 0.9203 - val_f1_score: 0.6094\n","Epoch 160/300\n","483/483 [==============================] - 34s 71ms/step - loss: 0.0119 - accuracy: 0.9143 - precision: 0.5992 - recall: 0.9530 - auc: 0.9770 - f1_score: 0.7358 - val_loss: 0.0424 - val_accuracy: 0.8786 - val_precision: 0.5133 - val_recall: 0.7637 - val_auc: 0.9247 - val_f1_score: 0.6139\n","Epoch 161/300\n","483/483 [==============================] - 34s 70ms/step - loss: 0.0121 - accuracy: 0.9128 - precision: 0.5948 - recall: 0.9526 - auc: 0.9768 - f1_score: 0.7324 - val_loss: 0.0407 - val_accuracy: 0.8769 - val_precision: 0.5087 - val_recall: 0.7708 - val_auc: 0.9231 - val_f1_score: 0.6129\n","Epoch 162/300\n","483/483 [==============================] - 34s 70ms/step - loss: 0.0119 - accuracy: 0.9142 - precision: 0.5988 - recall: 0.9537 - auc: 0.9772 - f1_score: 0.7357 - val_loss: 0.0418 - val_accuracy: 0.8740 - val_precision: 0.5011 - val_recall: 0.7916 - val_auc: 0.9254 - val_f1_score: 0.6137\n","Epoch 163/300\n","483/483 [==============================] - 34s 70ms/step - loss: 0.0119 - accuracy: 0.9157 - precision: 0.6031 - recall: 0.9543 - auc: 0.9776 - f1_score: 0.7391 - val_loss: 0.0424 - val_accuracy: 0.8777 - val_precision: 0.5109 - val_recall: 0.7719 - val_auc: 0.9242 - val_f1_score: 0.6148\n","Epoch 164/300\n","483/483 [==============================] - 34s 69ms/step - loss: 0.0122 - accuracy: 0.9114 - precision: 0.5907 - recall: 0.9532 - auc: 0.9760 - f1_score: 0.7293 - val_loss: 0.0396 - val_accuracy: 0.8689 - val_precision: 0.4888 - val_recall: 0.8142 - val_auc: 0.9237 - val_f1_score: 0.6109\n","Epoch 165/300\n","483/483 [==============================] - 34s 70ms/step - loss: 0.0120 - accuracy: 0.9134 - precision: 0.5965 - recall: 0.9521 - auc: 0.9769 - f1_score: 0.7335 - val_loss: 0.0425 - val_accuracy: 0.8674 - val_precision: 0.4852 - val_recall: 0.8018 - val_auc: 0.9249 - val_f1_score: 0.6046\n","Epoch 166/300\n","483/483 [==============================] - 34s 71ms/step - loss: 0.0120 - accuracy: 0.9132 - precision: 0.5960 - recall: 0.9526 - auc: 0.9770 - f1_score: 0.7333 - val_loss: 0.0433 - val_accuracy: 0.8731 - val_precision: 0.4988 - val_recall: 0.7760 - val_auc: 0.9223 - val_f1_score: 0.6072\n","Epoch 167/300\n","483/483 [==============================] - 34s 70ms/step - loss: 0.0117 - accuracy: 0.9170 - precision: 0.6071 - recall: 0.9553 - auc: 0.9780 - f1_score: 0.7424 - val_loss: 0.0406 - val_accuracy: 0.8758 - val_precision: 0.5057 - val_recall: 0.7639 - val_auc: 0.9215 - val_f1_score: 0.6085\n","Epoch 168/300\n","483/483 [==============================] - 34s 70ms/step - loss: 0.0117 - accuracy: 0.9167 - precision: 0.6064 - recall: 0.9549 - auc: 0.9781 - f1_score: 0.7417 - val_loss: 0.0477 - val_accuracy: 0.8851 - val_precision: 0.5324 - val_recall: 0.7467 - val_auc: 0.9245 - val_f1_score: 0.6216\n","Epoch 169/300\n","483/483 [==============================] - 34s 70ms/step - loss: 0.0118 - accuracy: 0.9156 - precision: 0.6034 - recall: 0.9515 - auc: 0.9780 - f1_score: 0.7385 - val_loss: 0.0412 - val_accuracy: 0.8821 - val_precision: 0.5231 - val_recall: 0.7585 - val_auc: 0.9241 - val_f1_score: 0.6192\n","Epoch 170/300\n","483/483 [==============================] - 33s 69ms/step - loss: 0.0116 - accuracy: 0.9164 - precision: 0.6055 - recall: 0.9527 - auc: 0.9784 - f1_score: 0.7404 - val_loss: 0.0424 - val_accuracy: 0.8749 - val_precision: 0.5034 - val_recall: 0.7713 - val_auc: 0.9222 - val_f1_score: 0.6092\n","Epoch 171/300\n","483/483 [==============================] - 33s 69ms/step - loss: 0.0117 - accuracy: 0.9167 - precision: 0.6065 - recall: 0.9528 - auc: 0.9780 - f1_score: 0.7412 - val_loss: 0.0418 - val_accuracy: 0.8722 - val_precision: 0.4966 - val_recall: 0.7852 - val_auc: 0.9221 - val_f1_score: 0.6084\n","Epoch 172/300\n","483/483 [==============================] - 34s 69ms/step - loss: 0.0121 - accuracy: 0.9124 - precision: 0.5936 - recall: 0.9527 - auc: 0.9769 - f1_score: 0.7314 - val_loss: 0.0399 - val_accuracy: 0.8766 - val_precision: 0.5080 - val_recall: 0.7611 - val_auc: 0.9224 - val_f1_score: 0.6093\n","Epoch 173/300\n","483/483 [==============================] - 34s 70ms/step - loss: 0.0116 - accuracy: 0.9175 - precision: 0.6087 - recall: 0.9543 - auc: 0.9784 - f1_score: 0.7433 - val_loss: 0.0395 - val_accuracy: 0.8689 - val_precision: 0.4884 - val_recall: 0.7854 - val_auc: 0.9218 - val_f1_score: 0.6023\n","Epoch 174/300\n","483/483 [==============================] - 34s 70ms/step - loss: 0.0117 - accuracy: 0.9176 - precision: 0.6089 - recall: 0.9552 - auc: 0.9783 - f1_score: 0.7437 - val_loss: 0.0410 - val_accuracy: 0.8693 - val_precision: 0.4895 - val_recall: 0.7870 - val_auc: 0.9209 - val_f1_score: 0.6036\n","Epoch 175/300\n","483/483 [==============================] - 34s 70ms/step - loss: 0.0114 - accuracy: 0.9177 - precision: 0.6091 - recall: 0.9567 - auc: 0.9789 - f1_score: 0.7443 - val_loss: 0.0418 - val_accuracy: 0.8726 - val_precision: 0.4974 - val_recall: 0.7867 - val_auc: 0.9234 - val_f1_score: 0.6095\n","Epoch 176/300\n","483/483 [==============================] - 34s 70ms/step - loss: 0.0117 - accuracy: 0.9164 - precision: 0.6053 - recall: 0.9545 - auc: 0.9780 - f1_score: 0.7408 - val_loss: 0.0445 - val_accuracy: 0.8809 - val_precision: 0.5201 - val_recall: 0.7454 - val_auc: 0.9217 - val_f1_score: 0.6127\n","Epoch 177/300\n","483/483 [==============================] - 34s 70ms/step - loss: 0.0118 - accuracy: 0.9165 - precision: 0.6056 - recall: 0.9553 - auc: 0.9780 - f1_score: 0.7413 - val_loss: 0.0415 - val_accuracy: 0.8720 - val_precision: 0.4959 - val_recall: 0.7429 - val_auc: 0.9188 - val_f1_score: 0.5948\n","Epoch 178/300\n","483/483 [==============================] - 33s 69ms/step - loss: 0.0116 - accuracy: 0.9169 - precision: 0.6068 - recall: 0.9548 - auc: 0.9786 - f1_score: 0.7420 - val_loss: 0.0470 - val_accuracy: 0.8834 - val_precision: 0.5281 - val_recall: 0.7296 - val_auc: 0.9225 - val_f1_score: 0.6127\n","Epoch 179/300\n","483/483 [==============================] - 34s 71ms/step - loss: 0.0114 - accuracy: 0.9194 - precision: 0.6147 - recall: 0.9547 - auc: 0.9792 - f1_score: 0.7479 - val_loss: 0.0466 - val_accuracy: 0.8795 - val_precision: 0.5158 - val_recall: 0.7634 - val_auc: 0.9233 - val_f1_score: 0.6157\n","Epoch 180/300\n","483/483 [==============================] - 34s 71ms/step - loss: 0.0113 - accuracy: 0.9201 - precision: 0.6168 - recall: 0.9541 - auc: 0.9794 - f1_score: 0.7493 - val_loss: 0.0492 - val_accuracy: 0.8787 - val_precision: 0.5137 - val_recall: 0.7657 - val_auc: 0.9235 - val_f1_score: 0.6149\n","Epoch 181/300\n","483/483 [==============================] - 35s 71ms/step - loss: 0.0117 - accuracy: 0.9169 - precision: 0.6069 - recall: 0.9543 - auc: 0.9786 - f1_score: 0.7420 - val_loss: 0.0466 - val_accuracy: 0.8837 - val_precision: 0.5285 - val_recall: 0.7398 - val_auc: 0.9244 - val_f1_score: 0.6165\n","Epoch 182/300\n","483/483 [==============================] - 34s 71ms/step - loss: 0.0116 - accuracy: 0.9188 - precision: 0.6127 - recall: 0.9554 - auc: 0.9788 - f1_score: 0.7466 - val_loss: 0.0476 - val_accuracy: 0.8843 - val_precision: 0.5303 - val_recall: 0.7424 - val_auc: 0.9233 - val_f1_score: 0.6187\n","Epoch 183/300\n","483/483 [==============================] - 34s 71ms/step - loss: 0.0114 - accuracy: 0.9195 - precision: 0.6149 - recall: 0.9551 - auc: 0.9791 - f1_score: 0.7481 - val_loss: 0.0427 - val_accuracy: 0.8806 - val_precision: 0.5186 - val_recall: 0.7754 - val_auc: 0.9259 - val_f1_score: 0.6215\n","Epoch 184/300\n","483/483 [==============================] - 34s 70ms/step - loss: 0.0113 - accuracy: 0.9199 - precision: 0.6162 - recall: 0.9554 - auc: 0.9794 - f1_score: 0.7492 - val_loss: 0.0450 - val_accuracy: 0.8763 - val_precision: 0.5070 - val_recall: 0.7742 - val_auc: 0.9226 - val_f1_score: 0.6127\n","Epoch 185/300\n","483/483 [==============================] - 34s 70ms/step - loss: 0.0114 - accuracy: 0.9203 - precision: 0.6171 - recall: 0.9572 - auc: 0.9793 - f1_score: 0.7504 - val_loss: 0.0393 - val_accuracy: 0.8799 - val_precision: 0.5170 - val_recall: 0.7557 - val_auc: 0.9229 - val_f1_score: 0.6140\n","Epoch 186/300\n","483/483 [==============================] - 34s 71ms/step - loss: 0.0113 - accuracy: 0.9194 - precision: 0.6145 - recall: 0.9560 - auc: 0.9793 - f1_score: 0.7481 - val_loss: 0.0433 - val_accuracy: 0.8759 - val_precision: 0.5058 - val_recall: 0.7783 - val_auc: 0.9239 - val_f1_score: 0.6131\n","Epoch 187/300\n","483/483 [==============================] - 34s 70ms/step - loss: 0.0114 - accuracy: 0.9194 - precision: 0.6144 - recall: 0.9566 - auc: 0.9794 - f1_score: 0.7482 - val_loss: 0.0450 - val_accuracy: 0.8841 - val_precision: 0.5297 - val_recall: 0.7434 - val_auc: 0.9227 - val_f1_score: 0.6186\n","Epoch 188/300\n","483/483 [==============================] - 34s 70ms/step - loss: 0.0115 - accuracy: 0.9183 - precision: 0.6114 - recall: 0.9547 - auc: 0.9787 - f1_score: 0.7454 - val_loss: 0.0483 - val_accuracy: 0.8866 - val_precision: 0.5384 - val_recall: 0.7185 - val_auc: 0.9207 - val_f1_score: 0.6156\n","Epoch 189/300\n","483/483 [==============================] - 34s 70ms/step - loss: 0.0111 - accuracy: 0.9216 - precision: 0.6213 - recall: 0.9566 - auc: 0.9802 - f1_score: 0.7533 - val_loss: 0.0410 - val_accuracy: 0.8755 - val_precision: 0.5050 - val_recall: 0.7729 - val_auc: 0.9218 - val_f1_score: 0.6109\n","Epoch 190/300\n","483/483 [==============================] - 34s 71ms/step - loss: 0.0111 - accuracy: 0.9203 - precision: 0.6170 - recall: 0.9574 - auc: 0.9801 - f1_score: 0.7504 - val_loss: 0.0415 - val_accuracy: 0.8811 - val_precision: 0.5206 - val_recall: 0.7529 - val_auc: 0.9230 - val_f1_score: 0.6155\n","Epoch 191/300\n","483/483 [==============================] - 34s 70ms/step - loss: 0.0117 - accuracy: 0.9164 - precision: 0.6054 - recall: 0.9542 - auc: 0.9783 - f1_score: 0.7408 - val_loss: 0.0454 - val_accuracy: 0.8813 - val_precision: 0.5217 - val_recall: 0.7380 - val_auc: 0.9232 - val_f1_score: 0.6113\n","Epoch 192/300\n","483/483 [==============================] - 34s 70ms/step - loss: 0.0114 - accuracy: 0.9188 - precision: 0.6126 - recall: 0.9559 - auc: 0.9795 - f1_score: 0.7467 - val_loss: 0.0500 - val_accuracy: 0.8880 - val_precision: 0.5431 - val_recall: 0.7190 - val_auc: 0.9232 - val_f1_score: 0.6188\n","Epoch 193/300\n","483/483 [==============================] - 34s 69ms/step - loss: 0.0111 - accuracy: 0.9217 - precision: 0.6217 - recall: 0.9563 - auc: 0.9805 - f1_score: 0.7535 - val_loss: 0.0406 - val_accuracy: 0.8785 - val_precision: 0.5127 - val_recall: 0.7744 - val_auc: 0.9234 - val_f1_score: 0.6170\n","Epoch 194/300\n","483/483 [==============================] - 34s 70ms/step - loss: 0.0114 - accuracy: 0.9186 - precision: 0.6123 - recall: 0.9545 - auc: 0.9793 - f1_score: 0.7460 - val_loss: 0.0420 - val_accuracy: 0.8731 - val_precision: 0.4988 - val_recall: 0.7588 - val_auc: 0.9211 - val_f1_score: 0.6019\n","Epoch 195/300\n","483/483 [==============================] - 35s 72ms/step - loss: 0.0114 - accuracy: 0.9188 - precision: 0.6129 - recall: 0.9544 - auc: 0.9791 - f1_score: 0.7464 - val_loss: 0.0417 - val_accuracy: 0.8736 - val_precision: 0.5000 - val_recall: 0.7642 - val_auc: 0.9219 - val_f1_score: 0.6045\n","Epoch 196/300\n","483/483 [==============================] - 34s 71ms/step - loss: 0.0113 - accuracy: 0.9199 - precision: 0.6161 - recall: 0.9557 - auc: 0.9799 - f1_score: 0.7492 - val_loss: 0.0443 - val_accuracy: 0.8824 - val_precision: 0.5248 - val_recall: 0.7401 - val_auc: 0.9227 - val_f1_score: 0.6141\n","Epoch 197/300\n","483/483 [==============================] - 34s 71ms/step - loss: 0.0111 - accuracy: 0.9219 - precision: 0.6225 - recall: 0.9556 - auc: 0.9805 - f1_score: 0.7539 - val_loss: 0.0448 - val_accuracy: 0.8843 - val_precision: 0.5298 - val_recall: 0.7544 - val_auc: 0.9254 - val_f1_score: 0.6225\n","Epoch 198/300\n","483/483 [==============================] - 35s 73ms/step - loss: 0.0110 - accuracy: 0.9223 - precision: 0.6235 - recall: 0.9572 - auc: 0.9809 - f1_score: 0.7551 - val_loss: 0.0504 - val_accuracy: 0.8847 - val_precision: 0.5326 - val_recall: 0.7157 - val_auc: 0.9198 - val_f1_score: 0.6107\n","Epoch 199/300\n","483/483 [==============================] - 35s 73ms/step - loss: 0.0110 - accuracy: 0.9223 - precision: 0.6235 - recall: 0.9575 - auc: 0.9807 - f1_score: 0.7552 - val_loss: 0.0465 - val_accuracy: 0.8807 - val_precision: 0.5193 - val_recall: 0.7565 - val_auc: 0.9229 - val_f1_score: 0.6158\n","Epoch 200/300\n","483/483 [==============================] - 35s 73ms/step - loss: 0.0111 - accuracy: 0.9215 - precision: 0.6212 - recall: 0.9561 - auc: 0.9804 - f1_score: 0.7531 - val_loss: 0.0436 - val_accuracy: 0.8814 - val_precision: 0.5210 - val_recall: 0.7667 - val_auc: 0.9242 - val_f1_score: 0.6204\n","Epoch 201/300\n","483/483 [==============================] - 35s 73ms/step - loss: 0.0112 - accuracy: 0.9209 - precision: 0.6192 - recall: 0.9559 - auc: 0.9801 - f1_score: 0.7515 - val_loss: 0.0478 - val_accuracy: 0.8850 - val_precision: 0.5327 - val_recall: 0.7355 - val_auc: 0.9231 - val_f1_score: 0.6179\n","Epoch 202/300\n","483/483 [==============================] - 35s 73ms/step - loss: 0.0112 - accuracy: 0.9221 - precision: 0.6229 - recall: 0.9563 - auc: 0.9805 - f1_score: 0.7544 - val_loss: 0.0458 - val_accuracy: 0.8817 - val_precision: 0.5220 - val_recall: 0.7619 - val_auc: 0.9240 - val_f1_score: 0.6196\n","Epoch 203/300\n","483/483 [==============================] - 36s 74ms/step - loss: 0.0112 - accuracy: 0.9220 - precision: 0.6231 - recall: 0.9541 - auc: 0.9803 - f1_score: 0.7538 - val_loss: 0.0402 - val_accuracy: 0.8786 - val_precision: 0.5131 - val_recall: 0.7698 - val_auc: 0.9234 - val_f1_score: 0.6157\n","Epoch 204/300\n","483/483 [==============================] - 35s 72ms/step - loss: 0.0110 - accuracy: 0.9233 - precision: 0.6269 - recall: 0.9574 - auc: 0.9808 - f1_score: 0.7577 - val_loss: 0.0461 - val_accuracy: 0.8811 - val_precision: 0.5208 - val_recall: 0.7419 - val_auc: 0.9214 - val_f1_score: 0.6120\n","Epoch 205/300\n","483/483 [==============================] - 35s 72ms/step - loss: 0.0110 - accuracy: 0.9231 - precision: 0.6263 - recall: 0.9570 - auc: 0.9808 - f1_score: 0.7571 - val_loss: 0.0462 - val_accuracy: 0.8801 - val_precision: 0.5176 - val_recall: 0.7560 - val_auc: 0.9224 - val_f1_score: 0.6145\n","Epoch 206/300\n","483/483 [==============================] - 35s 73ms/step - loss: 0.0110 - accuracy: 0.9225 - precision: 0.6246 - recall: 0.9556 - auc: 0.9807 - f1_score: 0.7554 - val_loss: 0.0402 - val_accuracy: 0.8776 - val_precision: 0.5105 - val_recall: 0.7649 - val_auc: 0.9226 - val_f1_score: 0.6124\n","Epoch 207/300\n","483/483 [==============================] - 35s 73ms/step - loss: 0.0111 - accuracy: 0.9215 - precision: 0.6209 - recall: 0.9585 - auc: 0.9806 - f1_score: 0.7537 - val_loss: 0.0425 - val_accuracy: 0.8801 - val_precision: 0.5177 - val_recall: 0.7554 - val_auc: 0.9243 - val_f1_score: 0.6143\n","Epoch 208/300\n","483/483 [==============================] - 35s 73ms/step - loss: 0.0110 - accuracy: 0.9230 - precision: 0.6260 - recall: 0.9560 - auc: 0.9807 - f1_score: 0.7566 - val_loss: 0.0406 - val_accuracy: 0.8757 - val_precision: 0.5055 - val_recall: 0.7780 - val_auc: 0.9229 - val_f1_score: 0.6128\n","Epoch 209/300\n","483/483 [==============================] - 35s 73ms/step - loss: 0.0109 - accuracy: 0.9228 - precision: 0.6252 - recall: 0.9569 - auc: 0.9810 - f1_score: 0.7563 - val_loss: 0.0429 - val_accuracy: 0.8830 - val_precision: 0.5256 - val_recall: 0.7598 - val_auc: 0.9247 - val_f1_score: 0.6214\n","Epoch 210/300\n","483/483 [==============================] - 35s 73ms/step - loss: 0.0110 - accuracy: 0.9239 - precision: 0.6290 - recall: 0.9563 - auc: 0.9812 - f1_score: 0.7589 - val_loss: 0.0454 - val_accuracy: 0.8866 - val_precision: 0.5388 - val_recall: 0.7155 - val_auc: 0.9227 - val_f1_score: 0.6147\n","Epoch 211/300\n","483/483 [==============================] - 35s 73ms/step - loss: 0.0109 - accuracy: 0.9228 - precision: 0.6253 - recall: 0.9566 - auc: 0.9809 - f1_score: 0.7563 - val_loss: 0.0408 - val_accuracy: 0.8690 - val_precision: 0.4888 - val_recall: 0.7916 - val_auc: 0.9229 - val_f1_score: 0.6044\n","Epoch 212/300\n","483/483 [==============================] - 35s 72ms/step - loss: 0.0108 - accuracy: 0.9240 - precision: 0.6291 - recall: 0.9579 - auc: 0.9815 - f1_score: 0.7595 - val_loss: 0.0456 - val_accuracy: 0.8856 - val_precision: 0.5355 - val_recall: 0.7180 - val_auc: 0.9223 - val_f1_score: 0.6134\n","Epoch 213/300\n","483/483 [==============================] - 35s 72ms/step - loss: 0.0108 - accuracy: 0.9255 - precision: 0.6340 - recall: 0.9578 - auc: 0.9817 - f1_score: 0.7630 - val_loss: 0.0427 - val_accuracy: 0.8751 - val_precision: 0.5041 - val_recall: 0.7595 - val_auc: 0.9217 - val_f1_score: 0.6060\n","Epoch 214/300\n","483/483 [==============================] - 35s 72ms/step - loss: 0.0108 - accuracy: 0.9249 - precision: 0.6323 - recall: 0.9565 - auc: 0.9816 - f1_score: 0.7613 - val_loss: 0.0430 - val_accuracy: 0.8789 - val_precision: 0.5140 - val_recall: 0.7685 - val_auc: 0.9232 - val_f1_score: 0.6160\n","Epoch 215/300\n","483/483 [==============================] - 34s 71ms/step - loss: 0.0107 - accuracy: 0.9245 - precision: 0.6302 - recall: 0.9601 - auc: 0.9816 - f1_score: 0.7610 - val_loss: 0.0481 - val_accuracy: 0.8801 - val_precision: 0.5181 - val_recall: 0.7401 - val_auc: 0.9211 - val_f1_score: 0.6095\n","Epoch 216/300\n","483/483 [==============================] - 35s 72ms/step - loss: 0.0107 - accuracy: 0.9238 - precision: 0.6279 - recall: 0.9603 - auc: 0.9817 - f1_score: 0.7593 - val_loss: 0.0471 - val_accuracy: 0.8800 - val_precision: 0.5175 - val_recall: 0.7524 - val_auc: 0.9206 - val_f1_score: 0.6132\n","Epoch 217/300\n","483/483 [==============================] - 34s 71ms/step - loss: 0.0110 - accuracy: 0.9228 - precision: 0.6255 - recall: 0.9549 - auc: 0.9811 - f1_score: 0.7559 - val_loss: 0.0482 - val_accuracy: 0.8789 - val_precision: 0.5143 - val_recall: 0.7539 - val_auc: 0.9228 - val_f1_score: 0.6114\n","Epoch 218/300\n","483/483 [==============================] - 34s 71ms/step - loss: 0.0107 - accuracy: 0.9247 - precision: 0.6314 - recall: 0.9587 - auc: 0.9816 - f1_score: 0.7613 - val_loss: 0.0456 - val_accuracy: 0.8794 - val_precision: 0.5156 - val_recall: 0.7634 - val_auc: 0.9222 - val_f1_score: 0.6155\n","Epoch 219/300\n","483/483 [==============================] - 35s 71ms/step - loss: 0.0108 - accuracy: 0.9241 - precision: 0.6294 - recall: 0.9582 - auc: 0.9816 - f1_score: 0.7598 - val_loss: 0.0436 - val_accuracy: 0.8813 - val_precision: 0.5212 - val_recall: 0.7516 - val_auc: 0.9220 - val_f1_score: 0.6156\n","Epoch 220/300\n","483/483 [==============================] - 35s 72ms/step - loss: 0.0106 - accuracy: 0.9257 - precision: 0.6343 - recall: 0.9598 - auc: 0.9822 - f1_score: 0.7638 - val_loss: 0.0497 - val_accuracy: 0.8837 - val_precision: 0.5282 - val_recall: 0.7503 - val_auc: 0.9224 - val_f1_score: 0.6200\n","Epoch 221/300\n","483/483 [==============================] - 34s 71ms/step - loss: 0.0107 - accuracy: 0.9247 - precision: 0.6313 - recall: 0.9590 - auc: 0.9821 - f1_score: 0.7614 - val_loss: 0.0440 - val_accuracy: 0.8726 - val_precision: 0.4975 - val_recall: 0.7667 - val_auc: 0.9203 - val_f1_score: 0.6035\n","Epoch 222/300\n","483/483 [==============================] - 35s 72ms/step - loss: 0.0106 - accuracy: 0.9259 - precision: 0.6355 - recall: 0.9581 - auc: 0.9821 - f1_score: 0.7641 - val_loss: 0.0430 - val_accuracy: 0.8809 - val_precision: 0.5203 - val_recall: 0.7406 - val_auc: 0.9231 - val_f1_score: 0.6112\n","Epoch 223/300\n","483/483 [==============================] - 34s 71ms/step - loss: 0.0106 - accuracy: 0.9264 - precision: 0.6369 - recall: 0.9579 - auc: 0.9824 - f1_score: 0.7651 - val_loss: 0.0488 - val_accuracy: 0.8803 - val_precision: 0.5181 - val_recall: 0.7624 - val_auc: 0.9219 - val_f1_score: 0.6169\n","Epoch 224/300\n","483/483 [==============================] - 35s 72ms/step - loss: 0.0108 - accuracy: 0.9238 - precision: 0.6284 - recall: 0.9578 - auc: 0.9814 - f1_score: 0.7589 - val_loss: 0.0468 - val_accuracy: 0.8822 - val_precision: 0.5237 - val_recall: 0.7511 - val_auc: 0.9236 - val_f1_score: 0.6171\n","Epoch 225/300\n","483/483 [==============================] - 35s 72ms/step - loss: 0.0106 - accuracy: 0.9253 - precision: 0.6330 - recall: 0.9592 - auc: 0.9823 - f1_score: 0.7627 - val_loss: 0.0493 - val_accuracy: 0.8843 - val_precision: 0.5311 - val_recall: 0.7221 - val_auc: 0.9215 - val_f1_score: 0.6121\n","Epoch 226/300\n","483/483 [==============================] - 34s 71ms/step - loss: 0.0108 - accuracy: 0.9244 - precision: 0.6304 - recall: 0.9576 - auc: 0.9815 - f1_score: 0.7603 - val_loss: 0.0411 - val_accuracy: 0.8761 - val_precision: 0.5064 - val_recall: 0.7672 - val_auc: 0.9220 - val_f1_score: 0.6101\n","Epoch 227/300\n","483/483 [==============================] - 35s 72ms/step - loss: 0.0105 - accuracy: 0.9261 - precision: 0.6359 - recall: 0.9592 - auc: 0.9828 - f1_score: 0.7648 - val_loss: 0.0447 - val_accuracy: 0.8775 - val_precision: 0.5101 - val_recall: 0.7744 - val_auc: 0.9227 - val_f1_score: 0.6151\n","Epoch 228/300\n","483/483 [==============================] - 35s 72ms/step - loss: 0.0106 - accuracy: 0.9253 - precision: 0.6338 - recall: 0.9565 - auc: 0.9823 - f1_score: 0.7624 - val_loss: 0.0474 - val_accuracy: 0.8817 - val_precision: 0.5226 - val_recall: 0.7390 - val_auc: 0.9221 - val_f1_score: 0.6122\n","Epoch 229/300\n","483/483 [==============================] - 35s 72ms/step - loss: 0.0105 - accuracy: 0.9269 - precision: 0.6384 - recall: 0.9596 - auc: 0.9825 - f1_score: 0.7667 - val_loss: 0.0461 - val_accuracy: 0.8791 - val_precision: 0.5148 - val_recall: 0.7565 - val_auc: 0.9220 - val_f1_score: 0.6127\n","Epoch 230/300\n","483/483 [==============================] - 35s 73ms/step - loss: 0.0107 - accuracy: 0.9261 - precision: 0.6358 - recall: 0.9591 - auc: 0.9822 - f1_score: 0.7647 - val_loss: 0.0464 - val_accuracy: 0.8844 - val_precision: 0.5304 - val_recall: 0.7419 - val_auc: 0.9232 - val_f1_score: 0.6186\n","Epoch 231/300\n","483/483 [==============================] - 35s 73ms/step - loss: 0.0107 - accuracy: 0.9253 - precision: 0.6333 - recall: 0.9589 - auc: 0.9821 - f1_score: 0.7628 - val_loss: 0.0454 - val_accuracy: 0.8783 - val_precision: 0.5127 - val_recall: 0.7560 - val_auc: 0.9205 - val_f1_score: 0.6110\n","Epoch 232/300\n","483/483 [==============================] - 35s 73ms/step - loss: 0.0105 - accuracy: 0.9270 - precision: 0.6388 - recall: 0.9596 - auc: 0.9828 - f1_score: 0.7670 - val_loss: 0.0484 - val_accuracy: 0.8822 - val_precision: 0.5236 - val_recall: 0.7549 - val_auc: 0.9240 - val_f1_score: 0.6184\n","Epoch 233/300\n","483/483 [==============================] - 35s 72ms/step - loss: 0.0104 - accuracy: 0.9274 - precision: 0.6402 - recall: 0.9589 - auc: 0.9828 - f1_score: 0.7678 - val_loss: 0.0466 - val_accuracy: 0.8790 - val_precision: 0.5149 - val_recall: 0.7442 - val_auc: 0.9203 - val_f1_score: 0.6087\n","Epoch 234/300\n","483/483 [==============================] - 35s 72ms/step - loss: 0.0103 - accuracy: 0.9293 - precision: 0.6473 - recall: 0.9574 - auc: 0.9833 - f1_score: 0.7723 - val_loss: 0.0441 - val_accuracy: 0.8831 - val_precision: 0.5263 - val_recall: 0.7552 - val_auc: 0.9236 - val_f1_score: 0.6203\n","Epoch 235/300\n","483/483 [==============================] - 35s 72ms/step - loss: 0.0105 - accuracy: 0.9273 - precision: 0.6396 - recall: 0.9599 - auc: 0.9826 - f1_score: 0.7677 - val_loss: 0.0410 - val_accuracy: 0.8740 - val_precision: 0.5011 - val_recall: 0.7875 - val_auc: 0.9232 - val_f1_score: 0.6124\n","Epoch 236/300\n","483/483 [==============================] - 35s 72ms/step - loss: 0.0105 - accuracy: 0.9262 - precision: 0.6360 - recall: 0.9600 - auc: 0.9827 - f1_score: 0.7651 - val_loss: 0.0419 - val_accuracy: 0.8773 - val_precision: 0.5096 - val_recall: 0.7713 - val_auc: 0.9221 - val_f1_score: 0.6137\n","Epoch 237/300\n","483/483 [==============================] - 35s 73ms/step - loss: 0.0104 - accuracy: 0.9277 - precision: 0.6410 - recall: 0.9606 - auc: 0.9828 - f1_score: 0.7689 - val_loss: 0.0527 - val_accuracy: 0.8815 - val_precision: 0.5216 - val_recall: 0.7593 - val_auc: 0.9220 - val_f1_score: 0.6184\n","Epoch 238/300\n","483/483 [==============================] - 35s 72ms/step - loss: 0.0105 - accuracy: 0.9270 - precision: 0.6394 - recall: 0.9557 - auc: 0.9827 - f1_score: 0.7662 - val_loss: 0.0403 - val_accuracy: 0.8762 - val_precision: 0.5069 - val_recall: 0.7567 - val_auc: 0.9203 - val_f1_score: 0.6071\n","Epoch 239/300\n","483/483 [==============================] - 35s 73ms/step - loss: 0.0104 - accuracy: 0.9266 - precision: 0.6375 - recall: 0.9594 - auc: 0.9828 - f1_score: 0.7660 - val_loss: 0.0527 - val_accuracy: 0.8835 - val_precision: 0.5282 - val_recall: 0.7360 - val_auc: 0.9198 - val_f1_score: 0.6150\n","Epoch 240/300\n","483/483 [==============================] - 35s 73ms/step - loss: 0.0103 - accuracy: 0.9291 - precision: 0.6460 - recall: 0.9595 - auc: 0.9832 - f1_score: 0.7722 - val_loss: 0.0506 - val_accuracy: 0.8807 - val_precision: 0.5198 - val_recall: 0.7385 - val_auc: 0.9199 - val_f1_score: 0.6101\n","Epoch 241/300\n","483/483 [==============================] - 35s 73ms/step - loss: 0.0103 - accuracy: 0.9284 - precision: 0.6437 - recall: 0.9588 - auc: 0.9831 - f1_score: 0.7703 - val_loss: 0.0501 - val_accuracy: 0.8863 - val_precision: 0.5379 - val_recall: 0.7149 - val_auc: 0.9218 - val_f1_score: 0.6139\n","Epoch 242/300\n","483/483 [==============================] - 36s 74ms/step - loss: 0.0104 - accuracy: 0.9289 - precision: 0.6458 - recall: 0.9574 - auc: 0.9833 - f1_score: 0.7713 - val_loss: 0.0486 - val_accuracy: 0.8835 - val_precision: 0.5281 - val_recall: 0.7403 - val_auc: 0.9226 - val_f1_score: 0.6164\n","Epoch 243/300\n","483/483 [==============================] - 35s 73ms/step - loss: 0.0103 - accuracy: 0.9285 - precision: 0.6442 - recall: 0.9584 - auc: 0.9833 - f1_score: 0.7705 - val_loss: 0.0464 - val_accuracy: 0.8795 - val_precision: 0.5162 - val_recall: 0.7449 - val_auc: 0.9212 - val_f1_score: 0.6098\n","Epoch 244/300\n","483/483 [==============================] - 36s 74ms/step - loss: 0.0104 - accuracy: 0.9292 - precision: 0.6467 - recall: 0.9587 - auc: 0.9831 - f1_score: 0.7724 - val_loss: 0.0515 - val_accuracy: 0.8898 - val_precision: 0.5493 - val_recall: 0.7139 - val_auc: 0.9232 - val_f1_score: 0.6209\n","Epoch 245/300\n","483/483 [==============================] - 36s 74ms/step - loss: 0.0103 - accuracy: 0.9290 - precision: 0.6457 - recall: 0.9590 - auc: 0.9834 - f1_score: 0.7717 - val_loss: 0.0464 - val_accuracy: 0.8831 - val_precision: 0.5270 - val_recall: 0.7303 - val_auc: 0.9220 - val_f1_score: 0.6122\n","Epoch 246/300\n","483/483 [==============================] - 36s 74ms/step - loss: 0.0102 - accuracy: 0.9295 - precision: 0.6474 - recall: 0.9601 - auc: 0.9837 - f1_score: 0.7734 - val_loss: 0.0439 - val_accuracy: 0.8833 - val_precision: 0.5264 - val_recall: 0.7670 - val_auc: 0.9245 - val_f1_score: 0.6243\n","Epoch 247/300\n","483/483 [==============================] - 35s 73ms/step - loss: 0.0103 - accuracy: 0.9278 - precision: 0.6418 - recall: 0.9589 - auc: 0.9833 - f1_score: 0.7689 - val_loss: 0.0550 - val_accuracy: 0.8880 - val_precision: 0.5427 - val_recall: 0.7237 - val_auc: 0.9217 - val_f1_score: 0.6202\n","Epoch 248/300\n","483/483 [==============================] - 35s 73ms/step - loss: 0.0104 - accuracy: 0.9291 - precision: 0.6459 - recall: 0.9603 - auc: 0.9835 - f1_score: 0.7723 - val_loss: 0.0412 - val_accuracy: 0.8794 - val_precision: 0.5158 - val_recall: 0.7493 - val_auc: 0.9229 - val_f1_score: 0.6110\n","Epoch 249/300\n","483/483 [==============================] - 35s 73ms/step - loss: 0.0100 - accuracy: 0.9310 - precision: 0.6525 - recall: 0.9606 - auc: 0.9841 - f1_score: 0.7771 - val_loss: 0.0515 - val_accuracy: 0.8861 - val_precision: 0.5365 - val_recall: 0.7278 - val_auc: 0.9221 - val_f1_score: 0.6176\n","Epoch 250/300\n","483/483 [==============================] - 35s 72ms/step - loss: 0.0101 - accuracy: 0.9299 - precision: 0.6485 - recall: 0.9607 - auc: 0.9841 - f1_score: 0.7743 - val_loss: 0.0445 - val_accuracy: 0.8825 - val_precision: 0.5253 - val_recall: 0.7331 - val_auc: 0.9206 - val_f1_score: 0.6120\n","Epoch 251/300\n","483/483 [==============================] - 36s 74ms/step - loss: 0.0100 - accuracy: 0.9306 - precision: 0.6514 - recall: 0.9583 - auc: 0.9842 - f1_score: 0.7756 - val_loss: 0.0550 - val_accuracy: 0.8861 - val_precision: 0.5377 - val_recall: 0.7067 - val_auc: 0.9182 - val_f1_score: 0.6108\n","Epoch 252/300\n","483/483 [==============================] - 35s 73ms/step - loss: 0.0102 - accuracy: 0.9287 - precision: 0.6445 - recall: 0.9597 - auc: 0.9836 - f1_score: 0.7712 - val_loss: 0.0519 - val_accuracy: 0.8844 - val_precision: 0.5320 - val_recall: 0.7096 - val_auc: 0.9205 - val_f1_score: 0.6081\n","Epoch 253/300\n","483/483 [==============================] - 35s 73ms/step - loss: 0.0101 - accuracy: 0.9300 - precision: 0.6491 - recall: 0.9598 - auc: 0.9839 - f1_score: 0.7745 - val_loss: 0.0448 - val_accuracy: 0.8819 - val_precision: 0.5233 - val_recall: 0.7362 - val_auc: 0.9220 - val_f1_score: 0.6118\n","Epoch 254/300\n","483/483 [==============================] - 36s 74ms/step - loss: 0.0102 - accuracy: 0.9293 - precision: 0.6469 - recall: 0.9594 - auc: 0.9836 - f1_score: 0.7727 - val_loss: 0.0455 - val_accuracy: 0.8863 - val_precision: 0.5373 - val_recall: 0.7221 - val_auc: 0.9227 - val_f1_score: 0.6161\n","Epoch 255/300\n","483/483 [==============================] - 35s 73ms/step - loss: 0.0102 - accuracy: 0.9290 - precision: 0.6457 - recall: 0.9590 - auc: 0.9836 - f1_score: 0.7718 - val_loss: 0.0546 - val_accuracy: 0.8817 - val_precision: 0.5232 - val_recall: 0.7214 - val_auc: 0.9188 - val_f1_score: 0.6065\n","Epoch 256/300\n","483/483 [==============================] - 36s 74ms/step - loss: 0.0103 - accuracy: 0.9292 - precision: 0.6466 - recall: 0.9588 - auc: 0.9835 - f1_score: 0.7723 - val_loss: 0.0450 - val_accuracy: 0.8740 - val_precision: 0.5010 - val_recall: 0.7616 - val_auc: 0.9197 - val_f1_score: 0.6044\n","Epoch 257/300\n","483/483 [==============================] - 36s 74ms/step - loss: 0.0104 - accuracy: 0.9277 - precision: 0.6416 - recall: 0.9573 - auc: 0.9832 - f1_score: 0.7683 - val_loss: 0.0462 - val_accuracy: 0.8801 - val_precision: 0.5185 - val_recall: 0.7247 - val_auc: 0.9191 - val_f1_score: 0.6045\n","Epoch 258/300\n","483/483 [==============================] - 36s 74ms/step - loss: 0.0101 - accuracy: 0.9293 - precision: 0.6470 - recall: 0.9583 - auc: 0.9837 - f1_score: 0.7725 - val_loss: 0.0440 - val_accuracy: 0.8814 - val_precision: 0.5212 - val_recall: 0.7572 - val_auc: 0.9211 - val_f1_score: 0.6174\n","Epoch 259/300\n","483/483 [==============================] - 36s 75ms/step - loss: 0.0100 - accuracy: 0.9306 - precision: 0.6514 - recall: 0.9593 - auc: 0.9841 - f1_score: 0.7759 - val_loss: 0.0477 - val_accuracy: 0.8843 - val_precision: 0.5312 - val_recall: 0.7196 - val_auc: 0.9212 - val_f1_score: 0.6112\n","Epoch 260/300\n","483/483 [==============================] - 36s 75ms/step - loss: 0.0101 - accuracy: 0.9304 - precision: 0.6508 - recall: 0.9578 - auc: 0.9841 - f1_score: 0.7750 - val_loss: 0.0453 - val_accuracy: 0.8801 - val_precision: 0.5184 - val_recall: 0.7290 - val_auc: 0.9202 - val_f1_score: 0.6059\n","Epoch 261/300\n","483/483 [==============================] - 37s 76ms/step - loss: 0.0101 - accuracy: 0.9300 - precision: 0.6491 - recall: 0.9596 - auc: 0.9840 - f1_score: 0.7744 - val_loss: 0.0436 - val_accuracy: 0.8786 - val_precision: 0.5137 - val_recall: 0.7439 - val_auc: 0.9203 - val_f1_score: 0.6077\n","Epoch 262/300\n","483/483 [==============================] - 36s 75ms/step - loss: 0.0100 - accuracy: 0.9308 - precision: 0.6519 - recall: 0.9591 - auc: 0.9845 - f1_score: 0.7762 - val_loss: 0.0508 - val_accuracy: 0.8811 - val_precision: 0.5210 - val_recall: 0.7355 - val_auc: 0.9206 - val_f1_score: 0.6099\n","Epoch 263/300\n","483/483 [==============================] - 36s 75ms/step - loss: 0.0102 - accuracy: 0.9291 - precision: 0.6459 - recall: 0.9594 - auc: 0.9838 - f1_score: 0.7720 - val_loss: 0.0415 - val_accuracy: 0.8782 - val_precision: 0.5124 - val_recall: 0.7496 - val_auc: 0.9216 - val_f1_score: 0.6087\n","Epoch 264/300\n","483/483 [==============================] - 36s 75ms/step - loss: 0.0100 - accuracy: 0.9315 - precision: 0.6544 - recall: 0.9603 - auc: 0.9844 - f1_score: 0.7784 - val_loss: 0.0469 - val_accuracy: 0.8799 - val_precision: 0.5171 - val_recall: 0.7531 - val_auc: 0.9206 - val_f1_score: 0.6132\n","Epoch 265/300\n","483/483 [==============================] - 36s 74ms/step - loss: 0.0102 - accuracy: 0.9296 - precision: 0.6482 - recall: 0.9573 - auc: 0.9838 - f1_score: 0.7730 - val_loss: 0.0480 - val_accuracy: 0.8896 - val_precision: 0.5483 - val_recall: 0.7175 - val_auc: 0.9234 - val_f1_score: 0.6216\n","Epoch 266/300\n","483/483 [==============================] - 36s 74ms/step - loss: 0.0100 - accuracy: 0.9310 - precision: 0.6529 - recall: 0.9590 - auc: 0.9843 - f1_score: 0.7769 - val_loss: 0.0500 - val_accuracy: 0.8856 - val_precision: 0.5355 - val_recall: 0.7137 - val_auc: 0.9212 - val_f1_score: 0.6119\n","Epoch 267/300\n","483/483 [==============================] - 36s 74ms/step - loss: 0.0100 - accuracy: 0.9320 - precision: 0.6557 - recall: 0.9619 - auc: 0.9844 - f1_score: 0.7798 - val_loss: 0.0520 - val_accuracy: 0.8858 - val_precision: 0.5357 - val_recall: 0.7260 - val_auc: 0.9228 - val_f1_score: 0.6165\n","Epoch 268/300\n","483/483 [==============================] - 36s 74ms/step - loss: 0.0101 - accuracy: 0.9308 - precision: 0.6523 - recall: 0.9581 - auc: 0.9843 - f1_score: 0.7762 - val_loss: 0.0448 - val_accuracy: 0.8766 - val_precision: 0.5081 - val_recall: 0.7406 - val_auc: 0.9192 - val_f1_score: 0.6027\n","Epoch 269/300\n","483/483 [==============================] - 36s 74ms/step - loss: 0.0099 - accuracy: 0.9316 - precision: 0.6549 - recall: 0.9600 - auc: 0.9848 - f1_score: 0.7786 - val_loss: 0.0481 - val_accuracy: 0.8823 - val_precision: 0.5249 - val_recall: 0.7285 - val_auc: 0.9215 - val_f1_score: 0.6102\n","Epoch 270/300\n","483/483 [==============================] - 36s 74ms/step - loss: 0.0098 - accuracy: 0.9320 - precision: 0.6558 - recall: 0.9613 - auc: 0.9851 - f1_score: 0.7797 - val_loss: 0.0514 - val_accuracy: 0.8870 - val_precision: 0.5392 - val_recall: 0.7298 - val_auc: 0.9209 - val_f1_score: 0.6202\n","Epoch 271/300\n","483/483 [==============================] - 36s 74ms/step - loss: 0.0098 - accuracy: 0.9338 - precision: 0.6630 - recall: 0.9579 - auc: 0.9850 - f1_score: 0.7836 - val_loss: 0.0510 - val_accuracy: 0.8868 - val_precision: 0.5384 - val_recall: 0.7314 - val_auc: 0.9226 - val_f1_score: 0.6202\n","Epoch 272/300\n","483/483 [==============================] - 36s 74ms/step - loss: 0.0099 - accuracy: 0.9331 - precision: 0.6596 - recall: 0.9619 - auc: 0.9849 - f1_score: 0.7826 - val_loss: 0.0506 - val_accuracy: 0.8841 - val_precision: 0.5306 - val_recall: 0.7178 - val_auc: 0.9196 - val_f1_score: 0.6102\n","Epoch 273/300\n","483/483 [==============================] - 36s 75ms/step - loss: 0.0099 - accuracy: 0.9320 - precision: 0.6559 - recall: 0.9609 - auc: 0.9848 - f1_score: 0.7797 - val_loss: 0.0460 - val_accuracy: 0.8786 - val_precision: 0.5133 - val_recall: 0.7578 - val_auc: 0.9206 - val_f1_score: 0.6120\n","Epoch 274/300\n","483/483 [==============================] - 36s 74ms/step - loss: 0.0097 - accuracy: 0.9335 - precision: 0.6611 - recall: 0.9624 - auc: 0.9851 - f1_score: 0.7838 - val_loss: 0.0491 - val_accuracy: 0.8830 - val_precision: 0.5268 - val_recall: 0.7275 - val_auc: 0.9206 - val_f1_score: 0.6111\n","Epoch 275/300\n","483/483 [==============================] - 36s 74ms/step - loss: 0.0100 - accuracy: 0.9318 - precision: 0.6552 - recall: 0.9609 - auc: 0.9845 - f1_score: 0.7791 - val_loss: 0.0470 - val_accuracy: 0.8787 - val_precision: 0.5138 - val_recall: 0.7467 - val_auc: 0.9205 - val_f1_score: 0.6088\n","Epoch 276/300\n","483/483 [==============================] - 36s 74ms/step - loss: 0.0099 - accuracy: 0.9322 - precision: 0.6569 - recall: 0.9606 - auc: 0.9845 - f1_score: 0.7802 - val_loss: 0.0517 - val_accuracy: 0.8829 - val_precision: 0.5263 - val_recall: 0.7396 - val_auc: 0.9204 - val_f1_score: 0.6149\n","Epoch 277/300\n","483/483 [==============================] - 36s 74ms/step - loss: 0.0098 - accuracy: 0.9325 - precision: 0.6576 - recall: 0.9618 - auc: 0.9851 - f1_score: 0.7812 - val_loss: 0.0593 - val_accuracy: 0.8907 - val_precision: 0.5538 - val_recall: 0.6949 - val_auc: 0.9205 - val_f1_score: 0.6164\n","Epoch 278/300\n","483/483 [==============================] - 36s 74ms/step - loss: 0.0097 - accuracy: 0.9332 - precision: 0.6603 - recall: 0.9614 - auc: 0.9854 - f1_score: 0.7829 - val_loss: 0.0516 - val_accuracy: 0.8845 - val_precision: 0.5316 - val_recall: 0.7247 - val_auc: 0.9206 - val_f1_score: 0.6133\n","Epoch 279/300\n","483/483 [==============================] - 35s 74ms/step - loss: 0.0098 - accuracy: 0.9329 - precision: 0.6589 - recall: 0.9622 - auc: 0.9850 - f1_score: 0.7822 - val_loss: 0.0536 - val_accuracy: 0.8839 - val_precision: 0.5300 - val_recall: 0.7175 - val_auc: 0.9189 - val_f1_score: 0.6097\n","Epoch 280/300\n","483/483 [==============================] - 35s 73ms/step - loss: 0.0098 - accuracy: 0.9324 - precision: 0.6576 - recall: 0.9594 - auc: 0.9849 - f1_score: 0.7804 - val_loss: 0.0531 - val_accuracy: 0.8869 - val_precision: 0.5403 - val_recall: 0.7057 - val_auc: 0.9210 - val_f1_score: 0.6120\n","Epoch 281/300\n","483/483 [==============================] - 36s 74ms/step - loss: 0.0096 - accuracy: 0.9349 - precision: 0.6661 - recall: 0.9622 - auc: 0.9857 - f1_score: 0.7872 - val_loss: 0.0574 - val_accuracy: 0.8890 - val_precision: 0.5473 - val_recall: 0.7029 - val_auc: 0.9212 - val_f1_score: 0.6154\n","Epoch 282/300\n","483/483 [==============================] - 35s 73ms/step - loss: 0.0097 - accuracy: 0.9335 - precision: 0.6615 - recall: 0.9605 - auc: 0.9854 - f1_score: 0.7835 - val_loss: 0.0515 - val_accuracy: 0.8863 - val_precision: 0.5386 - val_recall: 0.7034 - val_auc: 0.9209 - val_f1_score: 0.6100\n","Epoch 283/300\n","483/483 [==============================] - 35s 73ms/step - loss: 0.0099 - accuracy: 0.9323 - precision: 0.6577 - recall: 0.9583 - auc: 0.9849 - f1_score: 0.7801 - val_loss: 0.0473 - val_accuracy: 0.8869 - val_precision: 0.5403 - val_recall: 0.7088 - val_auc: 0.9216 - val_f1_score: 0.6132\n","Epoch 284/300\n","483/483 [==============================] - 35s 72ms/step - loss: 0.0098 - accuracy: 0.9325 - precision: 0.6578 - recall: 0.9612 - auc: 0.9852 - f1_score: 0.7811 - val_loss: 0.0520 - val_accuracy: 0.8867 - val_precision: 0.5385 - val_recall: 0.7229 - val_auc: 0.9221 - val_f1_score: 0.6172\n","Epoch 285/300\n","483/483 [==============================] - 35s 73ms/step - loss: 0.0099 - accuracy: 0.9321 - precision: 0.6566 - recall: 0.9603 - auc: 0.9848 - f1_score: 0.7799 - val_loss: 0.0469 - val_accuracy: 0.8828 - val_precision: 0.5263 - val_recall: 0.7283 - val_auc: 0.9201 - val_f1_score: 0.6110\n","Epoch 286/300\n","483/483 [==============================] - 35s 73ms/step - loss: 0.0097 - accuracy: 0.9342 - precision: 0.6635 - recall: 0.9622 - auc: 0.9854 - f1_score: 0.7854 - val_loss: 0.0509 - val_accuracy: 0.8804 - val_precision: 0.5194 - val_recall: 0.7183 - val_auc: 0.9180 - val_f1_score: 0.6028\n","Epoch 287/300\n","483/483 [==============================] - 35s 73ms/step - loss: 0.0097 - accuracy: 0.9340 - precision: 0.6631 - recall: 0.9620 - auc: 0.9851 - f1_score: 0.7851 - val_loss: 0.0511 - val_accuracy: 0.8811 - val_precision: 0.5208 - val_recall: 0.7480 - val_auc: 0.9201 - val_f1_score: 0.6141\n","Epoch 288/300\n","483/483 [==============================] - 36s 74ms/step - loss: 0.0096 - accuracy: 0.9341 - precision: 0.6633 - recall: 0.9612 - auc: 0.9856 - f1_score: 0.7850 - val_loss: 0.0490 - val_accuracy: 0.8804 - val_precision: 0.5189 - val_recall: 0.7390 - val_auc: 0.9214 - val_f1_score: 0.6097\n","Epoch 289/300\n","483/483 [==============================] - 36s 74ms/step - loss: 0.0099 - accuracy: 0.9324 - precision: 0.6570 - recall: 0.9621 - auc: 0.9849 - f1_score: 0.7808 - val_loss: 0.0498 - val_accuracy: 0.8843 - val_precision: 0.5315 - val_recall: 0.7137 - val_auc: 0.9203 - val_f1_score: 0.6093\n","Epoch 290/300\n","483/483 [==============================] - 37s 76ms/step - loss: 0.0095 - accuracy: 0.9350 - precision: 0.6662 - recall: 0.9630 - auc: 0.9859 - f1_score: 0.7876 - val_loss: 0.0495 - val_accuracy: 0.8804 - val_precision: 0.5189 - val_recall: 0.7385 - val_auc: 0.9194 - val_f1_score: 0.6095\n","Epoch 291/300\n","483/483 [==============================] - 37s 76ms/step - loss: 0.0100 - accuracy: 0.9305 - precision: 0.6510 - recall: 0.9588 - auc: 0.9843 - f1_score: 0.7755 - val_loss: 0.0542 - val_accuracy: 0.8791 - val_precision: 0.5158 - val_recall: 0.7160 - val_auc: 0.9159 - val_f1_score: 0.5996\n","Epoch 292/300\n","483/483 [==============================] - 36s 76ms/step - loss: 0.0099 - accuracy: 0.9323 - precision: 0.6570 - recall: 0.9607 - auc: 0.9850 - f1_score: 0.7803 - val_loss: 0.0503 - val_accuracy: 0.8866 - val_precision: 0.5396 - val_recall: 0.6998 - val_auc: 0.9200 - val_f1_score: 0.6094\n","Epoch 293/300\n","483/483 [==============================] - 36s 75ms/step - loss: 0.0096 - accuracy: 0.9345 - precision: 0.6653 - recall: 0.9589 - auc: 0.9857 - f1_score: 0.7856 - val_loss: 0.0505 - val_accuracy: 0.8852 - val_precision: 0.5335 - val_recall: 0.7285 - val_auc: 0.9215 - val_f1_score: 0.6160\n","Epoch 294/300\n","483/483 [==============================] - 36s 75ms/step - loss: 0.0094 - accuracy: 0.9355 - precision: 0.6684 - recall: 0.9627 - auc: 0.9865 - f1_score: 0.7890 - val_loss: 0.0551 - val_accuracy: 0.8870 - val_precision: 0.5403 - val_recall: 0.7101 - val_auc: 0.9205 - val_f1_score: 0.6136\n","Epoch 295/300\n","483/483 [==============================] - 36s 74ms/step - loss: 0.0097 - accuracy: 0.9335 - precision: 0.6611 - recall: 0.9624 - auc: 0.9853 - f1_score: 0.7838 - val_loss: 0.0553 - val_accuracy: 0.8849 - val_precision: 0.5332 - val_recall: 0.7173 - val_auc: 0.9212 - val_f1_score: 0.6117\n","Epoch 296/300\n","483/483 [==============================] - 36s 75ms/step - loss: 0.0096 - accuracy: 0.9339 - precision: 0.6626 - recall: 0.9616 - auc: 0.9856 - f1_score: 0.7845 - val_loss: 0.0549 - val_accuracy: 0.8803 - val_precision: 0.5187 - val_recall: 0.7311 - val_auc: 0.9197 - val_f1_score: 0.6069\n","Epoch 297/300\n","483/483 [==============================] - 36s 74ms/step - loss: 0.0095 - accuracy: 0.9345 - precision: 0.6647 - recall: 0.9626 - auc: 0.9859 - f1_score: 0.7864 - val_loss: 0.0510 - val_accuracy: 0.8839 - val_precision: 0.5299 - val_recall: 0.7231 - val_auc: 0.9207 - val_f1_score: 0.6116\n","Epoch 298/300\n","483/483 [==============================] - 36s 74ms/step - loss: 0.0097 - accuracy: 0.9351 - precision: 0.6673 - recall: 0.9610 - auc: 0.9858 - f1_score: 0.7877 - val_loss: 0.0501 - val_accuracy: 0.8775 - val_precision: 0.5104 - val_recall: 0.7511 - val_auc: 0.9181 - val_f1_score: 0.6078\n","Epoch 299/300\n","483/483 [==============================] - 36s 74ms/step - loss: 0.0096 - accuracy: 0.9348 - precision: 0.6661 - recall: 0.9618 - auc: 0.9858 - f1_score: 0.7870 - val_loss: 0.0457 - val_accuracy: 0.8815 - val_precision: 0.5221 - val_recall: 0.7367 - val_auc: 0.9219 - val_f1_score: 0.6111\n","Epoch 300/300\n","483/483 [==============================] - 35s 72ms/step - loss: 0.0097 - accuracy: 0.9354 - precision: 0.6683 - recall: 0.9614 - auc: 0.9856 - f1_score: 0.7885 - val_loss: 0.0523 - val_accuracy: 0.8893 - val_precision: 0.5495 - val_recall: 0.6901 - val_auc: 0.9212 - val_f1_score: 0.6118\n","-----------------------테스트 결과---------------------------\n","1206/1206 [==============================] - 14s 12ms/step - loss: 0.0498 - accuracy: 0.8902 - precision: 0.5523 - recall: 0.6907 - auc: 0.9234 - f1_score: 0.6138\n","\n","\n","WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Year': <tf.Tensor 'Year:0' shape=(None, 1) dtype=string>, 'N_of_SCI': <tf.Tensor 'N_of_SCI:0' shape=(None, 1) dtype=float64>, 'N_of_Paper': <tf.Tensor 'N_of_Paper:0' shape=(None, 1) dtype=float64>, 'N_Patent_App': <tf.Tensor 'N_Patent_App:0' shape=(None, 1) dtype=float64>, 'N_Patent_Reg': <tf.Tensor 'N_Patent_Reg:0' shape=(None, 1) dtype=float64>, 'N_of_Korean_Patent': <tf.Tensor 'N_of_Korean_Patent:0' shape=(None, 1) dtype=float64>, 'N_of_Inter_Patent': <tf.Tensor 'N_of_Inter_Patent:0' shape=(None, 1) dtype=float64>, 'N_of_Patent': <tf.Tensor 'N_of_Patent:0' shape=(None, 1) dtype=float64>, 'Multi_Year': <tf.Tensor 'Multi_Year:0' shape=(None, 1) dtype=string>, 'RnD_Org': <tf.Tensor 'RnD_Org:0' shape=(None, 1) dtype=string>, 'Region': <tf.Tensor 'Region:0' shape=(None, 1) dtype=string>, 'STP_Code_11': <tf.Tensor 'STP_Code_11:0' shape=(None, 1) dtype=string>, 'STP_Code_1_Weight': <tf.Tensor 'STP_Code_1_Weight:0' shape=(None, 1) dtype=float64>, 'STP_Code_21': <tf.Tensor 'STP_Code_21:0' shape=(None, 1) dtype=string>, 'STP_Code_2_Weight': <tf.Tensor 'STP_Code_2_Weight:0' shape=(None, 1) dtype=float64>, 'Application_Area_1': <tf.Tensor 'Application_Area_1:0' shape=(None, 1) dtype=string>, 'Application_Area_1_Weight': <tf.Tensor 'Application_Area_1_Weight:0' shape=(None, 1) dtype=float64>, 'Application_Area_2': <tf.Tensor 'Application_Area_2:0' shape=(None, 1) dtype=string>, 'Application_Area_2_Weight': <tf.Tensor 'Application_Area_2_Weight:0' shape=(None, 1) dtype=float64>, 'Application_Area_3': <tf.Tensor 'Application_Area_3:0' shape=(None, 1) dtype=string>, 'Application_Area_3_Weight': <tf.Tensor 'Application_Area_3_Weight:0' shape=(None, 1) dtype=float64>, 'Green_Tech': <tf.Tensor 'Green_Tech:0' shape=(None, 1) dtype=string>, 'SixT_2': <tf.Tensor 'SixT_2:0' shape=(None, 1) dtype=string>, 'Econ_Social': <tf.Tensor 'Econ_Social:0' shape=(None, 1) dtype=string>, 'National_Strategy_2': <tf.Tensor 'National_Strategy_2:0' shape=(None, 1) dtype=string>, 'RnD_Stage': <tf.Tensor 'RnD_Stage:0' shape=(None, 1) dtype=string>, 'Cowork_Cor': <tf.Tensor 'Cowork_Cor:0' shape=(None, 1) dtype=string>, 'Cowork_Uni': <tf.Tensor 'Cowork_Uni:0' shape=(None, 1) dtype=string>, 'Cowork_Inst': <tf.Tensor 'Cowork_Inst:0' shape=(None, 1) dtype=string>, 'Cowork_Abroad': <tf.Tensor 'Cowork_Abroad:0' shape=(None, 1) dtype=string>, 'Cowork_etc': <tf.Tensor 'Cowork_etc:0' shape=(None, 1) dtype=string>, 'Log_RnD_Fund': <tf.Tensor 'Log_RnD_Fund:0' shape=(None, 1) dtype=float64>, 'Log_Duration': <tf.Tensor 'Log_Duration:0' shape=(None, 1) dtype=float64>}\n","Consider rewriting this model with the Functional API.\n","WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Year': <tf.Tensor 'inputs_32:0' shape=(None, 1) dtype=string>, 'N_of_SCI': <tf.Tensor 'inputs_22:0' shape=(None, 1) dtype=float64>, 'N_of_Paper': <tf.Tensor 'inputs_20:0' shape=(None, 1) dtype=float64>, 'N_Patent_App': <tf.Tensor 'inputs_16:0' shape=(None, 1) dtype=float64>, 'N_Patent_Reg': <tf.Tensor 'inputs_17:0' shape=(None, 1) dtype=float64>, 'N_of_Korean_Patent': <tf.Tensor 'inputs_19:0' shape=(None, 1) dtype=float64>, 'N_of_Inter_Patent': <tf.Tensor 'inputs_18:0' shape=(None, 1) dtype=float64>, 'N_of_Patent': <tf.Tensor 'inputs_21:0' shape=(None, 1) dtype=float64>, 'Multi_Year': <tf.Tensor 'inputs_15:0' shape=(None, 1) dtype=string>, 'RnD_Org': <tf.Tensor 'inputs_25:0' shape=(None, 1) dtype=string>, 'Region': <tf.Tensor 'inputs_24:0' shape=(None, 1) dtype=string>, 'STP_Code_11': <tf.Tensor 'inputs_27:0' shape=(None, 1) dtype=string>, 'STP_Code_1_Weight': <tf.Tensor 'inputs_28:0' shape=(None, 1) dtype=float64>, 'STP_Code_21': <tf.Tensor 'inputs_29:0' shape=(None, 1) dtype=string>, 'STP_Code_2_Weight': <tf.Tensor 'inputs_30:0' shape=(None, 1) dtype=float64>, 'Application_Area_1': <tf.Tensor 'inputs:0' shape=(None, 1) dtype=string>, 'Application_Area_1_Weight': <tf.Tensor 'inputs_1:0' shape=(None, 1) dtype=float64>, 'Application_Area_2': <tf.Tensor 'inputs_2:0' shape=(None, 1) dtype=string>, 'Application_Area_2_Weight': <tf.Tensor 'inputs_3:0' shape=(None, 1) dtype=float64>, 'Application_Area_3': <tf.Tensor 'inputs_4:0' shape=(None, 1) dtype=string>, 'Application_Area_3_Weight': <tf.Tensor 'inputs_5:0' shape=(None, 1) dtype=float64>, 'Green_Tech': <tf.Tensor 'inputs_12:0' shape=(None, 1) dtype=string>, 'SixT_2': <tf.Tensor 'inputs_31:0' shape=(None, 1) dtype=string>, 'Econ_Social': <tf.Tensor 'inputs_11:0' shape=(None, 1) dtype=string>, 'National_Strategy_2': <tf.Tensor 'inputs_23:0' shape=(None, 1) dtype=string>, 'RnD_Stage': <tf.Tensor 'inputs_26:0' shape=(None, 1) dtype=string>, 'Cowork_Cor': <tf.Tensor 'inputs_7:0' shape=(None, 1) dtype=string>, 'Cowork_Uni': <tf.Tensor 'inputs_9:0' shape=(None, 1) dtype=string>, 'Cowork_Inst': <tf.Tensor 'inputs_8:0' shape=(None, 1) dtype=string>, 'Cowork_Abroad': <tf.Tensor 'inputs_6:0' shape=(None, 1) dtype=string>, 'Cowork_etc': <tf.Tensor 'inputs_10:0' shape=(None, 1) dtype=string>, 'Log_RnD_Fund': <tf.Tensor 'inputs_14:0' shape=(None, 1) dtype=float64>, 'Log_Duration': <tf.Tensor 'inputs_13:0' shape=(None, 1) dtype=float64>}\n","Consider rewriting this model with the Functional API.\n","WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Year': <tf.Tensor 'inputs_32:0' shape=(None, 1) dtype=string>, 'N_of_SCI': <tf.Tensor 'inputs_22:0' shape=(None, 1) dtype=float64>, 'N_of_Paper': <tf.Tensor 'inputs_20:0' shape=(None, 1) dtype=float64>, 'N_Patent_App': <tf.Tensor 'inputs_16:0' shape=(None, 1) dtype=float64>, 'N_Patent_Reg': <tf.Tensor 'inputs_17:0' shape=(None, 1) dtype=float64>, 'N_of_Korean_Patent': <tf.Tensor 'inputs_19:0' shape=(None, 1) dtype=float64>, 'N_of_Inter_Patent': <tf.Tensor 'inputs_18:0' shape=(None, 1) dtype=float64>, 'N_of_Patent': <tf.Tensor 'inputs_21:0' shape=(None, 1) dtype=float64>, 'Multi_Year': <tf.Tensor 'inputs_15:0' shape=(None, 1) dtype=string>, 'RnD_Org': <tf.Tensor 'inputs_25:0' shape=(None, 1) dtype=string>, 'Region': <tf.Tensor 'inputs_24:0' shape=(None, 1) dtype=string>, 'STP_Code_11': <tf.Tensor 'inputs_27:0' shape=(None, 1) dtype=string>, 'STP_Code_1_Weight': <tf.Tensor 'inputs_28:0' shape=(None, 1) dtype=float64>, 'STP_Code_21': <tf.Tensor 'inputs_29:0' shape=(None, 1) dtype=string>, 'STP_Code_2_Weight': <tf.Tensor 'inputs_30:0' shape=(None, 1) dtype=float64>, 'Application_Area_1': <tf.Tensor 'inputs:0' shape=(None, 1) dtype=string>, 'Application_Area_1_Weight': <tf.Tensor 'inputs_1:0' shape=(None, 1) dtype=float64>, 'Application_Area_2': <tf.Tensor 'inputs_2:0' shape=(None, 1) dtype=string>, 'Application_Area_2_Weight': <tf.Tensor 'inputs_3:0' shape=(None, 1) dtype=float64>, 'Application_Area_3': <tf.Tensor 'inputs_4:0' shape=(None, 1) dtype=string>, 'Application_Area_3_Weight': <tf.Tensor 'inputs_5:0' shape=(None, 1) dtype=float64>, 'Green_Tech': <tf.Tensor 'inputs_12:0' shape=(None, 1) dtype=string>, 'SixT_2': <tf.Tensor 'inputs_31:0' shape=(None, 1) dtype=string>, 'Econ_Social': <tf.Tensor 'inputs_11:0' shape=(None, 1) dtype=string>, 'National_Strategy_2': <tf.Tensor 'inputs_23:0' shape=(None, 1) dtype=string>, 'RnD_Stage': <tf.Tensor 'inputs_26:0' shape=(None, 1) dtype=string>, 'Cowork_Cor': <tf.Tensor 'inputs_7:0' shape=(None, 1) dtype=string>, 'Cowork_Uni': <tf.Tensor 'inputs_9:0' shape=(None, 1) dtype=string>, 'Cowork_Inst': <tf.Tensor 'inputs_8:0' shape=(None, 1) dtype=string>, 'Cowork_Abroad': <tf.Tensor 'inputs_6:0' shape=(None, 1) dtype=string>, 'Cowork_etc': <tf.Tensor 'inputs_10:0' shape=(None, 1) dtype=string>, 'Log_RnD_Fund': <tf.Tensor 'inputs_14:0' shape=(None, 1) dtype=float64>, 'Log_Duration': <tf.Tensor 'inputs_13:0' shape=(None, 1) dtype=float64>}\n","Consider rewriting this model with the Functional API.\n","WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Year': <tf.Tensor 'Year:0' shape=(None, 1) dtype=string>, 'N_of_SCI': <tf.Tensor 'N_of_SCI:0' shape=(None, 1) dtype=float64>, 'N_of_Paper': <tf.Tensor 'N_of_Paper:0' shape=(None, 1) dtype=float64>, 'N_Patent_App': <tf.Tensor 'N_Patent_App:0' shape=(None, 1) dtype=float64>, 'N_Patent_Reg': <tf.Tensor 'N_Patent_Reg:0' shape=(None, 1) dtype=float64>, 'N_of_Korean_Patent': <tf.Tensor 'N_of_Korean_Patent:0' shape=(None, 1) dtype=float64>, 'N_of_Inter_Patent': <tf.Tensor 'N_of_Inter_Patent:0' shape=(None, 1) dtype=float64>, 'N_of_Patent': <tf.Tensor 'N_of_Patent:0' shape=(None, 1) dtype=float64>, 'Multi_Year': <tf.Tensor 'Multi_Year:0' shape=(None, 1) dtype=string>, 'RnD_Org': <tf.Tensor 'RnD_Org:0' shape=(None, 1) dtype=string>, 'Region': <tf.Tensor 'Region:0' shape=(None, 1) dtype=string>, 'STP_Code_11': <tf.Tensor 'STP_Code_11:0' shape=(None, 1) dtype=string>, 'STP_Code_1_Weight': <tf.Tensor 'STP_Code_1_Weight:0' shape=(None, 1) dtype=float64>, 'STP_Code_21': <tf.Tensor 'STP_Code_21:0' shape=(None, 1) dtype=string>, 'STP_Code_2_Weight': <tf.Tensor 'STP_Code_2_Weight:0' shape=(None, 1) dtype=float64>, 'Application_Area_1': <tf.Tensor 'Application_Area_1:0' shape=(None, 1) dtype=string>, 'Application_Area_1_Weight': <tf.Tensor 'Application_Area_1_Weight:0' shape=(None, 1) dtype=float64>, 'Application_Area_2': <tf.Tensor 'Application_Area_2:0' shape=(None, 1) dtype=string>, 'Application_Area_2_Weight': <tf.Tensor 'Application_Area_2_Weight:0' shape=(None, 1) dtype=float64>, 'Application_Area_3': <tf.Tensor 'Application_Area_3:0' shape=(None, 1) dtype=string>, 'Application_Area_3_Weight': <tf.Tensor 'Application_Area_3_Weight:0' shape=(None, 1) dtype=float64>, 'Green_Tech': <tf.Tensor 'Green_Tech:0' shape=(None, 1) dtype=string>, 'SixT_2': <tf.Tensor 'SixT_2:0' shape=(None, 1) dtype=string>, 'Econ_Social': <tf.Tensor 'Econ_Social:0' shape=(None, 1) dtype=string>, 'National_Strategy_2': <tf.Tensor 'National_Strategy_2:0' shape=(None, 1) dtype=string>, 'RnD_Stage': <tf.Tensor 'RnD_Stage:0' shape=(None, 1) dtype=string>, 'Cowork_Cor': <tf.Tensor 'Cowork_Cor:0' shape=(None, 1) dtype=string>, 'Cowork_Uni': <tf.Tensor 'Cowork_Uni:0' shape=(None, 1) dtype=string>, 'Cowork_Inst': <tf.Tensor 'Cowork_Inst:0' shape=(None, 1) dtype=string>, 'Cowork_Abroad': <tf.Tensor 'Cowork_Abroad:0' shape=(None, 1) dtype=string>, 'Cowork_etc': <tf.Tensor 'Cowork_etc:0' shape=(None, 1) dtype=string>, 'Log_RnD_Fund': <tf.Tensor 'Log_RnD_Fund:0' shape=(None, 1) dtype=float64>, 'Log_Duration': <tf.Tensor 'Log_Duration:0' shape=(None, 1) dtype=float64>}\n","Consider rewriting this model with the Functional API.\n","WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Year': <tf.Tensor 'Year:0' shape=(None, 1) dtype=string>, 'N_of_SCI': <tf.Tensor 'N_of_SCI:0' shape=(None, 1) dtype=float64>, 'N_of_Paper': <tf.Tensor 'N_of_Paper:0' shape=(None, 1) dtype=float64>, 'N_Patent_App': <tf.Tensor 'N_Patent_App:0' shape=(None, 1) dtype=float64>, 'N_Patent_Reg': <tf.Tensor 'N_Patent_Reg:0' shape=(None, 1) dtype=float64>, 'N_of_Korean_Patent': <tf.Tensor 'N_of_Korean_Patent:0' shape=(None, 1) dtype=float64>, 'N_of_Inter_Patent': <tf.Tensor 'N_of_Inter_Patent:0' shape=(None, 1) dtype=float64>, 'N_of_Patent': <tf.Tensor 'N_of_Patent:0' shape=(None, 1) dtype=float64>, 'Multi_Year': <tf.Tensor 'Multi_Year:0' shape=(None, 1) dtype=string>, 'RnD_Org': <tf.Tensor 'RnD_Org:0' shape=(None, 1) dtype=string>, 'Region': <tf.Tensor 'Region:0' shape=(None, 1) dtype=string>, 'STP_Code_11': <tf.Tensor 'STP_Code_11:0' shape=(None, 1) dtype=string>, 'STP_Code_1_Weight': <tf.Tensor 'STP_Code_1_Weight:0' shape=(None, 1) dtype=float64>, 'STP_Code_21': <tf.Tensor 'STP_Code_21:0' shape=(None, 1) dtype=string>, 'STP_Code_2_Weight': <tf.Tensor 'STP_Code_2_Weight:0' shape=(None, 1) dtype=float64>, 'Application_Area_1': <tf.Tensor 'Application_Area_1:0' shape=(None, 1) dtype=string>, 'Application_Area_1_Weight': <tf.Tensor 'Application_Area_1_Weight:0' shape=(None, 1) dtype=float64>, 'Application_Area_2': <tf.Tensor 'Application_Area_2:0' shape=(None, 1) dtype=string>, 'Application_Area_2_Weight': <tf.Tensor 'Application_Area_2_Weight:0' shape=(None, 1) dtype=float64>, 'Application_Area_3': <tf.Tensor 'Application_Area_3:0' shape=(None, 1) dtype=string>, 'Application_Area_3_Weight': <tf.Tensor 'Application_Area_3_Weight:0' shape=(None, 1) dtype=float64>, 'Green_Tech': <tf.Tensor 'Green_Tech:0' shape=(None, 1) dtype=string>, 'SixT_2': <tf.Tensor 'SixT_2:0' shape=(None, 1) dtype=string>, 'Econ_Social': <tf.Tensor 'Econ_Social:0' shape=(None, 1) dtype=string>, 'National_Strategy_2': <tf.Tensor 'National_Strategy_2:0' shape=(None, 1) dtype=string>, 'RnD_Stage': <tf.Tensor 'RnD_Stage:0' shape=(None, 1) dtype=string>, 'Cowork_Cor': <tf.Tensor 'Cowork_Cor:0' shape=(None, 1) dtype=string>, 'Cowork_Uni': <tf.Tensor 'Cowork_Uni:0' shape=(None, 1) dtype=string>, 'Cowork_Inst': <tf.Tensor 'Cowork_Inst:0' shape=(None, 1) dtype=string>, 'Cowork_Abroad': <tf.Tensor 'Cowork_Abroad:0' shape=(None, 1) dtype=string>, 'Cowork_etc': <tf.Tensor 'Cowork_etc:0' shape=(None, 1) dtype=string>, 'Log_RnD_Fund': <tf.Tensor 'Log_RnD_Fund:0' shape=(None, 1) dtype=float64>, 'Log_Duration': <tf.Tensor 'Log_Duration:0' shape=(None, 1) dtype=float64>}\n","Consider rewriting this model with the Functional API.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Function `_wrapped_model` contains input name(s) Application_Area_1, Application_Area_1_Weight, Application_Area_2, Application_Area_2_Weight, Application_Area_3, Application_Area_3_Weight, Cowork_Abroad, Cowork_Cor, Cowork_Inst, Cowork_Uni, Cowork_etc, Econ_Social, Green_Tech, Log_Duration, Log_RnD_Fund, Multi_Year, N_Patent_App, N_Patent_Reg, N_of_Inter_Patent, N_of_Korean_Patent, N_of_Paper, N_of_Patent, N_of_SCI, National_Strategy_2, Region, RnD_Org, RnD_Stage, STP_Code_11, STP_Code_1_Weight, STP_Code_21, STP_Code_2_Weight, SixT_2, Year with unsupported characters which will be renamed to application_area_1, application_area_1_weight, application_area_2, application_area_2_weight, application_area_3, application_area_3_weight, cowork_abroad, cowork_cor, cowork_inst, cowork_uni, cowork_etc, econ_social, green_tech, log_duration, log_rnd_fund, multi_year, n_patent_app, n_patent_reg, n_of_inter_patent, n_of_korean_patent, n_of_paper, n_of_patent, n_of_sci, national_strategy_2, region, rnd_org, rnd_stage, stp_code_11, stp_code_1_weight, stp_code_21, stp_code_2_weight, sixt_2, year in the SavedModel.\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Year': <tf.Tensor 'inputs/Year:0' shape=(None, 1) dtype=string>, 'N_of_SCI': <tf.Tensor 'inputs/N_of_SCI:0' shape=(None, 1) dtype=float64>, 'N_of_Paper': <tf.Tensor 'inputs/N_of_Paper:0' shape=(None, 1) dtype=float64>, 'N_Patent_App': <tf.Tensor 'inputs/N_Patent_App:0' shape=(None, 1) dtype=float64>, 'N_Patent_Reg': <tf.Tensor 'inputs/N_Patent_Reg:0' shape=(None, 1) dtype=float64>, 'N_of_Korean_Patent': <tf.Tensor 'inputs/N_of_Korean_Patent:0' shape=(None, 1) dtype=float64>, 'N_of_Inter_Patent': <tf.Tensor 'inputs/N_of_Inter_Patent:0' shape=(None, 1) dtype=float64>, 'N_of_Patent': <tf.Tensor 'inputs/N_of_Patent:0' shape=(None, 1) dtype=float64>, 'Multi_Year': <tf.Tensor 'inputs/Multi_Year:0' shape=(None, 1) dtype=string>, 'RnD_Org': <tf.Tensor 'inputs/RnD_Org:0' shape=(None, 1) dtype=string>, 'Region': <tf.Tensor 'inputs/Region:0' shape=(None, 1) dtype=string>, 'STP_Code_11': <tf.Tensor 'inputs/STP_Code_11:0' shape=(None, 1) dtype=string>, 'STP_Code_1_Weight': <tf.Tensor 'inputs/STP_Code_1_Weight:0' shape=(None, 1) dtype=float64>, 'STP_Code_21': <tf.Tensor 'inputs/STP_Code_21:0' shape=(None, 1) dtype=string>, 'STP_Code_2_Weight': <tf.Tensor 'inputs/STP_Code_2_Weight:0' shape=(None, 1) dtype=float64>, 'Application_Area_1': <tf.Tensor 'inputs/Application_Area_1:0' shape=(None, 1) dtype=string>, 'Application_Area_1_Weight': <tf.Tensor 'inputs/Application_Area_1_Weight:0' shape=(None, 1) dtype=float64>, 'Application_Area_2': <tf.Tensor 'inputs/Application_Area_2:0' shape=(None, 1) dtype=string>, 'Application_Area_2_Weight': <tf.Tensor 'inputs/Application_Area_2_Weight:0' shape=(None, 1) dtype=float64>, 'Application_Area_3': <tf.Tensor 'inputs/Application_Area_3:0' shape=(None, 1) dtype=string>, 'Application_Area_3_Weight': <tf.Tensor 'inputs/Application_Area_3_Weight:0' shape=(None, 1) dtype=float64>, 'Green_Tech': <tf.Tensor 'inputs/Green_Tech:0' shape=(None, 1) dtype=string>, 'SixT_2': <tf.Tensor 'inputs/SixT_2:0' shape=(None, 1) dtype=string>, 'Econ_Social': <tf.Tensor 'inputs/Econ_Social:0' shape=(None, 1) dtype=string>, 'National_Strategy_2': <tf.Tensor 'inputs/National_Strategy_2:0' shape=(None, 1) dtype=string>, 'RnD_Stage': <tf.Tensor 'inputs/RnD_Stage:0' shape=(None, 1) dtype=string>, 'Cowork_Cor': <tf.Tensor 'inputs/Cowork_Cor:0' shape=(None, 1) dtype=string>, 'Cowork_Uni': <tf.Tensor 'inputs/Cowork_Uni:0' shape=(None, 1) dtype=string>, 'Cowork_Inst': <tf.Tensor 'inputs/Cowork_Inst:0' shape=(None, 1) dtype=string>, 'Cowork_Abroad': <tf.Tensor 'inputs/Cowork_Abroad:0' shape=(None, 1) dtype=string>, 'Cowork_etc': <tf.Tensor 'inputs/Cowork_etc:0' shape=(None, 1) dtype=string>, 'Log_RnD_Fund': <tf.Tensor 'inputs/Log_RnD_Fund:0' shape=(None, 1) dtype=float64>, 'Log_Duration': <tf.Tensor 'inputs/Log_Duration:0' shape=(None, 1) dtype=float64>}\n","Consider rewriting this model with the Functional API.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Year': <tf.Tensor 'inputs/Year:0' shape=(None, 1) dtype=string>, 'N_of_SCI': <tf.Tensor 'inputs/N_of_SCI:0' shape=(None, 1) dtype=float64>, 'N_of_Paper': <tf.Tensor 'inputs/N_of_Paper:0' shape=(None, 1) dtype=float64>, 'N_Patent_App': <tf.Tensor 'inputs/N_Patent_App:0' shape=(None, 1) dtype=float64>, 'N_Patent_Reg': <tf.Tensor 'inputs/N_Patent_Reg:0' shape=(None, 1) dtype=float64>, 'N_of_Korean_Patent': <tf.Tensor 'inputs/N_of_Korean_Patent:0' shape=(None, 1) dtype=float64>, 'N_of_Inter_Patent': <tf.Tensor 'inputs/N_of_Inter_Patent:0' shape=(None, 1) dtype=float64>, 'N_of_Patent': <tf.Tensor 'inputs/N_of_Patent:0' shape=(None, 1) dtype=float64>, 'Multi_Year': <tf.Tensor 'inputs/Multi_Year:0' shape=(None, 1) dtype=string>, 'RnD_Org': <tf.Tensor 'inputs/RnD_Org:0' shape=(None, 1) dtype=string>, 'Region': <tf.Tensor 'inputs/Region:0' shape=(None, 1) dtype=string>, 'STP_Code_11': <tf.Tensor 'inputs/STP_Code_11:0' shape=(None, 1) dtype=string>, 'STP_Code_1_Weight': <tf.Tensor 'inputs/STP_Code_1_Weight:0' shape=(None, 1) dtype=float64>, 'STP_Code_21': <tf.Tensor 'inputs/STP_Code_21:0' shape=(None, 1) dtype=string>, 'STP_Code_2_Weight': <tf.Tensor 'inputs/STP_Code_2_Weight:0' shape=(None, 1) dtype=float64>, 'Application_Area_1': <tf.Tensor 'inputs/Application_Area_1:0' shape=(None, 1) dtype=string>, 'Application_Area_1_Weight': <tf.Tensor 'inputs/Application_Area_1_Weight:0' shape=(None, 1) dtype=float64>, 'Application_Area_2': <tf.Tensor 'inputs/Application_Area_2:0' shape=(None, 1) dtype=string>, 'Application_Area_2_Weight': <tf.Tensor 'inputs/Application_Area_2_Weight:0' shape=(None, 1) dtype=float64>, 'Application_Area_3': <tf.Tensor 'inputs/Application_Area_3:0' shape=(None, 1) dtype=string>, 'Application_Area_3_Weight': <tf.Tensor 'inputs/Application_Area_3_Weight:0' shape=(None, 1) dtype=float64>, 'Green_Tech': <tf.Tensor 'inputs/Green_Tech:0' shape=(None, 1) dtype=string>, 'SixT_2': <tf.Tensor 'inputs/SixT_2:0' shape=(None, 1) dtype=string>, 'Econ_Social': <tf.Tensor 'inputs/Econ_Social:0' shape=(None, 1) dtype=string>, 'National_Strategy_2': <tf.Tensor 'inputs/National_Strategy_2:0' shape=(None, 1) dtype=string>, 'RnD_Stage': <tf.Tensor 'inputs/RnD_Stage:0' shape=(None, 1) dtype=string>, 'Cowork_Cor': <tf.Tensor 'inputs/Cowork_Cor:0' shape=(None, 1) dtype=string>, 'Cowork_Uni': <tf.Tensor 'inputs/Cowork_Uni:0' shape=(None, 1) dtype=string>, 'Cowork_Inst': <tf.Tensor 'inputs/Cowork_Inst:0' shape=(None, 1) dtype=string>, 'Cowork_Abroad': <tf.Tensor 'inputs/Cowork_Abroad:0' shape=(None, 1) dtype=string>, 'Cowork_etc': <tf.Tensor 'inputs/Cowork_etc:0' shape=(None, 1) dtype=string>, 'Log_RnD_Fund': <tf.Tensor 'inputs/Log_RnD_Fund:0' shape=(None, 1) dtype=float64>, 'Log_Duration': <tf.Tensor 'inputs/Log_Duration:0' shape=(None, 1) dtype=float64>}\n","Consider rewriting this model with the Functional API.\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Year': <tf.Tensor 'inputs/Year:0' shape=(None, 1) dtype=string>, 'N_of_SCI': <tf.Tensor 'inputs/N_of_SCI:0' shape=(None, 1) dtype=float64>, 'N_of_Paper': <tf.Tensor 'inputs/N_of_Paper:0' shape=(None, 1) dtype=float64>, 'N_Patent_App': <tf.Tensor 'inputs/N_Patent_App:0' shape=(None, 1) dtype=float64>, 'N_Patent_Reg': <tf.Tensor 'inputs/N_Patent_Reg:0' shape=(None, 1) dtype=float64>, 'N_of_Korean_Patent': <tf.Tensor 'inputs/N_of_Korean_Patent:0' shape=(None, 1) dtype=float64>, 'N_of_Inter_Patent': <tf.Tensor 'inputs/N_of_Inter_Patent:0' shape=(None, 1) dtype=float64>, 'N_of_Patent': <tf.Tensor 'inputs/N_of_Patent:0' shape=(None, 1) dtype=float64>, 'Multi_Year': <tf.Tensor 'inputs/Multi_Year:0' shape=(None, 1) dtype=string>, 'RnD_Org': <tf.Tensor 'inputs/RnD_Org:0' shape=(None, 1) dtype=string>, 'Region': <tf.Tensor 'inputs/Region:0' shape=(None, 1) dtype=string>, 'STP_Code_11': <tf.Tensor 'inputs/STP_Code_11:0' shape=(None, 1) dtype=string>, 'STP_Code_1_Weight': <tf.Tensor 'inputs/STP_Code_1_Weight:0' shape=(None, 1) dtype=float64>, 'STP_Code_21': <tf.Tensor 'inputs/STP_Code_21:0' shape=(None, 1) dtype=string>, 'STP_Code_2_Weight': <tf.Tensor 'inputs/STP_Code_2_Weight:0' shape=(None, 1) dtype=float64>, 'Application_Area_1': <tf.Tensor 'inputs/Application_Area_1:0' shape=(None, 1) dtype=string>, 'Application_Area_1_Weight': <tf.Tensor 'inputs/Application_Area_1_Weight:0' shape=(None, 1) dtype=float64>, 'Application_Area_2': <tf.Tensor 'inputs/Application_Area_2:0' shape=(None, 1) dtype=string>, 'Application_Area_2_Weight': <tf.Tensor 'inputs/Application_Area_2_Weight:0' shape=(None, 1) dtype=float64>, 'Application_Area_3': <tf.Tensor 'inputs/Application_Area_3:0' shape=(None, 1) dtype=string>, 'Application_Area_3_Weight': <tf.Tensor 'inputs/Application_Area_3_Weight:0' shape=(None, 1) dtype=float64>, 'Green_Tech': <tf.Tensor 'inputs/Green_Tech:0' shape=(None, 1) dtype=string>, 'SixT_2': <tf.Tensor 'inputs/SixT_2:0' shape=(None, 1) dtype=string>, 'Econ_Social': <tf.Tensor 'inputs/Econ_Social:0' shape=(None, 1) dtype=string>, 'National_Strategy_2': <tf.Tensor 'inputs/National_Strategy_2:0' shape=(None, 1) dtype=string>, 'RnD_Stage': <tf.Tensor 'inputs/RnD_Stage:0' shape=(None, 1) dtype=string>, 'Cowork_Cor': <tf.Tensor 'inputs/Cowork_Cor:0' shape=(None, 1) dtype=string>, 'Cowork_Uni': <tf.Tensor 'inputs/Cowork_Uni:0' shape=(None, 1) dtype=string>, 'Cowork_Inst': <tf.Tensor 'inputs/Cowork_Inst:0' shape=(None, 1) dtype=string>, 'Cowork_Abroad': <tf.Tensor 'inputs/Cowork_Abroad:0' shape=(None, 1) dtype=string>, 'Cowork_etc': <tf.Tensor 'inputs/Cowork_etc:0' shape=(None, 1) dtype=string>, 'Log_RnD_Fund': <tf.Tensor 'inputs/Log_RnD_Fund:0' shape=(None, 1) dtype=float64>, 'Log_Duration': <tf.Tensor 'inputs/Log_Duration:0' shape=(None, 1) dtype=float64>}\n","Consider rewriting this model with the Functional API.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Year': <tf.Tensor 'inputs/Year:0' shape=(None, 1) dtype=string>, 'N_of_SCI': <tf.Tensor 'inputs/N_of_SCI:0' shape=(None, 1) dtype=float64>, 'N_of_Paper': <tf.Tensor 'inputs/N_of_Paper:0' shape=(None, 1) dtype=float64>, 'N_Patent_App': <tf.Tensor 'inputs/N_Patent_App:0' shape=(None, 1) dtype=float64>, 'N_Patent_Reg': <tf.Tensor 'inputs/N_Patent_Reg:0' shape=(None, 1) dtype=float64>, 'N_of_Korean_Patent': <tf.Tensor 'inputs/N_of_Korean_Patent:0' shape=(None, 1) dtype=float64>, 'N_of_Inter_Patent': <tf.Tensor 'inputs/N_of_Inter_Patent:0' shape=(None, 1) dtype=float64>, 'N_of_Patent': <tf.Tensor 'inputs/N_of_Patent:0' shape=(None, 1) dtype=float64>, 'Multi_Year': <tf.Tensor 'inputs/Multi_Year:0' shape=(None, 1) dtype=string>, 'RnD_Org': <tf.Tensor 'inputs/RnD_Org:0' shape=(None, 1) dtype=string>, 'Region': <tf.Tensor 'inputs/Region:0' shape=(None, 1) dtype=string>, 'STP_Code_11': <tf.Tensor 'inputs/STP_Code_11:0' shape=(None, 1) dtype=string>, 'STP_Code_1_Weight': <tf.Tensor 'inputs/STP_Code_1_Weight:0' shape=(None, 1) dtype=float64>, 'STP_Code_21': <tf.Tensor 'inputs/STP_Code_21:0' shape=(None, 1) dtype=string>, 'STP_Code_2_Weight': <tf.Tensor 'inputs/STP_Code_2_Weight:0' shape=(None, 1) dtype=float64>, 'Application_Area_1': <tf.Tensor 'inputs/Application_Area_1:0' shape=(None, 1) dtype=string>, 'Application_Area_1_Weight': <tf.Tensor 'inputs/Application_Area_1_Weight:0' shape=(None, 1) dtype=float64>, 'Application_Area_2': <tf.Tensor 'inputs/Application_Area_2:0' shape=(None, 1) dtype=string>, 'Application_Area_2_Weight': <tf.Tensor 'inputs/Application_Area_2_Weight:0' shape=(None, 1) dtype=float64>, 'Application_Area_3': <tf.Tensor 'inputs/Application_Area_3:0' shape=(None, 1) dtype=string>, 'Application_Area_3_Weight': <tf.Tensor 'inputs/Application_Area_3_Weight:0' shape=(None, 1) dtype=float64>, 'Green_Tech': <tf.Tensor 'inputs/Green_Tech:0' shape=(None, 1) dtype=string>, 'SixT_2': <tf.Tensor 'inputs/SixT_2:0' shape=(None, 1) dtype=string>, 'Econ_Social': <tf.Tensor 'inputs/Econ_Social:0' shape=(None, 1) dtype=string>, 'National_Strategy_2': <tf.Tensor 'inputs/National_Strategy_2:0' shape=(None, 1) dtype=string>, 'RnD_Stage': <tf.Tensor 'inputs/RnD_Stage:0' shape=(None, 1) dtype=string>, 'Cowork_Cor': <tf.Tensor 'inputs/Cowork_Cor:0' shape=(None, 1) dtype=string>, 'Cowork_Uni': <tf.Tensor 'inputs/Cowork_Uni:0' shape=(None, 1) dtype=string>, 'Cowork_Inst': <tf.Tensor 'inputs/Cowork_Inst:0' shape=(None, 1) dtype=string>, 'Cowork_Abroad': <tf.Tensor 'inputs/Cowork_Abroad:0' shape=(None, 1) dtype=string>, 'Cowork_etc': <tf.Tensor 'inputs/Cowork_etc:0' shape=(None, 1) dtype=string>, 'Log_RnD_Fund': <tf.Tensor 'inputs/Log_RnD_Fund:0' shape=(None, 1) dtype=float64>, 'Log_Duration': <tf.Tensor 'inputs/Log_Duration:0' shape=(None, 1) dtype=float64>}\n","Consider rewriting this model with the Functional API.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: /gdrive/My Drive/Colab Notebooks/DNN/alpha/modelsave/프로젝트_성공_0.825/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: /gdrive/My Drive/Colab Notebooks/DNN/alpha/modelsave/프로젝트_성공_0.825/assets\n"]}]}]}