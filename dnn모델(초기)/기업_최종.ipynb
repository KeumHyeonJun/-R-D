{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"기업_최종.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPMHjAu4QOxeH6G1nzkJ03d"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"96Gxoli3C7sy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634281067988,"user_tz":-540,"elapsed":22029,"user":{"displayName":"현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06235385304799063880"}},"outputId":"40d1425c-6111-4590-cb92-bdbf0b899308"},"source":["from google.colab import drive\n","drive.mount('/gdrive',force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n"]}]},{"cell_type":"code","metadata":{"id":"DidIAB0VihkO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634281081309,"user_tz":-540,"elapsed":13327,"user":{"displayName":"현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06235385304799063880"}},"outputId":"6135342d-c2e0-49e3-cb93-aa3094d3af21"},"source":["!pip install pymysql\n","!pip install -q sklearn\n","!pip install tensorflow_addons \n","!pip install pyyaml h5py  # HDF5 포맷으로 모델을 저장하기 위해서 필요합니다\n"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pymysql\n","  Downloading PyMySQL-1.0.2-py3-none-any.whl (43 kB)\n","\u001b[?25l\r\u001b[K     |███████▌                        | 10 kB 23.6 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 20 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 30 kB 34.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 40 kB 38.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 43 kB 2.2 MB/s \n","\u001b[?25hInstalling collected packages: pymysql\n","Successfully installed pymysql-1.0.2\n","Collecting tensorflow_addons\n","  Downloading tensorflow_addons-0.14.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 31.2 MB/s \n","\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n","Installing collected packages: tensorflow-addons\n","Successfully installed tensorflow-addons-0.14.0\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (3.13)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n","Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py) (1.19.5)\n"]}]},{"cell_type":"markdown","metadata":{"id":"DJh_WozpvTo_"},"source":["# 라이브러리 import"]},{"cell_type":"code","metadata":{"id":"-YL5Mu3VHVDu","executionInfo":{"status":"ok","timestamp":1634281081311,"user_tz":-540,"elapsed":13,"user":{"displayName":"현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06235385304799063880"}}},"source":["!mkdir -p saved_model"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"oMsLJe9EimpR","executionInfo":{"status":"ok","timestamp":1634281084376,"user_tz":-540,"elapsed":3074,"user":{"displayName":"현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06235385304799063880"}}},"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow import feature_column\n","from tensorflow.keras import layers\n","import tensorflow_addons as tfa\n","\n","\n","import os\n","import tempfile\n","\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","\n","import sklearn\n","from sklearn.metrics import confusion_matrix\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"pNyta2n5ivgL","executionInfo":{"status":"ok","timestamp":1634281084380,"user_tz":-540,"elapsed":8,"user":{"displayName":"현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06235385304799063880"}}},"source":["import pymysql\n"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"34UAFJ6bxG81"},"source":["# 데이터 전처리"]},{"cell_type":"code","metadata":{"id":"Jf4FgLo2inl_","executionInfo":{"status":"ok","timestamp":1634281093209,"user_tz":-540,"elapsed":8835,"user":{"displayName":"현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06235385304799063880"}}},"source":["conn = pymysql.connect(\n","    user = 'orlab',\n","    passwd = 'orlabghkdlxld123!',\n","    host = 'orlab.cl9jlcc8q0pr.ap-northeast-2.rds.amazonaws.com',\n","    db = 'Dataset_final',\n","    charset = 'utf8'\n",")\n","curs = conn.cursor(pymysql.cursors.DictCursor)\n","curs1 = conn.cursor(pymysql.cursors.DictCursor)\n","\n","curs.execute(\"select * from DS_Project_Company_2016_1\")\n","\n","df = curs.fetchall()\n","df = pd.DataFrame(df)\n"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"_dK1T2_BIZ9e","colab":{"base_uri":"https://localhost:8080/","height":860},"executionInfo":{"status":"ok","timestamp":1634281093652,"user_tz":-540,"elapsed":447,"user":{"displayName":"현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06235385304799063880"}},"outputId":"697dde61-e059-43b1-955c-bdee576a316d"},"source":["df"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>Project_ID</th>\n","      <th>Year</th>\n","      <th>N_of_SCI</th>\n","      <th>N_of_Paper</th>\n","      <th>N_Patent_App</th>\n","      <th>N_Patent_Reg</th>\n","      <th>N_of_Korean_Patent</th>\n","      <th>N_of_Inter_Patent</th>\n","      <th>N_of_Patent</th>\n","      <th>Multi_Year</th>\n","      <th>RnD_Org</th>\n","      <th>Region</th>\n","      <th>STP_Code_11</th>\n","      <th>STP_Code_1_Weight</th>\n","      <th>STP_Code_21</th>\n","      <th>STP_Code_2_Weight</th>\n","      <th>Application_Area_1</th>\n","      <th>Application_Area_1_Weight</th>\n","      <th>Application_Area_2</th>\n","      <th>Application_Area_2_Weight</th>\n","      <th>Application_Area_3</th>\n","      <th>Application_Area_3_Weight</th>\n","      <th>Green_Tech</th>\n","      <th>SixT_2</th>\n","      <th>Econ_Social</th>\n","      <th>National_Strategy_2</th>\n","      <th>RnD_Stage</th>\n","      <th>Cowork_Cor</th>\n","      <th>Cowork_Uni</th>\n","      <th>Cowork_Inst</th>\n","      <th>Cowork_Abroad</th>\n","      <th>Log_RnD_Fund</th>\n","      <th>Log_Duration</th>\n","      <th>Cowork_etc</th>\n","      <th>Sales</th>\n","      <th>Income</th>\n","      <th>Asset</th>\n","      <th>Capital</th>\n","      <th>Sales_Income_Ratio</th>\n","      <th>Asset_Income_Ratio</th>\n","      <th>Sales_Operation_Ratio</th>\n","      <th>Expense_Ratio</th>\n","      <th>Debt_Ratio</th>\n","      <th>IPO</th>\n","      <th>Comp_Type</th>\n","      <th>Listed_Market</th>\n","      <th>Administration</th>\n","      <th>External_Audit</th>\n","      <th>Survival</th>\n","      <th>Venture</th>\n","      <th>Innobiz</th>\n","      <th>Mainbiz</th>\n","      <th>Employees</th>\n","      <th>Closed</th>\n","      <th>Ten_Industry_1</th>\n","      <th>Ten_Industry_11</th>\n","      <th>Ten_Industry_111</th>\n","      <th>Researcher</th>\n","      <th>Comm_Success</th>\n","      <th>Comm_Success_Code1_4</th>\n","      <th>Comm_Success_Code2_5</th>\n","      <th>Comm_Success_Code3_6</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1275000075</td>\n","      <td>2013.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>SA01</td>\n","      <td>50.0</td>\n","      <td>LA02</td>\n","      <td>30.0</td>\n","      <td>X10</td>\n","      <td>50.0</td>\n","      <td>X99</td>\n","      <td>50.0</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>999</td>\n","      <td>20100</td>\n","      <td>8</td>\n","      <td>60000</td>\n","      <td>3</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>18.472324</td>\n","      <td>5.897157</td>\n","      <td>N</td>\n","      <td>5.195160e+05</td>\n","      <td>113112.0</td>\n","      <td>1.273918e+06</td>\n","      <td>517728.0</td>\n","      <td>21.772573</td>\n","      <td>8.879064</td>\n","      <td>22.744439</td>\n","      <td>0.638814</td>\n","      <td>0.593594</td>\n","      <td>일반</td>\n","      <td>주식</td>\n","      <td>대상아님</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>4</td>\n","      <td>일반과세자</td>\n","      <td>M</td>\n","      <td>M70</td>\n","      <td>M70111</td>\n","      <td>중소기업</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1345213293</td>\n","      <td>2013.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>5</td>\n","      <td>LB01</td>\n","      <td>80.0</td>\n","      <td>LB03</td>\n","      <td>20.0</td>\n","      <td>Y01</td>\n","      <td>100.0</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>999</td>\n","      <td>20100</td>\n","      <td>6</td>\n","      <td>60000</td>\n","      <td>1</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>17.353742</td>\n","      <td>7.509884</td>\n","      <td>N</td>\n","      <td>1.117283e+08</td>\n","      <td>7991778.0</td>\n","      <td>9.128148e+07</td>\n","      <td>58595026.0</td>\n","      <td>7.152867</td>\n","      <td>8.755092</td>\n","      <td>5.729728</td>\n","      <td>0.034798</td>\n","      <td>0.358084</td>\n","      <td>비영리단체</td>\n","      <td>기타</td>\n","      <td>대상아님</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>52</td>\n","      <td>일반과세자</td>\n","      <td>M</td>\n","      <td>M70</td>\n","      <td>M70111</td>\n","      <td>대학</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>1345231051</td>\n","      <td>2014.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>SI02</td>\n","      <td>100.0</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>Y15</td>\n","      <td>100.0</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>999</td>\n","      <td>10400</td>\n","      <td>7</td>\n","      <td>60000</td>\n","      <td>4</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>19.721267</td>\n","      <td>7.509336</td>\n","      <td>N</td>\n","      <td>8.209287e+07</td>\n","      <td>7862077.0</td>\n","      <td>3.143850e+08</td>\n","      <td>275071785.0</td>\n","      <td>9.577053</td>\n","      <td>2.500780</td>\n","      <td>-10.851424</td>\n","      <td>1.108514</td>\n","      <td>0.125048</td>\n","      <td>비영리단체</td>\n","      <td>학교</td>\n","      <td>대상아님</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>562</td>\n","      <td>일반과세자</td>\n","      <td>P</td>\n","      <td>P85</td>\n","      <td>P85302</td>\n","      <td>대학</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>1345231052</td>\n","      <td>2014.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>SI99</td>\n","      <td>100.0</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>Y17</td>\n","      <td>100.0</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>999</td>\n","      <td>60200</td>\n","      <td>7</td>\n","      <td>60000</td>\n","      <td>4</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>19.713930</td>\n","      <td>7.509336</td>\n","      <td>N</td>\n","      <td>1.364778e+06</td>\n","      <td>166841.0</td>\n","      <td>1.041825e+06</td>\n","      <td>922162.0</td>\n","      <td>12.224772</td>\n","      <td>16.014302</td>\n","      <td>1.650671</td>\n","      <td>0.146740</td>\n","      <td>0.114858</td>\n","      <td>비영리단체</td>\n","      <td>학교</td>\n","      <td>대상아님</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>5</td>\n","      <td>일반과세자</td>\n","      <td>J</td>\n","      <td>J63</td>\n","      <td>J63991</td>\n","      <td>대학</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>1345231053</td>\n","      <td>2014.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>13</td>\n","      <td>LB17</td>\n","      <td>100.0</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>Y02</td>\n","      <td>100.0</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>999</td>\n","      <td>20200</td>\n","      <td>7</td>\n","      <td>20300</td>\n","      <td>4</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>19.599336</td>\n","      <td>6.997597</td>\n","      <td>N</td>\n","      <td>4.366534e+07</td>\n","      <td>769070.0</td>\n","      <td>2.078784e+07</td>\n","      <td>11890312.0</td>\n","      <td>1.761282</td>\n","      <td>3.699615</td>\n","      <td>2.326291</td>\n","      <td>0.092816</td>\n","      <td>0.428016</td>\n","      <td>비영리단체</td>\n","      <td>기타</td>\n","      <td>대상아님</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>0</td>\n","      <td>일반과세자</td>\n","      <td>S</td>\n","      <td>S94</td>\n","      <td>S94990</td>\n","      <td>대학</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>49080</th>\n","      <td>65451</td>\n","      <td>9991006112</td>\n","      <td>2016.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>1.0</td>\n","      <td>6.0</td>\n","      <td>3.0</td>\n","      <td>9.0</td>\n","      <td>2</td>\n","      <td>8</td>\n","      <td>8</td>\n","      <td>ED04</td>\n","      <td>50.0</td>\n","      <td>EB03</td>\n","      <td>30.0</td>\n","      <td>Y08</td>\n","      <td>100.0</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>999</td>\n","      <td>10100</td>\n","      <td>7</td>\n","      <td>10100</td>\n","      <td>3</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>21.041720</td>\n","      <td>6.970731</td>\n","      <td>Y</td>\n","      <td>3.168320e+08</td>\n","      <td>1148516.0</td>\n","      <td>2.776038e+08</td>\n","      <td>120113845.0</td>\n","      <td>0.362500</td>\n","      <td>0.413725</td>\n","      <td>1.578971</td>\n","      <td>0.132878</td>\n","      <td>0.567319</td>\n","      <td>코스닥상장</td>\n","      <td>주식</td>\n","      <td>코스닥</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>Y</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>106</td>\n","      <td>일반과세자</td>\n","      <td>C</td>\n","      <td>C26</td>\n","      <td>C26295</td>\n","      <td>중견기업</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>49081</th>\n","      <td>65452</td>\n","      <td>9991006114</td>\n","      <td>2016.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>8</td>\n","      <td>8</td>\n","      <td>LC99</td>\n","      <td>100.0</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>X02</td>\n","      <td>100.0</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>999</td>\n","      <td>20200</td>\n","      <td>4</td>\n","      <td>60000</td>\n","      <td>3</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>21.808489</td>\n","      <td>6.747588</td>\n","      <td>Y</td>\n","      <td>1.033114e+09</td>\n","      <td>62902751.0</td>\n","      <td>1.422757e+09</td>\n","      <td>982047195.0</td>\n","      <td>6.088657</td>\n","      <td>4.421186</td>\n","      <td>6.716762</td>\n","      <td>0.228559</td>\n","      <td>0.309758</td>\n","      <td>상장</td>\n","      <td>주식</td>\n","      <td>코스피</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>Y</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>2012</td>\n","      <td>일반과세자</td>\n","      <td>C</td>\n","      <td>C21</td>\n","      <td>C21210</td>\n","      <td>중견기업</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>49082</th>\n","      <td>65454</td>\n","      <td>9991006122</td>\n","      <td>2016.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>8</td>\n","      <td>1</td>\n","      <td>LC03</td>\n","      <td>100.0</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>X02</td>\n","      <td>100.0</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>999</td>\n","      <td>20200</td>\n","      <td>4</td>\n","      <td>60000</td>\n","      <td>3</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>21.920324</td>\n","      <td>6.302621</td>\n","      <td>Y</td>\n","      <td>1.055348e+08</td>\n","      <td>10968552.0</td>\n","      <td>1.509786e+08</td>\n","      <td>118356910.0</td>\n","      <td>10.393303</td>\n","      <td>7.264972</td>\n","      <td>10.206674</td>\n","      <td>0.351096</td>\n","      <td>0.216068</td>\n","      <td>외감</td>\n","      <td>주식</td>\n","      <td>대상아님</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>Y</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>375</td>\n","      <td>일반과세자</td>\n","      <td>C</td>\n","      <td>C21</td>\n","      <td>C21210</td>\n","      <td>중견기업</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>49083</th>\n","      <td>65455</td>\n","      <td>9991006124</td>\n","      <td>2016.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>8</td>\n","      <td>EB02</td>\n","      <td>80.0</td>\n","      <td>EA03</td>\n","      <td>20.0</td>\n","      <td>Y08</td>\n","      <td>60.0</td>\n","      <td>Y09</td>\n","      <td>40.0</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>999</td>\n","      <td>30200</td>\n","      <td>7</td>\n","      <td>10500</td>\n","      <td>3</td>\n","      <td>Y</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>N</td>\n","      <td>20.482467</td>\n","      <td>6.998511</td>\n","      <td>N</td>\n","      <td>4.882565e+06</td>\n","      <td>745474.0</td>\n","      <td>4.860485e+06</td>\n","      <td>2671343.0</td>\n","      <td>15.268081</td>\n","      <td>15.337441</td>\n","      <td>10.514289</td>\n","      <td>0.288234</td>\n","      <td>0.450396</td>\n","      <td>일반</td>\n","      <td>주식</td>\n","      <td>대상아님</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>Y</td>\n","      <td>Y</td>\n","      <td>N</td>\n","      <td>73</td>\n","      <td>일반과세자</td>\n","      <td>C</td>\n","      <td>C26</td>\n","      <td>C26121</td>\n","      <td>중소기업</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>49084</th>\n","      <td>65456</td>\n","      <td>9991006126</td>\n","      <td>2016.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>8</td>\n","      <td>NC09</td>\n","      <td>50.0</td>\n","      <td>NC10</td>\n","      <td>30.0</td>\n","      <td>Y13</td>\n","      <td>50.0</td>\n","      <td>Y05</td>\n","      <td>50.0</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>424</td>\n","      <td>50100</td>\n","      <td>7</td>\n","      <td>30200</td>\n","      <td>4</td>\n","      <td>Y</td>\n","      <td>Y</td>\n","      <td>Y</td>\n","      <td>N</td>\n","      <td>20.584004</td>\n","      <td>6.998511</td>\n","      <td>N</td>\n","      <td>2.894517e+06</td>\n","      <td>-25103944.0</td>\n","      <td>1.276902e+07</td>\n","      <td>1125159.0</td>\n","      <td>-867.293023</td>\n","      <td>-196.600412</td>\n","      <td>-197.028243</td>\n","      <td>1.893346</td>\n","      <td>0.911884</td>\n","      <td>일반</td>\n","      <td>주식</td>\n","      <td>대상아님</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>15</td>\n","      <td>일반과세자</td>\n","      <td>C</td>\n","      <td>C20</td>\n","      <td>C20119</td>\n","      <td>중소기업</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>49085 rows × 63 columns</p>\n","</div>"],"text/plain":["       index  Project_ID  ... Comm_Success_Code2_5  Comm_Success_Code3_6\n","0          0  1275000075  ...                    1                     0\n","1          1  1345213293  ...                    0                     0\n","2          2  1345231051  ...                    1                     0\n","3          3  1345231052  ...                    0                     0\n","4          4  1345231053  ...                    1                     0\n","...      ...         ...  ...                  ...                   ...\n","49080  65451  9991006112  ...                    0                     0\n","49081  65452  9991006114  ...                    0                     0\n","49082  65454  9991006122  ...                    0                     0\n","49083  65455  9991006124  ...                    0                     0\n","49084  65456  9991006126  ...                    0                     0\n","\n","[49085 rows x 63 columns]"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"mfouTFJxbk4j","executionInfo":{"status":"ok","timestamp":1634281093654,"user_tz":-540,"elapsed":16,"user":{"displayName":"현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06235385304799063880"}}},"source":["df[\"Year\"] = df[\"Year\"].apply(str)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"zRzI-bN0rxHw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634281093655,"user_tz":-540,"elapsed":17,"user":{"displayName":"현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06235385304799063880"}},"outputId":"aa8f99ec-f4fc-4e69-ab50-2f1f09fd62bc"},"source":["df.columns"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['index', 'Project_ID', 'Year', 'N_of_SCI', 'N_of_Paper', 'N_Patent_App',\n","       'N_Patent_Reg', 'N_of_Korean_Patent', 'N_of_Inter_Patent',\n","       'N_of_Patent', 'Multi_Year', 'RnD_Org', 'Region', 'STP_Code_11',\n","       'STP_Code_1_Weight', 'STP_Code_21', 'STP_Code_2_Weight',\n","       'Application_Area_1', 'Application_Area_1_Weight', 'Application_Area_2',\n","       'Application_Area_2_Weight', 'Application_Area_3',\n","       'Application_Area_3_Weight', 'Green_Tech', 'SixT_2', 'Econ_Social',\n","       'National_Strategy_2', 'RnD_Stage', 'Cowork_Cor', 'Cowork_Uni',\n","       'Cowork_Inst', 'Cowork_Abroad', 'Log_RnD_Fund', 'Log_Duration',\n","       'Cowork_etc', 'Sales', 'Income', 'Asset', 'Capital',\n","       'Sales_Income_Ratio', 'Asset_Income_Ratio', 'Sales_Operation_Ratio',\n","       'Expense_Ratio', 'Debt_Ratio', 'IPO', 'Comp_Type', 'Listed_Market',\n","       'Administration', 'External_Audit', 'Survival', 'Venture', 'Innobiz',\n","       'Mainbiz', 'Employees', 'Closed', 'Ten_Industry_1', 'Ten_Industry_11',\n","       'Ten_Industry_111', 'Researcher', 'Comm_Success',\n","       'Comm_Success_Code1_4', 'Comm_Success_Code2_5', 'Comm_Success_Code3_6'],\n","      dtype='object')"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"wuXW6gjjn3Yp","executionInfo":{"status":"ok","timestamp":1634281093658,"user_tz":-540,"elapsed":13,"user":{"displayName":"현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06235385304799063880"}}},"source":["df['Sales'] = (df['Sales'] - df['Sales'].mean())/df['Sales'].std()\n","df['Income'] = (df['Income'] - df['Income'].mean())/df['Income'].std()\n","df['Asset'] = (df['Asset'] - df['Asset'].mean())/df['Asset'].std()\n","df['Capital'] = (df['Capital'] - df['Capital'].mean())/df['Capital'].std()\n","\n","df[\"Employees\"] = np.log1p(df[\"Employees\"])"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hAfDkd1Gvv1Y"},"source":["# feature_columns 생성"]},{"cell_type":"code","metadata":{"id":"Av4KNrTh2-yf","executionInfo":{"status":"ok","timestamp":1634281094687,"user_tz":-540,"elapsed":1041,"user":{"displayName":"현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06235385304799063880"}}},"source":["\n","feature_columns = []\n","\n","for header in ['Log_RnD_Fund','Log_Duration','N_of_SCI','N_of_Paper','N_Patent_App','N_Patent_Reg','N_of_Korean_Patent','N_of_Inter_Patent',\n","               'N_of_Patent','STP_Code_1_Weight','STP_Code_2_Weight','Application_Area_1_Weight','Application_Area_2_Weight','Application_Area_3_Weight','Sales','Income','Asset','Capital',\n","               'Sales_Income_Ratio','Asset_Income_Ratio', 'Sales_Operation_Ratio', 'Expense_Ratio','Debt_Ratio','Employees']:\n","    feature_columns.append(feature_column.numeric_column(header, dtype=tf.dtypes.float64 ))\n","\n","# 범주형 열(Categorical column)은 특정 문자열을 수치형으로 매핑하여 전달\n","\n","#IPO\n","df[\"IPO\"] = df[\"IPO\"].apply(str)\n","IPO = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'IPO', df['IPO'].unique() )\n","IPO_hot = tf.feature_column.indicator_column(IPO)\n","feature_columns.append(IPO_hot)\n","\n","#Comp_Type\n","df[\"Comp_Type\"] = df[\"Comp_Type\"].apply(str)\n","Comp_Type = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'Comp_Type', df['Comp_Type'].unique() )\n","Comp_Type_hot = tf.feature_column.indicator_column(Comp_Type)\n","feature_columns.append(Comp_Type_hot)\n","\n","#Listed_Market\n","df[\"Listed_Market\"] = df[\"Listed_Market\"].apply(str)\n","Listed_Market = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'Listed_Market', df['Listed_Market'].unique() )\n","Listed_Market_hot = tf.feature_column.indicator_column(Listed_Market)\n","feature_columns.append(Listed_Market_hot)\n","\n","#Administration\n","df[\"Administration\"] = df[\"Administration\"].apply(str)\n","Administration = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'Administration', df['Administration'].unique() )\n","Administration_hot = tf.feature_column.indicator_column(Administration)\n","feature_columns.append(Administration_hot)\n","\n","#External_Audit\n","df[\"External_Audit\"] = df[\"External_Audit\"].apply(str)\n","External_Audit = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'External_Audit', df['External_Audit'].unique() )\n","External_Audit_hot = tf.feature_column.indicator_column(External_Audit)\n","feature_columns.append(External_Audit_hot)\n","\n","#Survival\n","df[\"Survival\"] = df[\"Survival\"].apply(str)\n","Survival = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'Survival', df['Survival'].unique() )\n","Survival_hot = tf.feature_column.indicator_column(Survival)\n","feature_columns.append(Survival_hot)\n","\n","#Venture\n","df[\"Venture\"] = df[\"Venture\"].apply(str)\n","Venture = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'Venture', df['Venture'].unique() )\n","Venture_hot = tf.feature_column.indicator_column(Venture)\n","feature_columns.append(Venture_hot)\n","\n","#Innobiz\n","df[\"Innobiz\"] = df[\"Innobiz\"].apply(str)\n","Innobiz = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'Innobiz', df['Innobiz'].unique() )\n","Innobiz_hot = tf.feature_column.indicator_column(Innobiz)\n","feature_columns.append(Innobiz_hot)\n","\n","#Mainbiz\n","df[\"Mainbiz\"] = df[\"Mainbiz\"].apply(str)\n","Mainbiz = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'Mainbiz', df['Mainbiz'].unique() )\n","Mainbiz_hot = tf.feature_column.indicator_column(Mainbiz)\n","feature_columns.append(Mainbiz_hot)\n","\n","#Closed\n","df[\"Closed\"] = df[\"Closed\"].apply(str)\n","Closed = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'Closed', df['Closed'].unique() )\n","Closed_hot = tf.feature_column.indicator_column(Closed)\n","feature_columns.append(Closed_hot)\n","\n","#Ten_Industry_11\n","df[\"Ten_Industry_11\"] = df[\"Ten_Industry_11\"].apply(str)\n","Ten_Industry_11 = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'Ten_Industry_11', df['Ten_Industry_11'].unique() )\n","Ten_Industry_11_hot = tf.feature_column.indicator_column(Ten_Industry_11)\n","feature_columns.append(Ten_Industry_11_hot)\n","\n","#Researcher\n","df[\"Researcher\"] = df[\"Researcher\"].apply(str)\n","Researcher = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'Researcher', df['Researcher'].unique() )\n","Researcher_hot = tf.feature_column.indicator_column(Researcher)\n","feature_columns.append(Researcher_hot)\n","\n","#Year\n","df[\"Year\"] = df[\"Year\"].apply(str)\n","Year = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'Year', df['Year'].unique() )\n","Year_hot = tf.feature_column.indicator_column(Year)\n","feature_columns.append(Year_hot)\n","\n","\n","#Multi_Year\n","df[\"Multi_Year\"] = df[\"Multi_Year\"].apply(str)\n","Multi_Year = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'Multi_Year', df['Multi_Year'].unique() )\n","Multi_Year_one_hot = tf.feature_column.indicator_column(Multi_Year)\n","feature_columns.append(Multi_Year_one_hot)\n","\n","\n","#RnD_Org\n","df[\"RnD_Org\"] = df[\"RnD_Org\"].apply(str)\n","RnD_Org = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'RnD_Org', df['RnD_Org'].unique() )\n","RnD_Org_one_hot = tf.feature_column.indicator_column(RnD_Org)\n","feature_columns.append(RnD_Org_one_hot)\n","\n","#Region\n","df[\"Region\"] = df[\"Region\"].apply(str)\n","\n","Region = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'Region', df['Region'].unique() )\n","Region_one_hot = tf.feature_column.indicator_column(Region)\n","feature_columns.append(Region_one_hot)\n","\n","#STP_Code_11\n","df[\"STP_Code_11\"] = df[\"STP_Code_11\"].apply(str)\n","\n","STP_Code_11 = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'STP_Code_11', df['STP_Code_11'].unique() )\n","STP_Code_11_one_hot = tf.feature_column.indicator_column(STP_Code_11)\n","feature_columns.append(STP_Code_11_one_hot)\n","\n","\n","#STP_Code_21\n","df[\"STP_Code_21\"] = df[\"STP_Code_21\"].apply(str)\n","\n","STP_Code_21 = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'STP_Code_21', df['STP_Code_21'].unique() )\n","STP_Code_21_one_hot = tf.feature_column.indicator_column(STP_Code_21)\n","feature_columns.append(STP_Code_21_one_hot)\n","\n","\n","\n","#Application_Area_1\n","df[\"Application_Area_1\"] = df[\"Application_Area_1\"].apply(str)\n","\n","Application_Area_1 = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'Application_Area_1', df['Application_Area_1'].unique() )\n","Application_Area_1_one_hot = tf.feature_column.indicator_column(Application_Area_1)\n","feature_columns.append(Application_Area_1_one_hot)\n","\n","\n","\n","#Application_Area_2\n","df[\"Application_Area_2\"] = df[\"Application_Area_2\"].apply(str)\n","\n","Application_Area_2 = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'Application_Area_2', df['Application_Area_2'].unique() )\n","Application_Area_2_one_hot = tf.feature_column.indicator_column(Application_Area_2)\n","feature_columns.append(Application_Area_2_one_hot)\n","\n","#Application_Area_3\n","df[\"Application_Area_3\"] = df[\"Application_Area_3\"].apply(str)\n","\n","Application_Area_3 = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'Application_Area_3', df['Application_Area_3'].unique() )\n","Application_Area_3_one_hot = tf.feature_column.indicator_column(Application_Area_3)\n","feature_columns.append(Application_Area_3_one_hot)\n","\n","\n","\n","#Green_Tech\n","df[\"Green_Tech\"] = df[\"Green_Tech\"].apply(str)\n","\n","Green_Tech = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'Green_Tech', df['Green_Tech'].unique() )\n","Green_Tech_one_hot = tf.feature_column.indicator_column(Green_Tech)\n","feature_columns.append(Green_Tech_one_hot)\n","\n","\n","\n","#SixT_2\n","df[\"SixT_2\"] = df[\"SixT_2\"].apply(str)\n","SixT_2 = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'SixT_2', df['SixT_2'].unique() )\n","SixT_2_one_hot = tf.feature_column.indicator_column(SixT_2)\n","feature_columns.append(SixT_2_one_hot)\n","\n","\n","#Econ_Social\n","df[\"Econ_Social\"] = df[\"Econ_Social\"].apply(str)\n","Econ_Social = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'Econ_Social', df['Econ_Social'].unique() )\n","Econ_Social_one_hot = tf.feature_column.indicator_column(Econ_Social)\n","feature_columns.append(Econ_Social_one_hot)\n","\n","#National_Strategy_2\n","df[\"National_Strategy_2\"] = df[\"National_Strategy_2\"].apply(str)\n","National_Strategy_2 = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'National_Strategy_2', df['National_Strategy_2'].unique() )\n","National_Strategy_2_one_hot = tf.feature_column.indicator_column(National_Strategy_2)\n","feature_columns.append(National_Strategy_2_one_hot)\n","\n","#RnD_Stage\n","df[\"RnD_Stage\"] = df[\"RnD_Stage\"].apply(str)\n","RnD_Stage = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'RnD_Stage', df['RnD_Stage'].unique() )\n","RnD_Stage_one_hot = tf.feature_column.indicator_column(RnD_Stage)\n","feature_columns.append(RnD_Stage_one_hot)\n","\n","#Cowork_Cor\n","df[\"Cowork_Cor\"] = df[\"Cowork_Cor\"].apply(str)\n","Cowork_Cor = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'Cowork_Cor', df['Cowork_Cor'].unique() )\n","Cowork_Cor_one_hot = tf.feature_column.indicator_column(Cowork_Cor)\n","feature_columns.append(Cowork_Cor_one_hot)\n","\n","#Cowork_Uni\n","df[\"Cowork_Uni\"] = df[\"Cowork_Uni\"].apply(str)\n","Cowork_Uni = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'Cowork_Uni', df['Cowork_Uni'].unique() )\n","Cowork_Uni_one_hot = tf.feature_column.indicator_column(Cowork_Uni)\n","feature_columns.append(Cowork_Uni_one_hot)\n","\n","#Cowork_Inst\n","df[\"Cowork_Inst\"] = df[\"Cowork_Inst\"].apply(str)\n","Cowork_Inst = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'Cowork_Inst', df['Cowork_Inst'].unique() )\n","Cowork_Inst_one_hot = tf.feature_column.indicator_column(Cowork_Inst)\n","feature_columns.append(Cowork_Inst_one_hot)\n","\n","#Cowork_Abroad\n","df[\"Cowork_Abroad\"] = df[\"Cowork_Abroad\"].apply(str)\n","Cowork_Abroad = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'Cowork_Abroad', df['Cowork_Abroad'].unique() )\n","Cowork_Abroad_one_hot = tf.feature_column.indicator_column(Cowork_Abroad)\n","feature_columns.append(Cowork_Abroad_one_hot)\n","\n","#Cowork_etc\n","df[\"Cowork_etc\"] = df[\"Cowork_etc\"].apply(str)\n","Cowork_etc = tf.feature_column.categorical_column_with_vocabulary_list(\n","      'Cowork_etc', df['Cowork_etc'].unique() )\n","Cowork_etc_one_hot = tf.feature_column.indicator_column(Cowork_etc)\n","feature_columns.append(Cowork_etc_one_hot)\n","\n","\n"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"YeFTa1NA6yVD","executionInfo":{"status":"ok","timestamp":1634281094688,"user_tz":-540,"elapsed":35,"user":{"displayName":"현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06235385304799063880"}}},"source":["feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"HaWHIcma6zry","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634281094688,"user_tz":-540,"elapsed":33,"user":{"displayName":"현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06235385304799063880"}},"outputId":"9ecf0b45-f5ab-4b17-b4c6-25daf3216cd8"},"source":["feature_columns"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[NumericColumn(key='Log_RnD_Fund', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n"," NumericColumn(key='Log_Duration', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n"," NumericColumn(key='N_of_SCI', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n"," NumericColumn(key='N_of_Paper', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n"," NumericColumn(key='N_Patent_App', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n"," NumericColumn(key='N_Patent_Reg', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n"," NumericColumn(key='N_of_Korean_Patent', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n"," NumericColumn(key='N_of_Inter_Patent', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n"," NumericColumn(key='N_of_Patent', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n"," NumericColumn(key='STP_Code_1_Weight', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n"," NumericColumn(key='STP_Code_2_Weight', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n"," NumericColumn(key='Application_Area_1_Weight', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n"," NumericColumn(key='Application_Area_2_Weight', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n"," NumericColumn(key='Application_Area_3_Weight', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n"," NumericColumn(key='Sales', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n"," NumericColumn(key='Income', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n"," NumericColumn(key='Asset', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n"," NumericColumn(key='Capital', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n"," NumericColumn(key='Sales_Income_Ratio', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n"," NumericColumn(key='Asset_Income_Ratio', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n"," NumericColumn(key='Sales_Operation_Ratio', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n"," NumericColumn(key='Expense_Ratio', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n"," NumericColumn(key='Debt_Ratio', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n"," NumericColumn(key='Employees', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='IPO', vocabulary_list=('일반', '비영리단체', '외감', '공기관', '상장', '폐업', '피흡수합병', '코스닥상장', '코넥스', '코스닥관리', '상장관리'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Comp_Type', vocabulary_list=('주식', '기타', '학교', '정부투자기관', '단체/협회', '합자', '유한', '조합', '합명'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Listed_Market', vocabulary_list=('대상아님', '코스피', '코스닥', '코넥스', 'K-OTC'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Administration', vocabulary_list=('N', 'Y'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='External_Audit', vocabulary_list=('N', 'Y'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Survival', vocabulary_list=('Y', 'N'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Venture', vocabulary_list=('N', 'Y'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Innobiz', vocabulary_list=('N', 'Y'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Mainbiz', vocabulary_list=('N', 'Y'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Closed', vocabulary_list=('일반과세자', '폐업자', '면세사업자', '휴업자', '비영리법인'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Ten_Industry_11', vocabulary_list=('M70', 'P85', 'J63', 'S94', 'N75', 'J59', 'C28', 'J58', 'C31', 'C27', 'H50', 'R90', 'C20', 'C26', 'M73', 'F42', 'G46', 'J62', 'M71', 'C15', 'C33', 'C29', 'C17', 'C10', 'C30', 'G47', 'O84', 'J60', 'J61', 'F41', 'A01', 'C16', 'C23', 'A02', 'C11', 'N74', 'C21', 'C13', 'C22', 'C14', 'M72', 'C24', 'K64', 'H51', 'C25', 'C19', 'E38', 'D35', 'C32', 'G45', 'A03', 'Q87', 'E37', 'L68', 'H52', 'C18', 'E36', 'S96', 'B07', 'Q86', 'B05', 'S95', 'K66', 'E39', 'N76', 'C34', 'B06', 'I56', 'H49', 'R91', 'I55', 'B08', 'C12'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Researcher', vocabulary_list=('중소기업', '대학', '대기업', '기타', '출연연구소', '중견기업', '국공립연구소', '정부부처'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Year', vocabulary_list=('2013.0', '2014.0', '2015.0', '2016.0'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Multi_Year', vocabulary_list=('2', '1'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='RnD_Org', vocabulary_list=('5', '3', '4', '99', '2', '8', '1', '6'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Region', vocabulary_list=('1', '5', '2', '13', '12', '10', '6', '8', '14', '3', '16', '11', '99', '9', '15', '7', '4', '17', '19'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='STP_Code_11', vocabulary_list=('SA01', 'LB01', 'SI02', 'SI99', 'LB17', 'LB07', 'EH03', 'SH02', 'EE02', 'HE04', 'LB19', 'ED09', 'EE08', 'ND05', 'EH06', 'ND07', 'HE14', 'NB05', 'ED08', 'HE13', 'SF07', 'LB12', 'EC05', 'EA02', 'HE12', 'EE03', 'HE99', 'HE15', 'HE02', 'EE99', 'HE08', 'HE06', 'EE01', 'LB18', 'LB02', 'LB03', 'LB99', 'LB08', 'LA09', 'LB20', 'LA02', 'LC03', 'LC05', 'EA11', 'EE04', 'EE12', 'EB03', 'ED10', 'ED01', 'EC09', 'EH11', 'EH14', 'NC05', 'EA04', 'EC07', 'EC06', 'EA08', 'EE06', 'SD02', 'EA10', 'ED05', 'ED07', 'SE05', 'ED02', 'ED03', 'EA09', 'EA05', 'EE11', 'SE99', 'NC02', 'NC99', 'EA03', 'EB01', 'EB06', 'EB05', 'LC04', 'LC10', 'LA07', 'EF06', 'EE09', 'EH01', 'ED04', 'EE10', 'ED06', 'EA07', 'HE03', 'EE13', 'EB02', 'EF05', 'EE07', 'LC06', 'EF04', 'EC01', 'EH02', 'ED99', 'EB99', 'LA99', 'EA99', 'LC99', 'EI04', 'EI99', 'ED11', 'EA01', 'EF99', 'EE05', 'EH07', 'LB13', 'EC08', 'EA06', 'EB04', 'EC99', 'EI08', 'EC02', 'EF02', 'EI11', 'LB06', 'LB04', 'LA08', 'EC04', 'LC11', 'LC12', 'SH99', 'EC03', 'HE07', 'NC03', 'OC03', 'LC07', 'LB15', 'SC10', 'ND09', 'EH05', 'EG09', 'EH13', 'EG06', 'LA10', 'ND08', 'LC02', 'NC09', 'EG02', 'LC14', 'EI12', 'SE04', 'EH08', 'LC01', 'EG07', 'EB08', 'EH12', 'EI05', 'NB04', 'SC12', 'EF03', 'EA14', 'SE03', 'EF01', 'NC10', 'ND10', 'NC07', 'SD08', 'LA03', 'OC99', 'EB07', 'SB11', 'SC99', 'SC11', 'SB99', 'LC15', 'EG04', 'EG03', 'EH09', 'SH01', 'NC08', 'LC13', 'OA04', 'EC10', 'EI10', 'SI05', 'LC08', 'EG99', 'SC06', 'EE14', 'OB02', 'SE06', 'NC01', 'SC04', 'EI07', 'ND01', 'SB06', 'SC14', 'SB02', 'SI03', 'LB05', 'LA01', 'OB99', 'OA02', 'EH15', 'SC07', 'SF02', 'SH06', 'EI03', 'LA06', 'EH99', 'SI01', 'EI02', 'SC13', 'LB16', 'EH10', 'HC12', 'NC04', 'OB01', 'EI06', 'NC06', 'EH04', 'EI09', 'LB11', 'SC08', 'HE05', 'SF99', 'LB10', 'SH04', 'LB14', 'LB09', 'EA12', 'LA05', 'NA08', 'HC05', 'SH07', 'LA04', 'LA11', 'HE01', 'NA05', 'EG05', 'NB09', 'ZZ99', 'SB12', 'ZZ', 'SB08', 'SI07', 'EA13', 'ND14', 'ND02', 'ND04', 'ND06', 'SF01', 'EG01', 'EG08', 'LC09', 'SH08', 'EA15', 'SF06', 'SD09', 'NB06', 'NB07', 'NB99', 'SH03', 'NA07', 'SC16', 'HE10', 'SD99', 'OA03', 'SA07', 'SA99', 'ND99', 'EI01', 'SD01', 'ND13', 'HC01'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='STP_Code_21', vocabulary_list=('LA02', 'LB03', 'None', 'EH02', 'EC02', 'EE11', 'NC05', 'EE02', 'EC06', 'EH11', 'HE04', 'EE08', 'EE03', 'EE07', 'HE14', 'LA09', 'LA05', 'NA01', 'LB18', 'LB02', 'LB05', 'EC07', 'ED02', 'EA01', 'EB99', 'OB02', 'EC03', 'NC09', 'EA05', 'EB04', 'EB03', 'EC09', 'ED05', 'EC08', 'EH01', 'EA09', 'EA03', 'LC04', 'LC03', 'EB02', 'EF06', 'EB06', 'NC08', 'EE04', 'EF05', 'EE06', 'ED01', 'EA02', 'SI05', 'EH08', 'ED03', 'EB01', 'EA04', 'EG07', 'ED04', 'ED10', 'EF99', 'EF01', 'EH07', 'LA08', 'EA07', 'EH14', 'EF04', 'OB01', 'EA10', 'ED09', 'LB08', 'ED07', 'EA14', 'EE99', 'LB17', 'EC01', 'NC02', 'NC04', 'EI04', 'EB07', 'EI99', 'ED06', 'LB06', 'SH02', 'EA08', 'EC05', 'HE10', 'EB05', 'HE08', 'EE10', 'EE01', 'LC11', 'LB20', 'LB19', 'EE09', 'SE05', 'LC14', 'LC10', 'EA99', 'LB99', 'ND06', 'EH09', 'NC06', 'NC03', 'LA07', 'LA10', 'ED08', 'EA06', 'EC99', 'EE12', 'EI05', 'NB05', 'SI02', 'LC06', 'LB07', 'ED11', 'ED99', 'LC15', 'HE07', 'OA04', 'LC05', 'NC01', 'EI09', 'NA06', 'EC04', 'SF07', 'LC09', 'NC07', 'EI12', 'SC10', 'EF02', 'LB15', 'SC07', 'SC12', 'SC99', 'EH12', 'EG09', 'EG99', 'EG02', 'EB08', 'EI10', 'EA11', 'LC02', 'EG08', 'SD05', 'NB06', 'EE14', 'EE05', 'NB01', 'HE03', 'NC99', 'ND10', 'LC01', 'LC99', 'LC07', 'LB16', 'LB14', 'LB01', 'LA04', 'ND01', 'LB04', 'LA99', 'LA03', 'EH04', 'NB99', 'EI08', 'EI03', 'EH10', 'EE13', 'EH06', 'LC08', 'SC11', 'SB12', 'NC10', 'EG04', 'LB12', 'NA05', 'ND05', 'NA07', 'HE13', 'LA11', 'SE99', 'LB09', 'LB10', 'LB11', 'LA06', 'EF03', 'EG06', 'EG03', 'EH05', 'EI06', 'LB13', 'NB04', 'ND04', 'EH99', 'OC03', 'EG05', 'ND12', 'EI11', 'NB09', 'EH13', 'EA15', 'NA09', 'SC06', 'SI01', 'LC13', 'OA03', 'LA01', 'ND09', 'ND08', 'ND07', 'LC12', 'EI01', 'SF02', 'EI02', 'SF01', 'SH99', 'EA12', 'OC99', 'ND13', 'SB06', 'SB11', 'SD02', 'EA13', 'SH06', 'SD08', 'SG06', 'SG03', 'SH01'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Application_Area_1', vocabulary_list=('X10', 'Y01', 'Y15', 'Y17', 'Y02', 'X12', 'Y18', 'X09', 'Y16', 'X11', 'Y05', 'Y99', 'Y10', 'X99', 'Y08', 'Y19', 'Y04', 'X01', 'X02', 'Y06', 'Y07', 'Y03', 'X03', 'Y11', 'Y09', 'X05', 'Y13', 'X07', 'Y12', 'Y14', 'X08', 'X04', 'X06'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Application_Area_2', vocabulary_list=('X99', 'None', 'Y10', 'Y08', 'Y16', 'X07', 'X08', 'Y17', 'Y19', 'Y99', 'X11', 'X05', 'Y09', 'Y05', 'Y07', 'Y13', 'X09', 'X12', 'Y06', 'X02', 'Y14', 'Y15', 'Y01', 'Y02', 'Y11', 'Y18', 'X03', 'Y12', 'X10', 'Y03', 'X01', 'X04', 'X06'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Application_Area_3', vocabulary_list=('None', 'X05', 'Y09', 'X09', 'X99', 'Y15', 'Y06', 'Y11', 'Y99', 'Y08', 'Y18', 'Y07', 'Y17', 'Y05', 'Y10', 'X12', 'Y01', 'X01', 'X02', 'X03', 'Y02', 'X11', 'X10', 'X08', 'Y16', 'Y13', 'X04', 'Y04', 'Y03', 'Y19', 'X06', 'Y14', 'X07'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Green_Tech', vocabulary_list=('999', '111', '112', '422', '332', '511', '344', '341', '222', '354', '351', '325', '322', '331', '326', '432', '226', '324', '423', '221', '352', '213', '227', '321', '312', '431', '412', '224', '212', '244', '211', '214', '225', '343', '424', '323', '353', '327', '234', '215', '441', '421', '342', '411', '237', '442', '413', '245', '311', '241', '243', '223', '236', '242', '900', '235', '232', '231', '233', '313'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='SixT_2', vocabulary_list=('20100', '10400', '60200', '20200', '70000', '20300', '10300', '50200', '40100', '50100', '50400', '60100', '60300', '50300', '10200', '10100', '30400', '30100', '30200', '40300', '30300', '40400', '40200'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Econ_Social', vocabulary_list=('8', '6', '7', '14', '3', '13', '11', '4', '12', '5', '1', '2', '9'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='National_Strategy_2', vocabulary_list=('60000', '20300', '50300', '20100', '10300', '10100', '30100', '30200', '50100', '10200', '40200', '10500', '50200', '20200', '20400', '40300', '20500', '10400', '30300', '40100', '30400'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='RnD_Stage', vocabulary_list=('3', '1', '4', '2'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Cowork_Cor', vocabulary_list=('N', 'Y'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Cowork_Uni', vocabulary_list=('N', 'Y'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Cowork_Inst', vocabulary_list=('N', 'Y'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Cowork_Abroad', vocabulary_list=('N', 'Y'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n"," IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Cowork_etc', vocabulary_list=('N', 'Y'), dtype=tf.string, default_value=-1, num_oov_buckets=0))]"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"fufnbPq2_0ZF"},"source":["# train, test, val split"]},{"cell_type":"code","metadata":{"id":"upL1RJgxvcvh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634281094689,"user_tz":-540,"elapsed":27,"user":{"displayName":"현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06235385304799063880"}},"outputId":"a4b2d05f-f6b1-47c6-eba7-c37564944b68"},"source":["df.columns"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['index', 'Project_ID', 'Year', 'N_of_SCI', 'N_of_Paper', 'N_Patent_App',\n","       'N_Patent_Reg', 'N_of_Korean_Patent', 'N_of_Inter_Patent',\n","       'N_of_Patent', 'Multi_Year', 'RnD_Org', 'Region', 'STP_Code_11',\n","       'STP_Code_1_Weight', 'STP_Code_21', 'STP_Code_2_Weight',\n","       'Application_Area_1', 'Application_Area_1_Weight', 'Application_Area_2',\n","       'Application_Area_2_Weight', 'Application_Area_3',\n","       'Application_Area_3_Weight', 'Green_Tech', 'SixT_2', 'Econ_Social',\n","       'National_Strategy_2', 'RnD_Stage', 'Cowork_Cor', 'Cowork_Uni',\n","       'Cowork_Inst', 'Cowork_Abroad', 'Log_RnD_Fund', 'Log_Duration',\n","       'Cowork_etc', 'Sales', 'Income', 'Asset', 'Capital',\n","       'Sales_Income_Ratio', 'Asset_Income_Ratio', 'Sales_Operation_Ratio',\n","       'Expense_Ratio', 'Debt_Ratio', 'IPO', 'Comp_Type', 'Listed_Market',\n","       'Administration', 'External_Audit', 'Survival', 'Venture', 'Innobiz',\n","       'Mainbiz', 'Employees', 'Closed', 'Ten_Industry_1', 'Ten_Industry_11',\n","       'Ten_Industry_111', 'Researcher', 'Comm_Success',\n","       'Comm_Success_Code1_4', 'Comm_Success_Code2_5', 'Comm_Success_Code3_6'],\n","      dtype='object')"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"gDi__QDQt-Lm","executionInfo":{"status":"ok","timestamp":1634281094970,"user_tz":-540,"elapsed":291,"user":{"displayName":"현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06235385304799063880"}}},"source":["# Use a utility from sklearn to split and shuffle our dataset.\n","train_df, test_df = train_test_split(df, test_size=0.2)\n","train_df, val_df = train_test_split(train_df, test_size=0.2)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"i9QYocVwvZtH","executionInfo":{"status":"ok","timestamp":1634281094971,"user_tz":-540,"elapsed":8,"user":{"displayName":"현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06235385304799063880"}}},"source":["# Use a utility from sklearn to split and shuffle our dataset.\n","train_df, test_df = train_test_split(df, test_size=0.2)\n","train_df, val_df = train_test_split(train_df, test_size=0.2)\n","\n","# train\n","x_train = train_df.loc[:,['Year', 'N_of_SCI', 'N_of_Paper', 'N_Patent_App', 'N_Patent_Reg',\n","       'N_of_Korean_Patent', 'N_of_Inter_Patent', 'N_of_Patent', 'Multi_Year',\n","       'RnD_Org', 'Region', 'STP_Code_11', 'STP_Code_1_Weight', 'STP_Code_21',\n","       'STP_Code_2_Weight', 'Application_Area_1', 'Application_Area_1_Weight',\n","       'Application_Area_2', 'Application_Area_2_Weight', 'Application_Area_3',\n","       'Application_Area_3_Weight', 'Green_Tech', 'SixT_2', 'Econ_Social',\n","       'National_Strategy_2', 'RnD_Stage', 'Cowork_Cor', 'Cowork_Uni',\n","       'Cowork_Inst', 'Cowork_Abroad', 'Log_RnD_Fund', 'Log_Duration',\n","       'Cowork_etc', 'Sales', 'Income', 'Asset', 'Capital',\n","       'Sales_Income_Ratio', 'Asset_Income_Ratio', 'Sales_Operation_Ratio',\n","       'Expense_Ratio', 'Debt_Ratio', 'IPO', 'Comp_Type', 'Listed_Market',\n","       'Administration', 'External_Audit', 'Survival', 'Venture', 'Innobiz',\n","       'Mainbiz', 'Employees', 'Closed', 'Ten_Industry_1', 'Ten_Industry_11',\n","       'Ten_Industry_111', 'Researcher']]\n","y_train = train_df.loc[:,['Comm_Success',\n","       'Comm_Success_Code1_4', 'Comm_Success_Code2_5', 'Comm_Success_Code3_6']]\n","x_train = dict(x_train)\n","\n","# val\n","x_val = val_df.loc[:,['Year', 'N_of_SCI', 'N_of_Paper', 'N_Patent_App', 'N_Patent_Reg',\n","       'N_of_Korean_Patent', 'N_of_Inter_Patent', 'N_of_Patent', 'Multi_Year',\n","       'RnD_Org', 'Region', 'STP_Code_11', 'STP_Code_1_Weight', 'STP_Code_21',\n","       'STP_Code_2_Weight', 'Application_Area_1', 'Application_Area_1_Weight',\n","       'Application_Area_2', 'Application_Area_2_Weight', 'Application_Area_3',\n","       'Application_Area_3_Weight', 'Green_Tech', 'SixT_2', 'Econ_Social',\n","       'National_Strategy_2', 'RnD_Stage', 'Cowork_Cor', 'Cowork_Uni',\n","       'Cowork_Inst', 'Cowork_Abroad', 'Log_RnD_Fund', 'Log_Duration',\n","       'Cowork_etc', 'Sales', 'Income', 'Asset', 'Capital',\n","       'Sales_Income_Ratio', 'Asset_Income_Ratio', 'Sales_Operation_Ratio',\n","       'Expense_Ratio', 'Debt_Ratio', 'IPO', 'Comp_Type', 'Listed_Market',\n","       'Administration', 'External_Audit', 'Survival', 'Venture', 'Innobiz',\n","       'Mainbiz', 'Employees', 'Closed', 'Ten_Industry_1', 'Ten_Industry_11',\n","       'Ten_Industry_111', 'Researcher']]\n","y_val = val_df.loc[:,['Comm_Success',\n","       'Comm_Success_Code1_4', 'Comm_Success_Code2_5', 'Comm_Success_Code3_6']]\n","x_val = dict(x_val)\n","\n","# test\n","x_test = test_df.loc[:,['Year', 'N_of_SCI', 'N_of_Paper', 'N_Patent_App', 'N_Patent_Reg',\n","       'N_of_Korean_Patent', 'N_of_Inter_Patent', 'N_of_Patent', 'Multi_Year',\n","       'RnD_Org', 'Region', 'STP_Code_11', 'STP_Code_1_Weight', 'STP_Code_21',\n","       'STP_Code_2_Weight', 'Application_Area_1', 'Application_Area_1_Weight',\n","       'Application_Area_2', 'Application_Area_2_Weight', 'Application_Area_3',\n","       'Application_Area_3_Weight', 'Green_Tech', 'SixT_2', 'Econ_Social',\n","       'National_Strategy_2', 'RnD_Stage', 'Cowork_Cor', 'Cowork_Uni',\n","       'Cowork_Inst', 'Cowork_Abroad', 'Log_RnD_Fund', 'Log_Duration',\n","       'Cowork_etc', 'Sales', 'Income', 'Asset', 'Capital',\n","       'Sales_Income_Ratio', 'Asset_Income_Ratio', 'Sales_Operation_Ratio',\n","       'Expense_Ratio', 'Debt_Ratio', 'IPO', 'Comp_Type', 'Listed_Market',\n","       'Administration', 'External_Audit', 'Survival', 'Venture', 'Innobiz',\n","       'Mainbiz', 'Employees', 'Closed', 'Ten_Industry_1', 'Ten_Industry_11',\n","       'Ten_Industry_111', 'Researcher']]\n","y_test = test_df.loc[:,['Comm_Success',\n","       'Comm_Success_Code1_4', 'Comm_Success_Code2_5', 'Comm_Success_Code3_6']]\n","x_test = dict(x_test)"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j5Xx9G-mxeKe"},"source":["#모델생성"]},{"cell_type":"code","metadata":{"id":"mwJvfg7_ShrD","executionInfo":{"status":"ok","timestamp":1634281094972,"user_tz":-540,"elapsed":8,"user":{"displayName":"현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06235385304799063880"}}},"source":["from sklearn.metrics import precision_recall_fscore_support\n","from keras.callbacks import ModelCheckpoint"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"nu75_5_4iLSh","executionInfo":{"status":"ok","timestamp":1634281095263,"user_tz":-540,"elapsed":298,"user":{"displayName":"현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06235385304799063880"}}},"source":["METRICS = [\n","      keras.metrics.AUC(name='auc', multi_label=True, num_labels=4),\n","\n","      tfa.metrics.F1Score(\n","      num_classes = 4,\n","      average = 'micro',\n","      name ='f1_score',\n","      threshold = 0.5)\n","\n","]"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"7qZJHRIcc47b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634283482115,"user_tz":-540,"elapsed":2386856,"user":{"displayName":"현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06235385304799063880"}},"outputId":"95a67938-0e05-45b4-976b-c3d4c513a3eb"},"source":["cb = tf.keras.callbacks.EarlyStopping( monitor='val_loss', min_delta = 0,  patience=500, verbose=1, mode='min', baseline=None )\n","\n","\n","def creat_model():\n","  model = tf.keras.models.Sequential([\n","    tf.keras.layers.DenseFeatures(feature_columns=feature_columns),\n","    tf.keras.layers.Dense(units=300, activation='relu'),\n","    tf.keras.layers.Dropout(rate=0.1),\n","    tf.keras.layers.Dense(units=300, activation='relu'),\n","    tf.keras.layers.Dropout(rate=0.1),\n","    tf.keras.layers.Dense(units=300, activation='relu'),\n","    tf.keras.layers.Dropout(rate=0.1),\n","    tf.keras.layers.Dense(units=4, activation='sigmoid')\n","  ])\n","\n","  model.compile(optimizer='adam',\n","                loss= tfa.losses.SigmoidFocalCrossEntropy(gamma = 2, alpha=[0.5, 0.965, 0.6, 0.93]),\n","                metrics=METRICS)\n","  \n","  return model\n","\n","\n","model = creat_model()\n","\n","\n","model.fit(\n","    x_train, y_train,\n","    batch_size=256,\n","    epochs=2000,\n","    validation_data=(x_val, y_val),\n","    callbacks=cb\n",")\n","\n","y_pred = (model.predict(x_test) > 0.5).astype(\"int32\")\n","\n","y_true = test_df.loc[:,['Comm_Success','Comm_Success_Code1_4', 'Comm_Success_Code2_5',\n","       'Comm_Success_Code3_6']]  \n","y_true = np.array(y_true)\n","print('')\n","print('')\n","print('')\n","print('-----------------------테스트 결과---------------------------')\n","F1Score= model.evaluate(x_test, y_test)\n","print('   precision            recall               f1')\n","print(sklearn.metrics.precision_recall_fscore_support(y_true, y_pred, average='micro'))\n","print('')\n","print('')\n","print('')\n","# 모델 저장 경로\n","model.save('/gdrive/MyDrive/Colab Notebooks/DNN/최종본/모델저장/기업_최종')"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2000\n","WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Year': <tf.Tensor 'ExpandDims_56:0' shape=(None, 1) dtype=string>, 'N_of_SCI': <tf.Tensor 'ExpandDims_37:0' shape=(None, 1) dtype=float64>, 'N_of_Paper': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float64>, 'N_Patent_App': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float64>, 'N_Patent_Reg': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float64>, 'N_of_Korean_Patent': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float64>, 'N_of_Inter_Patent': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float64>, 'N_of_Patent': <tf.Tensor 'ExpandDims_36:0' shape=(None, 1) dtype=float64>, 'Multi_Year': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=string>, 'RnD_Org': <tf.Tensor 'ExpandDims_41:0' shape=(None, 1) dtype=string>, 'Region': <tf.Tensor 'ExpandDims_39:0' shape=(None, 1) dtype=string>, 'STP_Code_11': <tf.Tensor 'ExpandDims_43:0' shape=(None, 1) dtype=string>, 'STP_Code_1_Weight': <tf.Tensor 'ExpandDims_44:0' shape=(None, 1) dtype=float64>, 'STP_Code_21': <tf.Tensor 'ExpandDims_45:0' shape=(None, 1) dtype=string>, 'STP_Code_2_Weight': <tf.Tensor 'ExpandDims_46:0' shape=(None, 1) dtype=float64>, 'Application_Area_1': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=string>, 'Application_Area_1_Weight': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float64>, 'Application_Area_2': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=string>, 'Application_Area_2_Weight': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float64>, 'Application_Area_3': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=string>, 'Application_Area_3_Weight': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float64>, 'Green_Tech': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=string>, 'SixT_2': <tf.Tensor 'ExpandDims_50:0' shape=(None, 1) dtype=string>, 'Econ_Social': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=string>, 'National_Strategy_2': <tf.Tensor 'ExpandDims_38:0' shape=(None, 1) dtype=string>, 'RnD_Stage': <tf.Tensor 'ExpandDims_42:0' shape=(None, 1) dtype=string>, 'Cowork_Cor': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'Cowork_Uni': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=string>, 'Cowork_Inst': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=string>, 'Cowork_Abroad': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=string>, 'Log_RnD_Fund': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float64>, 'Log_Duration': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=float64>, 'Cowork_etc': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=string>, 'Sales': <tf.Tensor 'ExpandDims_47:0' shape=(None, 1) dtype=float64>, 'Income': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float64>, 'Asset': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float64>, 'Capital': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=float64>, 'Sales_Income_Ratio': <tf.Tensor 'ExpandDims_48:0' shape=(None, 1) dtype=float64>, 'Asset_Income_Ratio': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float64>, 'Sales_Operation_Ratio': <tf.Tensor 'ExpandDims_49:0' shape=(None, 1) dtype=float64>, 'Expense_Ratio': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float64>, 'Debt_Ratio': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float64>, 'IPO': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=string>, 'Comp_Type': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=string>, 'Listed_Market': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=string>, 'Administration': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=string>, 'External_Audit': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=string>, 'Survival': <tf.Tensor 'ExpandDims_51:0' shape=(None, 1) dtype=string>, 'Venture': <tf.Tensor 'ExpandDims_55:0' shape=(None, 1) dtype=string>, 'Innobiz': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=string>, 'Mainbiz': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=string>, 'Employees': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float64>, 'Closed': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'Ten_Industry_1': <tf.Tensor 'ExpandDims_52:0' shape=(None, 1) dtype=string>, 'Ten_Industry_11': <tf.Tensor 'ExpandDims_53:0' shape=(None, 1) dtype=string>, 'Ten_Industry_111': <tf.Tensor 'ExpandDims_54:0' shape=(None, 1) dtype=string>, 'Researcher': <tf.Tensor 'ExpandDims_40:0' shape=(None, 1) dtype=string>}\n","Consider rewriting this model with the Functional API.\n","WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Year': <tf.Tensor 'ExpandDims_56:0' shape=(None, 1) dtype=string>, 'N_of_SCI': <tf.Tensor 'ExpandDims_37:0' shape=(None, 1) dtype=float64>, 'N_of_Paper': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float64>, 'N_Patent_App': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float64>, 'N_Patent_Reg': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float64>, 'N_of_Korean_Patent': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float64>, 'N_of_Inter_Patent': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float64>, 'N_of_Patent': <tf.Tensor 'ExpandDims_36:0' shape=(None, 1) dtype=float64>, 'Multi_Year': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=string>, 'RnD_Org': <tf.Tensor 'ExpandDims_41:0' shape=(None, 1) dtype=string>, 'Region': <tf.Tensor 'ExpandDims_39:0' shape=(None, 1) dtype=string>, 'STP_Code_11': <tf.Tensor 'ExpandDims_43:0' shape=(None, 1) dtype=string>, 'STP_Code_1_Weight': <tf.Tensor 'ExpandDims_44:0' shape=(None, 1) dtype=float64>, 'STP_Code_21': <tf.Tensor 'ExpandDims_45:0' shape=(None, 1) dtype=string>, 'STP_Code_2_Weight': <tf.Tensor 'ExpandDims_46:0' shape=(None, 1) dtype=float64>, 'Application_Area_1': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=string>, 'Application_Area_1_Weight': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float64>, 'Application_Area_2': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=string>, 'Application_Area_2_Weight': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float64>, 'Application_Area_3': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=string>, 'Application_Area_3_Weight': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float64>, 'Green_Tech': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=string>, 'SixT_2': <tf.Tensor 'ExpandDims_50:0' shape=(None, 1) dtype=string>, 'Econ_Social': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=string>, 'National_Strategy_2': <tf.Tensor 'ExpandDims_38:0' shape=(None, 1) dtype=string>, 'RnD_Stage': <tf.Tensor 'ExpandDims_42:0' shape=(None, 1) dtype=string>, 'Cowork_Cor': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'Cowork_Uni': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=string>, 'Cowork_Inst': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=string>, 'Cowork_Abroad': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=string>, 'Log_RnD_Fund': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float64>, 'Log_Duration': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=float64>, 'Cowork_etc': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=string>, 'Sales': <tf.Tensor 'ExpandDims_47:0' shape=(None, 1) dtype=float64>, 'Income': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float64>, 'Asset': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float64>, 'Capital': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=float64>, 'Sales_Income_Ratio': <tf.Tensor 'ExpandDims_48:0' shape=(None, 1) dtype=float64>, 'Asset_Income_Ratio': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float64>, 'Sales_Operation_Ratio': <tf.Tensor 'ExpandDims_49:0' shape=(None, 1) dtype=float64>, 'Expense_Ratio': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float64>, 'Debt_Ratio': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float64>, 'IPO': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=string>, 'Comp_Type': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=string>, 'Listed_Market': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=string>, 'Administration': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=string>, 'External_Audit': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=string>, 'Survival': <tf.Tensor 'ExpandDims_51:0' shape=(None, 1) dtype=string>, 'Venture': <tf.Tensor 'ExpandDims_55:0' shape=(None, 1) dtype=string>, 'Innobiz': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=string>, 'Mainbiz': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=string>, 'Employees': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float64>, 'Closed': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'Ten_Industry_1': <tf.Tensor 'ExpandDims_52:0' shape=(None, 1) dtype=string>, 'Ten_Industry_11': <tf.Tensor 'ExpandDims_53:0' shape=(None, 1) dtype=string>, 'Ten_Industry_111': <tf.Tensor 'ExpandDims_54:0' shape=(None, 1) dtype=string>, 'Researcher': <tf.Tensor 'ExpandDims_40:0' shape=(None, 1) dtype=string>}\n","Consider rewriting this model with the Functional API.\n","123/123 [==============================] - ETA: 0s - loss: 0.4350 - auc: 0.5316 - f1_score: 0.3682WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Year': <tf.Tensor 'ExpandDims_56:0' shape=(None, 1) dtype=string>, 'N_of_SCI': <tf.Tensor 'ExpandDims_37:0' shape=(None, 1) dtype=float64>, 'N_of_Paper': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float64>, 'N_Patent_App': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float64>, 'N_Patent_Reg': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float64>, 'N_of_Korean_Patent': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float64>, 'N_of_Inter_Patent': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float64>, 'N_of_Patent': <tf.Tensor 'ExpandDims_36:0' shape=(None, 1) dtype=float64>, 'Multi_Year': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=string>, 'RnD_Org': <tf.Tensor 'ExpandDims_41:0' shape=(None, 1) dtype=string>, 'Region': <tf.Tensor 'ExpandDims_39:0' shape=(None, 1) dtype=string>, 'STP_Code_11': <tf.Tensor 'ExpandDims_43:0' shape=(None, 1) dtype=string>, 'STP_Code_1_Weight': <tf.Tensor 'ExpandDims_44:0' shape=(None, 1) dtype=float64>, 'STP_Code_21': <tf.Tensor 'ExpandDims_45:0' shape=(None, 1) dtype=string>, 'STP_Code_2_Weight': <tf.Tensor 'ExpandDims_46:0' shape=(None, 1) dtype=float64>, 'Application_Area_1': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=string>, 'Application_Area_1_Weight': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float64>, 'Application_Area_2': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=string>, 'Application_Area_2_Weight': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float64>, 'Application_Area_3': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=string>, 'Application_Area_3_Weight': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float64>, 'Green_Tech': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=string>, 'SixT_2': <tf.Tensor 'ExpandDims_50:0' shape=(None, 1) dtype=string>, 'Econ_Social': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=string>, 'National_Strategy_2': <tf.Tensor 'ExpandDims_38:0' shape=(None, 1) dtype=string>, 'RnD_Stage': <tf.Tensor 'ExpandDims_42:0' shape=(None, 1) dtype=string>, 'Cowork_Cor': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'Cowork_Uni': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=string>, 'Cowork_Inst': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=string>, 'Cowork_Abroad': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=string>, 'Log_RnD_Fund': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float64>, 'Log_Duration': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=float64>, 'Cowork_etc': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=string>, 'Sales': <tf.Tensor 'ExpandDims_47:0' shape=(None, 1) dtype=float64>, 'Income': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float64>, 'Asset': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float64>, 'Capital': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=float64>, 'Sales_Income_Ratio': <tf.Tensor 'ExpandDims_48:0' shape=(None, 1) dtype=float64>, 'Asset_Income_Ratio': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float64>, 'Sales_Operation_Ratio': <tf.Tensor 'ExpandDims_49:0' shape=(None, 1) dtype=float64>, 'Expense_Ratio': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float64>, 'Debt_Ratio': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float64>, 'IPO': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=string>, 'Comp_Type': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=string>, 'Listed_Market': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=string>, 'Administration': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=string>, 'External_Audit': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=string>, 'Survival': <tf.Tensor 'ExpandDims_51:0' shape=(None, 1) dtype=string>, 'Venture': <tf.Tensor 'ExpandDims_55:0' shape=(None, 1) dtype=string>, 'Innobiz': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=string>, 'Mainbiz': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=string>, 'Employees': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float64>, 'Closed': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'Ten_Industry_1': <tf.Tensor 'ExpandDims_52:0' shape=(None, 1) dtype=string>, 'Ten_Industry_11': <tf.Tensor 'ExpandDims_53:0' shape=(None, 1) dtype=string>, 'Ten_Industry_111': <tf.Tensor 'ExpandDims_54:0' shape=(None, 1) dtype=string>, 'Researcher': <tf.Tensor 'ExpandDims_40:0' shape=(None, 1) dtype=string>}\n","Consider rewriting this model with the Functional API.\n","123/123 [==============================] - 10s 47ms/step - loss: 0.4350 - auc: 0.5316 - f1_score: 0.3682 - val_loss: 0.2823 - val_auc: 0.6474 - val_f1_score: 0.1958\n","Epoch 2/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.2589 - auc: 0.6150 - f1_score: 0.4223 - val_loss: 0.2471 - val_auc: 0.7477 - val_f1_score: 0.4891\n","Epoch 3/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.2414 - auc: 0.7151 - f1_score: 0.4977 - val_loss: 0.1903 - val_auc: 0.7786 - val_f1_score: 0.5236\n","Epoch 4/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.2090 - auc: 0.7542 - f1_score: 0.5264 - val_loss: 0.1881 - val_auc: 0.7953 - val_f1_score: 0.5468\n","Epoch 5/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.1993 - auc: 0.7684 - f1_score: 0.5377 - val_loss: 0.2005 - val_auc: 0.7944 - val_f1_score: 0.5642\n","Epoch 6/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.1791 - auc: 0.7854 - f1_score: 0.5493 - val_loss: 0.1624 - val_auc: 0.8081 - val_f1_score: 0.5615\n","Epoch 7/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.1706 - auc: 0.7941 - f1_score: 0.5631 - val_loss: 0.1591 - val_auc: 0.8124 - val_f1_score: 0.5688\n","Epoch 8/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.1702 - auc: 0.7960 - f1_score: 0.5648 - val_loss: 0.1560 - val_auc: 0.8159 - val_f1_score: 0.5604\n","Epoch 9/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.1548 - auc: 0.8055 - f1_score: 0.5748 - val_loss: 0.1509 - val_auc: 0.8177 - val_f1_score: 0.5740\n","Epoch 10/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.1519 - auc: 0.8103 - f1_score: 0.5793 - val_loss: 0.1478 - val_auc: 0.8233 - val_f1_score: 0.5923\n","Epoch 11/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.1508 - auc: 0.8150 - f1_score: 0.5831 - val_loss: 0.1465 - val_auc: 0.8283 - val_f1_score: 0.5873\n","Epoch 12/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.1462 - auc: 0.8193 - f1_score: 0.5872 - val_loss: 0.1468 - val_auc: 0.8274 - val_f1_score: 0.5974\n","Epoch 13/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.1474 - auc: 0.8246 - f1_score: 0.5915 - val_loss: 0.1450 - val_auc: 0.8311 - val_f1_score: 0.5864\n","Epoch 14/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.1448 - auc: 0.8283 - f1_score: 0.5933 - val_loss: 0.1452 - val_auc: 0.8370 - val_f1_score: 0.5907\n","Epoch 15/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.1430 - auc: 0.8330 - f1_score: 0.5979 - val_loss: 0.1416 - val_auc: 0.8328 - val_f1_score: 0.5999\n","Epoch 16/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.1389 - auc: 0.8356 - f1_score: 0.6009 - val_loss: 0.1411 - val_auc: 0.8388 - val_f1_score: 0.5892\n","Epoch 17/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.1394 - auc: 0.8400 - f1_score: 0.6077 - val_loss: 0.1405 - val_auc: 0.8404 - val_f1_score: 0.5900\n","Epoch 18/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.1364 - auc: 0.8435 - f1_score: 0.6121 - val_loss: 0.1374 - val_auc: 0.8418 - val_f1_score: 0.6009\n","Epoch 19/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.1330 - auc: 0.8473 - f1_score: 0.6118 - val_loss: 0.1404 - val_auc: 0.8406 - val_f1_score: 0.5865\n","Epoch 20/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.1335 - auc: 0.8494 - f1_score: 0.6159 - val_loss: 0.1393 - val_auc: 0.8424 - val_f1_score: 0.6045\n","Epoch 21/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.1327 - auc: 0.8525 - f1_score: 0.6181 - val_loss: 0.1423 - val_auc: 0.8398 - val_f1_score: 0.5909\n","Epoch 22/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.1315 - auc: 0.8553 - f1_score: 0.6213 - val_loss: 0.1441 - val_auc: 0.8361 - val_f1_score: 0.6170\n","Epoch 23/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.1302 - auc: 0.8551 - f1_score: 0.6215 - val_loss: 0.1420 - val_auc: 0.8449 - val_f1_score: 0.5930\n","Epoch 24/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.1303 - auc: 0.8584 - f1_score: 0.6257 - val_loss: 0.1416 - val_auc: 0.8413 - val_f1_score: 0.5984\n","Epoch 25/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.1273 - auc: 0.8611 - f1_score: 0.6265 - val_loss: 0.1388 - val_auc: 0.8466 - val_f1_score: 0.6123\n","Epoch 26/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.1252 - auc: 0.8657 - f1_score: 0.6352 - val_loss: 0.1423 - val_auc: 0.8433 - val_f1_score: 0.6376\n","Epoch 27/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.1240 - auc: 0.8674 - f1_score: 0.6354 - val_loss: 0.1435 - val_auc: 0.8451 - val_f1_score: 0.6162\n","Epoch 28/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.1211 - auc: 0.8703 - f1_score: 0.6406 - val_loss: 0.1465 - val_auc: 0.8424 - val_f1_score: 0.6328\n","Epoch 29/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.1191 - auc: 0.8745 - f1_score: 0.6466 - val_loss: 0.1396 - val_auc: 0.8447 - val_f1_score: 0.6143\n","Epoch 30/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.1193 - auc: 0.8729 - f1_score: 0.6449 - val_loss: 0.1369 - val_auc: 0.8463 - val_f1_score: 0.6099\n","Epoch 31/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.1185 - auc: 0.8723 - f1_score: 0.6415 - val_loss: 0.1377 - val_auc: 0.8475 - val_f1_score: 0.6083\n","Epoch 32/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.1189 - auc: 0.8756 - f1_score: 0.6424 - val_loss: 0.1395 - val_auc: 0.8442 - val_f1_score: 0.5948\n","Epoch 33/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.1182 - auc: 0.8765 - f1_score: 0.6419 - val_loss: 0.1384 - val_auc: 0.8477 - val_f1_score: 0.6188\n","Epoch 34/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.1143 - auc: 0.8824 - f1_score: 0.6537 - val_loss: 0.1401 - val_auc: 0.8458 - val_f1_score: 0.6054\n","Epoch 35/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.1134 - auc: 0.8837 - f1_score: 0.6525 - val_loss: 0.1495 - val_auc: 0.8375 - val_f1_score: 0.6092\n","Epoch 36/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.1171 - auc: 0.8803 - f1_score: 0.6478 - val_loss: 0.1397 - val_auc: 0.8464 - val_f1_score: 0.6164\n","Epoch 37/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.1139 - auc: 0.8831 - f1_score: 0.6520 - val_loss: 0.1434 - val_auc: 0.8508 - val_f1_score: 0.6184\n","Epoch 38/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.1127 - auc: 0.8855 - f1_score: 0.6570 - val_loss: 0.1451 - val_auc: 0.8474 - val_f1_score: 0.6154\n","Epoch 39/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.1128 - auc: 0.8894 - f1_score: 0.6606 - val_loss: 0.1469 - val_auc: 0.8477 - val_f1_score: 0.6219\n","Epoch 40/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.1111 - auc: 0.8903 - f1_score: 0.6635 - val_loss: 0.1537 - val_auc: 0.8511 - val_f1_score: 0.6501\n","Epoch 41/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.1097 - auc: 0.8920 - f1_score: 0.6657 - val_loss: 0.1472 - val_auc: 0.8486 - val_f1_score: 0.6400\n","Epoch 42/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.1078 - auc: 0.8940 - f1_score: 0.6708 - val_loss: 0.1472 - val_auc: 0.8508 - val_f1_score: 0.6108\n","Epoch 43/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.1056 - auc: 0.8975 - f1_score: 0.6757 - val_loss: 0.1506 - val_auc: 0.8484 - val_f1_score: 0.6039\n","Epoch 44/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.1065 - auc: 0.8974 - f1_score: 0.6763 - val_loss: 0.1534 - val_auc: 0.8512 - val_f1_score: 0.6167\n","Epoch 45/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.1049 - auc: 0.8991 - f1_score: 0.6763 - val_loss: 0.1487 - val_auc: 0.8505 - val_f1_score: 0.6256\n","Epoch 46/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.1023 - auc: 0.9025 - f1_score: 0.6822 - val_loss: 0.1598 - val_auc: 0.8515 - val_f1_score: 0.6407\n","Epoch 47/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.1012 - auc: 0.9049 - f1_score: 0.6855 - val_loss: 0.1571 - val_auc: 0.8484 - val_f1_score: 0.6301\n","Epoch 48/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.1032 - auc: 0.9047 - f1_score: 0.6861 - val_loss: 0.1537 - val_auc: 0.8489 - val_f1_score: 0.6121\n","Epoch 49/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.1001 - auc: 0.9078 - f1_score: 0.6887 - val_loss: 0.1564 - val_auc: 0.8482 - val_f1_score: 0.6189\n","Epoch 50/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0991 - auc: 0.9087 - f1_score: 0.6884 - val_loss: 0.1608 - val_auc: 0.8481 - val_f1_score: 0.6463\n","Epoch 51/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0982 - auc: 0.9106 - f1_score: 0.6941 - val_loss: 0.1540 - val_auc: 0.8527 - val_f1_score: 0.6262\n","Epoch 52/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0988 - auc: 0.9092 - f1_score: 0.6914 - val_loss: 0.1576 - val_auc: 0.8528 - val_f1_score: 0.6355\n","Epoch 53/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.0972 - auc: 0.9117 - f1_score: 0.6970 - val_loss: 0.1645 - val_auc: 0.8517 - val_f1_score: 0.6554\n","Epoch 54/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.0964 - auc: 0.9116 - f1_score: 0.6937 - val_loss: 0.1589 - val_auc: 0.8534 - val_f1_score: 0.6407\n","Epoch 55/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.0961 - auc: 0.9150 - f1_score: 0.6999 - val_loss: 0.1578 - val_auc: 0.8520 - val_f1_score: 0.6489\n","Epoch 56/2000\n","123/123 [==============================] - 4s 37ms/step - loss: 0.0947 - auc: 0.9169 - f1_score: 0.7003 - val_loss: 0.1639 - val_auc: 0.8517 - val_f1_score: 0.6396\n","Epoch 57/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.0929 - auc: 0.9192 - f1_score: 0.7055 - val_loss: 0.1648 - val_auc: 0.8466 - val_f1_score: 0.6372\n","Epoch 58/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.0913 - auc: 0.9213 - f1_score: 0.7117 - val_loss: 0.1753 - val_auc: 0.8509 - val_f1_score: 0.6469\n","Epoch 59/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.0918 - auc: 0.9215 - f1_score: 0.7118 - val_loss: 0.1690 - val_auc: 0.8522 - val_f1_score: 0.6437\n","Epoch 60/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.0890 - auc: 0.9249 - f1_score: 0.7147 - val_loss: 0.1734 - val_auc: 0.8514 - val_f1_score: 0.6473\n","Epoch 61/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.0896 - auc: 0.9238 - f1_score: 0.7138 - val_loss: 0.1654 - val_auc: 0.8494 - val_f1_score: 0.6282\n","Epoch 62/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0883 - auc: 0.9244 - f1_score: 0.7137 - val_loss: 0.1631 - val_auc: 0.8573 - val_f1_score: 0.6407\n","Epoch 63/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.0885 - auc: 0.9263 - f1_score: 0.7163 - val_loss: 0.1738 - val_auc: 0.8532 - val_f1_score: 0.6358\n","Epoch 64/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0872 - auc: 0.9285 - f1_score: 0.7204 - val_loss: 0.1887 - val_auc: 0.8526 - val_f1_score: 0.6586\n","Epoch 65/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.0879 - auc: 0.9271 - f1_score: 0.7211 - val_loss: 0.1615 - val_auc: 0.8450 - val_f1_score: 0.6255\n","Epoch 66/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.0861 - auc: 0.9298 - f1_score: 0.7243 - val_loss: 0.1655 - val_auc: 0.8511 - val_f1_score: 0.6406\n","Epoch 67/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.0851 - auc: 0.9317 - f1_score: 0.7289 - val_loss: 0.1785 - val_auc: 0.8472 - val_f1_score: 0.6471\n","Epoch 68/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.0863 - auc: 0.9319 - f1_score: 0.7283 - val_loss: 0.1947 - val_auc: 0.8522 - val_f1_score: 0.6583\n","Epoch 69/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.0867 - auc: 0.9302 - f1_score: 0.7287 - val_loss: 0.1806 - val_auc: 0.8520 - val_f1_score: 0.6445\n","Epoch 70/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0819 - auc: 0.9359 - f1_score: 0.7355 - val_loss: 0.1962 - val_auc: 0.8569 - val_f1_score: 0.6421\n","Epoch 71/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0820 - auc: 0.9364 - f1_score: 0.7341 - val_loss: 0.1916 - val_auc: 0.8479 - val_f1_score: 0.6671\n","Epoch 72/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.0804 - auc: 0.9378 - f1_score: 0.7401 - val_loss: 0.2029 - val_auc: 0.8522 - val_f1_score: 0.6681\n","Epoch 73/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0831 - auc: 0.9358 - f1_score: 0.7372 - val_loss: 0.2088 - val_auc: 0.8474 - val_f1_score: 0.6490\n","Epoch 74/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.0799 - auc: 0.9378 - f1_score: 0.7383 - val_loss: 0.1933 - val_auc: 0.8520 - val_f1_score: 0.6610\n","Epoch 75/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.0779 - auc: 0.9412 - f1_score: 0.7457 - val_loss: 0.1974 - val_auc: 0.8515 - val_f1_score: 0.6568\n","Epoch 76/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0793 - auc: 0.9401 - f1_score: 0.7413 - val_loss: 0.1806 - val_auc: 0.8522 - val_f1_score: 0.6609\n","Epoch 77/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.0791 - auc: 0.9395 - f1_score: 0.7444 - val_loss: 0.1964 - val_auc: 0.8533 - val_f1_score: 0.6492\n","Epoch 78/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.0784 - auc: 0.9411 - f1_score: 0.7442 - val_loss: 0.1954 - val_auc: 0.8495 - val_f1_score: 0.6500\n","Epoch 79/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0764 - auc: 0.9444 - f1_score: 0.7508 - val_loss: 0.1959 - val_auc: 0.8508 - val_f1_score: 0.6590\n","Epoch 80/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.0788 - auc: 0.9426 - f1_score: 0.7508 - val_loss: 0.1830 - val_auc: 0.8443 - val_f1_score: 0.6427\n","Epoch 81/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0788 - auc: 0.9421 - f1_score: 0.7444 - val_loss: 0.1966 - val_auc: 0.8495 - val_f1_score: 0.6580\n","Epoch 82/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.0768 - auc: 0.9433 - f1_score: 0.7499 - val_loss: 0.2012 - val_auc: 0.8520 - val_f1_score: 0.6378\n","Epoch 83/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.0750 - auc: 0.9458 - f1_score: 0.7546 - val_loss: 0.1948 - val_auc: 0.8498 - val_f1_score: 0.6448\n","Epoch 84/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0737 - auc: 0.9469 - f1_score: 0.7577 - val_loss: 0.2053 - val_auc: 0.8524 - val_f1_score: 0.6617\n","Epoch 85/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0738 - auc: 0.9470 - f1_score: 0.7570 - val_loss: 0.2121 - val_auc: 0.8507 - val_f1_score: 0.6660\n","Epoch 86/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0735 - auc: 0.9469 - f1_score: 0.7565 - val_loss: 0.2059 - val_auc: 0.8502 - val_f1_score: 0.6582\n","Epoch 87/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.0724 - auc: 0.9498 - f1_score: 0.7636 - val_loss: 0.2145 - val_auc: 0.8523 - val_f1_score: 0.6512\n","Epoch 88/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.0717 - auc: 0.9500 - f1_score: 0.7620 - val_loss: 0.2246 - val_auc: 0.8466 - val_f1_score: 0.6758\n","Epoch 89/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.0764 - auc: 0.9493 - f1_score: 0.7619 - val_loss: 0.2220 - val_auc: 0.8496 - val_f1_score: 0.6533\n","Epoch 90/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0714 - auc: 0.9503 - f1_score: 0.7652 - val_loss: 0.2205 - val_auc: 0.8468 - val_f1_score: 0.6652\n","Epoch 91/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0711 - auc: 0.9510 - f1_score: 0.7638 - val_loss: 0.2154 - val_auc: 0.8508 - val_f1_score: 0.6529\n","Epoch 92/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0738 - auc: 0.9501 - f1_score: 0.7671 - val_loss: 0.1999 - val_auc: 0.8495 - val_f1_score: 0.6485\n","Epoch 93/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0709 - auc: 0.9539 - f1_score: 0.7706 - val_loss: 0.2078 - val_auc: 0.8469 - val_f1_score: 0.6590\n","Epoch 94/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0714 - auc: 0.9529 - f1_score: 0.7710 - val_loss: 0.2228 - val_auc: 0.8536 - val_f1_score: 0.6716\n","Epoch 95/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.0702 - auc: 0.9549 - f1_score: 0.7757 - val_loss: 0.1968 - val_auc: 0.8488 - val_f1_score: 0.6566\n","Epoch 96/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.0728 - auc: 0.9520 - f1_score: 0.7690 - val_loss: 0.1990 - val_auc: 0.8477 - val_f1_score: 0.6482\n","Epoch 97/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.0695 - auc: 0.9536 - f1_score: 0.7717 - val_loss: 0.2109 - val_auc: 0.8503 - val_f1_score: 0.6656\n","Epoch 98/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0679 - auc: 0.9539 - f1_score: 0.7738 - val_loss: 0.2171 - val_auc: 0.8469 - val_f1_score: 0.6650\n","Epoch 99/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0680 - auc: 0.9548 - f1_score: 0.7760 - val_loss: 0.2195 - val_auc: 0.8478 - val_f1_score: 0.6697\n","Epoch 100/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0662 - auc: 0.9561 - f1_score: 0.7790 - val_loss: 0.2096 - val_auc: 0.8511 - val_f1_score: 0.6692\n","Epoch 101/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0689 - auc: 0.9572 - f1_score: 0.7796 - val_loss: 0.2289 - val_auc: 0.8494 - val_f1_score: 0.6696\n","Epoch 102/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.0653 - auc: 0.9584 - f1_score: 0.7833 - val_loss: 0.2221 - val_auc: 0.8525 - val_f1_score: 0.6644\n","Epoch 103/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.0641 - auc: 0.9589 - f1_score: 0.7845 - val_loss: 0.2193 - val_auc: 0.8472 - val_f1_score: 0.6645\n","Epoch 104/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0651 - auc: 0.9591 - f1_score: 0.7852 - val_loss: 0.2558 - val_auc: 0.8483 - val_f1_score: 0.6636\n","Epoch 105/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.0637 - auc: 0.9607 - f1_score: 0.7895 - val_loss: 0.2370 - val_auc: 0.8496 - val_f1_score: 0.6768\n","Epoch 106/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0652 - auc: 0.9588 - f1_score: 0.7851 - val_loss: 0.2467 - val_auc: 0.8465 - val_f1_score: 0.6672\n","Epoch 107/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0630 - auc: 0.9605 - f1_score: 0.7897 - val_loss: 0.2308 - val_auc: 0.8490 - val_f1_score: 0.6479\n","Epoch 108/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0633 - auc: 0.9601 - f1_score: 0.7868 - val_loss: 0.2369 - val_auc: 0.8481 - val_f1_score: 0.6660\n","Epoch 109/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0626 - auc: 0.9622 - f1_score: 0.7918 - val_loss: 0.2418 - val_auc: 0.8447 - val_f1_score: 0.6690\n","Epoch 110/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0625 - auc: 0.9626 - f1_score: 0.7966 - val_loss: 0.2506 - val_auc: 0.8519 - val_f1_score: 0.6711\n","Epoch 111/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0618 - auc: 0.9628 - f1_score: 0.7953 - val_loss: 0.2557 - val_auc: 0.8536 - val_f1_score: 0.6798\n","Epoch 112/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.0632 - auc: 0.9605 - f1_score: 0.7905 - val_loss: 0.2158 - val_auc: 0.8482 - val_f1_score: 0.6530\n","Epoch 113/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0600 - auc: 0.9642 - f1_score: 0.7967 - val_loss: 0.2409 - val_auc: 0.8484 - val_f1_score: 0.6755\n","Epoch 114/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0606 - auc: 0.9638 - f1_score: 0.7977 - val_loss: 0.2325 - val_auc: 0.8494 - val_f1_score: 0.6589\n","Epoch 115/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0631 - auc: 0.9611 - f1_score: 0.7911 - val_loss: 0.2360 - val_auc: 0.8530 - val_f1_score: 0.6743\n","Epoch 116/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0582 - auc: 0.9658 - f1_score: 0.8025 - val_loss: 0.2494 - val_auc: 0.8504 - val_f1_score: 0.6705\n","Epoch 117/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.0590 - auc: 0.9648 - f1_score: 0.7992 - val_loss: 0.2746 - val_auc: 0.8474 - val_f1_score: 0.6749\n","Epoch 118/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0576 - auc: 0.9666 - f1_score: 0.8042 - val_loss: 0.2627 - val_auc: 0.8487 - val_f1_score: 0.6692\n","Epoch 119/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.0588 - auc: 0.9656 - f1_score: 0.8020 - val_loss: 0.2457 - val_auc: 0.8484 - val_f1_score: 0.6791\n","Epoch 120/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0591 - auc: 0.9661 - f1_score: 0.8020 - val_loss: 0.2640 - val_auc: 0.8438 - val_f1_score: 0.6793\n","Epoch 121/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0583 - auc: 0.9661 - f1_score: 0.8045 - val_loss: 0.2352 - val_auc: 0.8531 - val_f1_score: 0.6660\n","Epoch 122/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0594 - auc: 0.9660 - f1_score: 0.8027 - val_loss: 0.2530 - val_auc: 0.8494 - val_f1_score: 0.6730\n","Epoch 123/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.0558 - auc: 0.9689 - f1_score: 0.8108 - val_loss: 0.2473 - val_auc: 0.8496 - val_f1_score: 0.6776\n","Epoch 124/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.0588 - auc: 0.9660 - f1_score: 0.8020 - val_loss: 0.2391 - val_auc: 0.8452 - val_f1_score: 0.6606\n","Epoch 125/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0594 - auc: 0.9667 - f1_score: 0.8071 - val_loss: 0.2453 - val_auc: 0.8465 - val_f1_score: 0.6689\n","Epoch 126/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0598 - auc: 0.9660 - f1_score: 0.8029 - val_loss: 0.2371 - val_auc: 0.8448 - val_f1_score: 0.6779\n","Epoch 127/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0558 - auc: 0.9689 - f1_score: 0.8116 - val_loss: 0.2630 - val_auc: 0.8475 - val_f1_score: 0.6754\n","Epoch 128/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0564 - auc: 0.9677 - f1_score: 0.8071 - val_loss: 0.2374 - val_auc: 0.8417 - val_f1_score: 0.6673\n","Epoch 129/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0585 - auc: 0.9672 - f1_score: 0.8081 - val_loss: 0.2429 - val_auc: 0.8480 - val_f1_score: 0.6747\n","Epoch 130/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0559 - auc: 0.9697 - f1_score: 0.8111 - val_loss: 0.2503 - val_auc: 0.8465 - val_f1_score: 0.6795\n","Epoch 131/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0572 - auc: 0.9696 - f1_score: 0.8144 - val_loss: 0.2543 - val_auc: 0.8523 - val_f1_score: 0.6855\n","Epoch 132/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.0561 - auc: 0.9694 - f1_score: 0.8133 - val_loss: 0.2600 - val_auc: 0.8532 - val_f1_score: 0.6855\n","Epoch 133/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0556 - auc: 0.9693 - f1_score: 0.8136 - val_loss: 0.2581 - val_auc: 0.8416 - val_f1_score: 0.6746\n","Epoch 134/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0567 - auc: 0.9688 - f1_score: 0.8090 - val_loss: 0.2584 - val_auc: 0.8480 - val_f1_score: 0.6719\n","Epoch 135/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0533 - auc: 0.9723 - f1_score: 0.8218 - val_loss: 0.2719 - val_auc: 0.8465 - val_f1_score: 0.6839\n","Epoch 136/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0535 - auc: 0.9708 - f1_score: 0.8193 - val_loss: 0.2623 - val_auc: 0.8468 - val_f1_score: 0.6806\n","Epoch 137/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.0546 - auc: 0.9704 - f1_score: 0.8160 - val_loss: 0.2582 - val_auc: 0.8461 - val_f1_score: 0.6681\n","Epoch 138/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.0525 - auc: 0.9715 - f1_score: 0.8185 - val_loss: 0.2828 - val_auc: 0.8498 - val_f1_score: 0.6851\n","Epoch 139/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0545 - auc: 0.9704 - f1_score: 0.8131 - val_loss: 0.2624 - val_auc: 0.8475 - val_f1_score: 0.6870\n","Epoch 140/2000\n","123/123 [==============================] - 4s 34ms/step - loss: 0.0545 - auc: 0.9706 - f1_score: 0.8184 - val_loss: 0.2803 - val_auc: 0.8444 - val_f1_score: 0.6885\n","Epoch 141/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0540 - auc: 0.9715 - f1_score: 0.8199 - val_loss: 0.2475 - val_auc: 0.8482 - val_f1_score: 0.6705\n","Epoch 142/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0519 - auc: 0.9729 - f1_score: 0.8243 - val_loss: 0.2614 - val_auc: 0.8477 - val_f1_score: 0.6749\n","Epoch 143/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0521 - auc: 0.9729 - f1_score: 0.8241 - val_loss: 0.2679 - val_auc: 0.8495 - val_f1_score: 0.6858\n","Epoch 144/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0533 - auc: 0.9717 - f1_score: 0.8194 - val_loss: 0.2910 - val_auc: 0.8470 - val_f1_score: 0.6881\n","Epoch 145/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0520 - auc: 0.9723 - f1_score: 0.8219 - val_loss: 0.2614 - val_auc: 0.8438 - val_f1_score: 0.6689\n","Epoch 146/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0530 - auc: 0.9723 - f1_score: 0.8223 - val_loss: 0.2523 - val_auc: 0.8508 - val_f1_score: 0.6657\n","Epoch 147/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0528 - auc: 0.9730 - f1_score: 0.8236 - val_loss: 0.2550 - val_auc: 0.8500 - val_f1_score: 0.6645\n","Epoch 148/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0504 - auc: 0.9737 - f1_score: 0.8272 - val_loss: 0.2790 - val_auc: 0.8476 - val_f1_score: 0.6682\n","Epoch 149/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0513 - auc: 0.9741 - f1_score: 0.8261 - val_loss: 0.2732 - val_auc: 0.8419 - val_f1_score: 0.6797\n","Epoch 150/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0500 - auc: 0.9747 - f1_score: 0.8318 - val_loss: 0.2727 - val_auc: 0.8438 - val_f1_score: 0.6640\n","Epoch 151/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0506 - auc: 0.9740 - f1_score: 0.8274 - val_loss: 0.2700 - val_auc: 0.8500 - val_f1_score: 0.6723\n","Epoch 152/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0518 - auc: 0.9739 - f1_score: 0.8287 - val_loss: 0.2582 - val_auc: 0.8468 - val_f1_score: 0.6783\n","Epoch 153/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0491 - auc: 0.9755 - f1_score: 0.8337 - val_loss: 0.2837 - val_auc: 0.8470 - val_f1_score: 0.6886\n","Epoch 154/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0486 - auc: 0.9761 - f1_score: 0.8344 - val_loss: 0.2708 - val_auc: 0.8479 - val_f1_score: 0.6746\n","Epoch 155/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0467 - auc: 0.9775 - f1_score: 0.8387 - val_loss: 0.2961 - val_auc: 0.8503 - val_f1_score: 0.6859\n","Epoch 156/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0521 - auc: 0.9736 - f1_score: 0.8281 - val_loss: 0.2931 - val_auc: 0.8458 - val_f1_score: 0.6760\n","Epoch 157/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0518 - auc: 0.9746 - f1_score: 0.8289 - val_loss: 0.2760 - val_auc: 0.8434 - val_f1_score: 0.6788\n","Epoch 158/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0531 - auc: 0.9722 - f1_score: 0.8242 - val_loss: 0.2505 - val_auc: 0.8345 - val_f1_score: 0.6452\n","Epoch 159/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0586 - auc: 0.9676 - f1_score: 0.8086 - val_loss: 0.2685 - val_auc: 0.8407 - val_f1_score: 0.6792\n","Epoch 160/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0546 - auc: 0.9711 - f1_score: 0.8175 - val_loss: 0.2849 - val_auc: 0.8497 - val_f1_score: 0.6860\n","Epoch 161/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0519 - auc: 0.9737 - f1_score: 0.8248 - val_loss: 0.2716 - val_auc: 0.8442 - val_f1_score: 0.6868\n","Epoch 162/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0541 - auc: 0.9717 - f1_score: 0.8212 - val_loss: 0.2668 - val_auc: 0.8483 - val_f1_score: 0.6819\n","Epoch 163/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0500 - auc: 0.9745 - f1_score: 0.8289 - val_loss: 0.2814 - val_auc: 0.8404 - val_f1_score: 0.6779\n","Epoch 164/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0491 - auc: 0.9754 - f1_score: 0.8328 - val_loss: 0.2841 - val_auc: 0.8453 - val_f1_score: 0.6819\n","Epoch 165/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0483 - auc: 0.9767 - f1_score: 0.8366 - val_loss: 0.2843 - val_auc: 0.8459 - val_f1_score: 0.6805\n","Epoch 166/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0473 - auc: 0.9769 - f1_score: 0.8384 - val_loss: 0.2854 - val_auc: 0.8403 - val_f1_score: 0.6907\n","Epoch 167/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0482 - auc: 0.9768 - f1_score: 0.8390 - val_loss: 0.2953 - val_auc: 0.8445 - val_f1_score: 0.6804\n","Epoch 168/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0495 - auc: 0.9754 - f1_score: 0.8316 - val_loss: 0.2736 - val_auc: 0.8449 - val_f1_score: 0.6854\n","Epoch 169/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0459 - auc: 0.9782 - f1_score: 0.8411 - val_loss: 0.2920 - val_auc: 0.8429 - val_f1_score: 0.6761\n","Epoch 170/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0475 - auc: 0.9776 - f1_score: 0.8393 - val_loss: 0.2764 - val_auc: 0.8468 - val_f1_score: 0.6909\n","Epoch 171/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0481 - auc: 0.9779 - f1_score: 0.8400 - val_loss: 0.2936 - val_auc: 0.8468 - val_f1_score: 0.6995\n","Epoch 172/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0475 - auc: 0.9771 - f1_score: 0.8394 - val_loss: 0.3006 - val_auc: 0.8406 - val_f1_score: 0.6762\n","Epoch 173/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0479 - auc: 0.9770 - f1_score: 0.8384 - val_loss: 0.3110 - val_auc: 0.8458 - val_f1_score: 0.6870\n","Epoch 174/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0458 - auc: 0.9792 - f1_score: 0.8441 - val_loss: 0.2962 - val_auc: 0.8483 - val_f1_score: 0.6877\n","Epoch 175/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0460 - auc: 0.9791 - f1_score: 0.8464 - val_loss: 0.2891 - val_auc: 0.8421 - val_f1_score: 0.6695\n","Epoch 176/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0471 - auc: 0.9777 - f1_score: 0.8416 - val_loss: 0.2915 - val_auc: 0.8432 - val_f1_score: 0.6821\n","Epoch 177/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0484 - auc: 0.9775 - f1_score: 0.8401 - val_loss: 0.2789 - val_auc: 0.8417 - val_f1_score: 0.6880\n","Epoch 178/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0458 - auc: 0.9784 - f1_score: 0.8448 - val_loss: 0.3156 - val_auc: 0.8466 - val_f1_score: 0.6802\n","Epoch 179/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0481 - auc: 0.9774 - f1_score: 0.8404 - val_loss: 0.3016 - val_auc: 0.8506 - val_f1_score: 0.6945\n","Epoch 180/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0488 - auc: 0.9771 - f1_score: 0.8371 - val_loss: 0.2760 - val_auc: 0.8476 - val_f1_score: 0.6862\n","Epoch 181/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0470 - auc: 0.9783 - f1_score: 0.8425 - val_loss: 0.2673 - val_auc: 0.8419 - val_f1_score: 0.6684\n","Epoch 182/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0471 - auc: 0.9776 - f1_score: 0.8411 - val_loss: 0.3007 - val_auc: 0.8493 - val_f1_score: 0.6816\n","Epoch 183/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0472 - auc: 0.9782 - f1_score: 0.8419 - val_loss: 0.2931 - val_auc: 0.8470 - val_f1_score: 0.6850\n","Epoch 184/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0522 - auc: 0.9767 - f1_score: 0.8377 - val_loss: 0.3060 - val_auc: 0.8442 - val_f1_score: 0.6827\n","Epoch 185/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0530 - auc: 0.9773 - f1_score: 0.8389 - val_loss: 0.2859 - val_auc: 0.8505 - val_f1_score: 0.6851\n","Epoch 186/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0502 - auc: 0.9787 - f1_score: 0.8481 - val_loss: 0.2910 - val_auc: 0.8472 - val_f1_score: 0.6762\n","Epoch 187/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0500 - auc: 0.9781 - f1_score: 0.8417 - val_loss: 0.2745 - val_auc: 0.8462 - val_f1_score: 0.6853\n","Epoch 188/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0467 - auc: 0.9796 - f1_score: 0.8488 - val_loss: 0.3185 - val_auc: 0.8452 - val_f1_score: 0.6962\n","Epoch 189/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0456 - auc: 0.9792 - f1_score: 0.8464 - val_loss: 0.2851 - val_auc: 0.8469 - val_f1_score: 0.6815\n","Epoch 190/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0463 - auc: 0.9792 - f1_score: 0.8477 - val_loss: 0.2768 - val_auc: 0.8443 - val_f1_score: 0.6798\n","Epoch 191/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0435 - auc: 0.9808 - f1_score: 0.8507 - val_loss: 0.2843 - val_auc: 0.8490 - val_f1_score: 0.6827\n","Epoch 192/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0462 - auc: 0.9791 - f1_score: 0.8465 - val_loss: 0.3047 - val_auc: 0.8447 - val_f1_score: 0.6934\n","Epoch 193/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0434 - auc: 0.9809 - f1_score: 0.8515 - val_loss: 0.2977 - val_auc: 0.8438 - val_f1_score: 0.6818\n","Epoch 194/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0474 - auc: 0.9779 - f1_score: 0.8415 - val_loss: 0.2987 - val_auc: 0.8483 - val_f1_score: 0.6787\n","Epoch 195/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0443 - auc: 0.9807 - f1_score: 0.8521 - val_loss: 0.2724 - val_auc: 0.8450 - val_f1_score: 0.6777\n","Epoch 196/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0459 - auc: 0.9800 - f1_score: 0.8460 - val_loss: 0.2699 - val_auc: 0.8470 - val_f1_score: 0.6813\n","Epoch 197/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0446 - auc: 0.9801 - f1_score: 0.8504 - val_loss: 0.2911 - val_auc: 0.8472 - val_f1_score: 0.6797\n","Epoch 198/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0447 - auc: 0.9805 - f1_score: 0.8499 - val_loss: 0.3145 - val_auc: 0.8446 - val_f1_score: 0.6833\n","Epoch 199/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0463 - auc: 0.9791 - f1_score: 0.8463 - val_loss: 0.2884 - val_auc: 0.8440 - val_f1_score: 0.6840\n","Epoch 200/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0429 - auc: 0.9813 - f1_score: 0.8539 - val_loss: 0.3071 - val_auc: 0.8428 - val_f1_score: 0.6876\n","Epoch 201/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0427 - auc: 0.9815 - f1_score: 0.8544 - val_loss: 0.3308 - val_auc: 0.8460 - val_f1_score: 0.6996\n","Epoch 202/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0440 - auc: 0.9813 - f1_score: 0.8542 - val_loss: 0.3035 - val_auc: 0.8478 - val_f1_score: 0.6925\n","Epoch 203/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0453 - auc: 0.9803 - f1_score: 0.8518 - val_loss: 0.2956 - val_auc: 0.8382 - val_f1_score: 0.6831\n","Epoch 204/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0440 - auc: 0.9806 - f1_score: 0.8530 - val_loss: 0.2972 - val_auc: 0.8420 - val_f1_score: 0.6820\n","Epoch 205/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0409 - auc: 0.9831 - f1_score: 0.8606 - val_loss: 0.3079 - val_auc: 0.8442 - val_f1_score: 0.6791\n","Epoch 206/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0447 - auc: 0.9804 - f1_score: 0.8506 - val_loss: 0.2966 - val_auc: 0.8476 - val_f1_score: 0.6871\n","Epoch 207/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0429 - auc: 0.9820 - f1_score: 0.8578 - val_loss: 0.3333 - val_auc: 0.8446 - val_f1_score: 0.6979\n","Epoch 208/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0441 - auc: 0.9807 - f1_score: 0.8527 - val_loss: 0.3049 - val_auc: 0.8451 - val_f1_score: 0.6957\n","Epoch 209/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0429 - auc: 0.9822 - f1_score: 0.8587 - val_loss: 0.2943 - val_auc: 0.8434 - val_f1_score: 0.6891\n","Epoch 210/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0436 - auc: 0.9813 - f1_score: 0.8526 - val_loss: 0.2802 - val_auc: 0.8448 - val_f1_score: 0.6808\n","Epoch 211/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0432 - auc: 0.9808 - f1_score: 0.8531 - val_loss: 0.2972 - val_auc: 0.8435 - val_f1_score: 0.6905\n","Epoch 212/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0441 - auc: 0.9815 - f1_score: 0.8558 - val_loss: 0.3015 - val_auc: 0.8455 - val_f1_score: 0.6930\n","Epoch 213/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0430 - auc: 0.9808 - f1_score: 0.8541 - val_loss: 0.2977 - val_auc: 0.8473 - val_f1_score: 0.6922\n","Epoch 214/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0426 - auc: 0.9819 - f1_score: 0.8563 - val_loss: 0.2854 - val_auc: 0.8394 - val_f1_score: 0.6890\n","Epoch 215/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0418 - auc: 0.9818 - f1_score: 0.8572 - val_loss: 0.2945 - val_auc: 0.8426 - val_f1_score: 0.6813\n","Epoch 216/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0404 - auc: 0.9828 - f1_score: 0.8602 - val_loss: 0.3152 - val_auc: 0.8476 - val_f1_score: 0.6990\n","Epoch 217/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0419 - auc: 0.9821 - f1_score: 0.8568 - val_loss: 0.3092 - val_auc: 0.8454 - val_f1_score: 0.6897\n","Epoch 218/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0419 - auc: 0.9822 - f1_score: 0.8552 - val_loss: 0.3209 - val_auc: 0.8493 - val_f1_score: 0.6997\n","Epoch 219/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0409 - auc: 0.9831 - f1_score: 0.8620 - val_loss: 0.3176 - val_auc: 0.8467 - val_f1_score: 0.6853\n","Epoch 220/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0411 - auc: 0.9826 - f1_score: 0.8609 - val_loss: 0.2836 - val_auc: 0.8461 - val_f1_score: 0.6751\n","Epoch 221/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0427 - auc: 0.9816 - f1_score: 0.8556 - val_loss: 0.2948 - val_auc: 0.8451 - val_f1_score: 0.6820\n","Epoch 222/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0408 - auc: 0.9835 - f1_score: 0.8629 - val_loss: 0.3185 - val_auc: 0.8466 - val_f1_score: 0.6911\n","Epoch 223/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0406 - auc: 0.9835 - f1_score: 0.8634 - val_loss: 0.3006 - val_auc: 0.8409 - val_f1_score: 0.6802\n","Epoch 224/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0434 - auc: 0.9819 - f1_score: 0.8557 - val_loss: 0.3082 - val_auc: 0.8464 - val_f1_score: 0.6921\n","Epoch 225/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0424 - auc: 0.9816 - f1_score: 0.8576 - val_loss: 0.3233 - val_auc: 0.8422 - val_f1_score: 0.6961\n","Epoch 226/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0393 - auc: 0.9843 - f1_score: 0.8671 - val_loss: 0.3325 - val_auc: 0.8475 - val_f1_score: 0.6949\n","Epoch 227/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0416 - auc: 0.9824 - f1_score: 0.8601 - val_loss: 0.3025 - val_auc: 0.8433 - val_f1_score: 0.6927\n","Epoch 228/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0416 - auc: 0.9830 - f1_score: 0.8608 - val_loss: 0.3273 - val_auc: 0.8421 - val_f1_score: 0.6936\n","Epoch 229/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0398 - auc: 0.9838 - f1_score: 0.8636 - val_loss: 0.3265 - val_auc: 0.8387 - val_f1_score: 0.6801\n","Epoch 230/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0422 - auc: 0.9822 - f1_score: 0.8581 - val_loss: 0.2927 - val_auc: 0.8471 - val_f1_score: 0.6901\n","Epoch 231/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0417 - auc: 0.9819 - f1_score: 0.8574 - val_loss: 0.3051 - val_auc: 0.8485 - val_f1_score: 0.6912\n","Epoch 232/2000\n","123/123 [==============================] - 4s 35ms/step - loss: 0.0398 - auc: 0.9838 - f1_score: 0.8671 - val_loss: 0.3013 - val_auc: 0.8475 - val_f1_score: 0.6899\n","Epoch 233/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0407 - auc: 0.9834 - f1_score: 0.8634 - val_loss: 0.2990 - val_auc: 0.8459 - val_f1_score: 0.6869\n","Epoch 234/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0411 - auc: 0.9831 - f1_score: 0.8620 - val_loss: 0.3171 - val_auc: 0.8419 - val_f1_score: 0.6947\n","Epoch 235/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0386 - auc: 0.9845 - f1_score: 0.8673 - val_loss: 0.3471 - val_auc: 0.8410 - val_f1_score: 0.7014\n","Epoch 236/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0421 - auc: 0.9825 - f1_score: 0.8630 - val_loss: 0.2885 - val_auc: 0.8444 - val_f1_score: 0.6836\n","Epoch 237/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0387 - auc: 0.9846 - f1_score: 0.8679 - val_loss: 0.3483 - val_auc: 0.8464 - val_f1_score: 0.6963\n","Epoch 238/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0412 - auc: 0.9833 - f1_score: 0.8627 - val_loss: 0.3230 - val_auc: 0.8414 - val_f1_score: 0.6845\n","Epoch 239/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0417 - auc: 0.9833 - f1_score: 0.8629 - val_loss: 0.3040 - val_auc: 0.8430 - val_f1_score: 0.6906\n","Epoch 240/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0392 - auc: 0.9840 - f1_score: 0.8652 - val_loss: 0.3100 - val_auc: 0.8477 - val_f1_score: 0.6878\n","Epoch 241/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0442 - auc: 0.9818 - f1_score: 0.8540 - val_loss: 0.2784 - val_auc: 0.8362 - val_f1_score: 0.6651\n","Epoch 242/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0476 - auc: 0.9800 - f1_score: 0.8451 - val_loss: 0.3112 - val_auc: 0.8391 - val_f1_score: 0.6776\n","Epoch 243/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0418 - auc: 0.9823 - f1_score: 0.8573 - val_loss: 0.3214 - val_auc: 0.8445 - val_f1_score: 0.6893\n","Epoch 244/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0417 - auc: 0.9835 - f1_score: 0.8632 - val_loss: 0.3368 - val_auc: 0.8443 - val_f1_score: 0.7007\n","Epoch 245/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0386 - auc: 0.9850 - f1_score: 0.8698 - val_loss: 0.3069 - val_auc: 0.8440 - val_f1_score: 0.6840\n","Epoch 246/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0404 - auc: 0.9835 - f1_score: 0.8626 - val_loss: 0.3224 - val_auc: 0.8435 - val_f1_score: 0.6900\n","Epoch 247/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0405 - auc: 0.9846 - f1_score: 0.8678 - val_loss: 0.3307 - val_auc: 0.8452 - val_f1_score: 0.6891\n","Epoch 248/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0403 - auc: 0.9834 - f1_score: 0.8628 - val_loss: 0.3190 - val_auc: 0.8441 - val_f1_score: 0.6917\n","Epoch 249/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0413 - auc: 0.9835 - f1_score: 0.8625 - val_loss: 0.3260 - val_auc: 0.8445 - val_f1_score: 0.7001\n","Epoch 250/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0405 - auc: 0.9836 - f1_score: 0.8628 - val_loss: 0.3049 - val_auc: 0.8469 - val_f1_score: 0.7041\n","Epoch 251/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0389 - auc: 0.9850 - f1_score: 0.8710 - val_loss: 0.3178 - val_auc: 0.8422 - val_f1_score: 0.6845\n","Epoch 252/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0385 - auc: 0.9844 - f1_score: 0.8682 - val_loss: 0.3311 - val_auc: 0.8410 - val_f1_score: 0.6866\n","Epoch 253/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0395 - auc: 0.9844 - f1_score: 0.8675 - val_loss: 0.3242 - val_auc: 0.8377 - val_f1_score: 0.6953\n","Epoch 254/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0395 - auc: 0.9841 - f1_score: 0.8677 - val_loss: 0.3246 - val_auc: 0.8437 - val_f1_score: 0.6878\n","Epoch 255/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0383 - auc: 0.9852 - f1_score: 0.8700 - val_loss: 0.3237 - val_auc: 0.8451 - val_f1_score: 0.6858\n","Epoch 256/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0373 - auc: 0.9855 - f1_score: 0.8705 - val_loss: 0.3798 - val_auc: 0.8478 - val_f1_score: 0.7011\n","Epoch 257/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0373 - auc: 0.9858 - f1_score: 0.8754 - val_loss: 0.3451 - val_auc: 0.8382 - val_f1_score: 0.6876\n","Epoch 258/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0388 - auc: 0.9848 - f1_score: 0.8683 - val_loss: 0.3169 - val_auc: 0.8447 - val_f1_score: 0.6910\n","Epoch 259/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0388 - auc: 0.9846 - f1_score: 0.8693 - val_loss: 0.3367 - val_auc: 0.8443 - val_f1_score: 0.6933\n","Epoch 260/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0408 - auc: 0.9842 - f1_score: 0.8666 - val_loss: 0.3091 - val_auc: 0.8338 - val_f1_score: 0.6700\n","Epoch 261/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0436 - auc: 0.9817 - f1_score: 0.8556 - val_loss: 0.3123 - val_auc: 0.8399 - val_f1_score: 0.6896\n","Epoch 262/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0393 - auc: 0.9847 - f1_score: 0.8666 - val_loss: 0.3298 - val_auc: 0.8448 - val_f1_score: 0.6992\n","Epoch 263/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0388 - auc: 0.9854 - f1_score: 0.8720 - val_loss: 0.3472 - val_auc: 0.8422 - val_f1_score: 0.6944\n","Epoch 264/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0395 - auc: 0.9845 - f1_score: 0.8668 - val_loss: 0.3162 - val_auc: 0.8409 - val_f1_score: 0.6843\n","Epoch 265/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0370 - auc: 0.9860 - f1_score: 0.8735 - val_loss: 0.3334 - val_auc: 0.8422 - val_f1_score: 0.6992\n","Epoch 266/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0369 - auc: 0.9856 - f1_score: 0.8738 - val_loss: 0.3370 - val_auc: 0.8392 - val_f1_score: 0.6889\n","Epoch 267/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0402 - auc: 0.9846 - f1_score: 0.8684 - val_loss: 0.3085 - val_auc: 0.8431 - val_f1_score: 0.6903\n","Epoch 268/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0369 - auc: 0.9864 - f1_score: 0.8770 - val_loss: 0.3477 - val_auc: 0.8414 - val_f1_score: 0.7021\n","Epoch 269/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0382 - auc: 0.9854 - f1_score: 0.8729 - val_loss: 0.3294 - val_auc: 0.8411 - val_f1_score: 0.6886\n","Epoch 270/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0370 - auc: 0.9863 - f1_score: 0.8738 - val_loss: 0.3268 - val_auc: 0.8429 - val_f1_score: 0.6908\n","Epoch 271/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0363 - auc: 0.9867 - f1_score: 0.8782 - val_loss: 0.3514 - val_auc: 0.8450 - val_f1_score: 0.7003\n","Epoch 272/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0350 - auc: 0.9872 - f1_score: 0.8790 - val_loss: 0.3768 - val_auc: 0.8411 - val_f1_score: 0.7016\n","Epoch 273/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0368 - auc: 0.9861 - f1_score: 0.8736 - val_loss: 0.3412 - val_auc: 0.8353 - val_f1_score: 0.6856\n","Epoch 274/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0375 - auc: 0.9858 - f1_score: 0.8730 - val_loss: 0.3249 - val_auc: 0.8409 - val_f1_score: 0.6882\n","Epoch 275/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0382 - auc: 0.9860 - f1_score: 0.8736 - val_loss: 0.3020 - val_auc: 0.8416 - val_f1_score: 0.6852\n","Epoch 276/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0349 - auc: 0.9872 - f1_score: 0.8800 - val_loss: 0.3238 - val_auc: 0.8461 - val_f1_score: 0.6898\n","Epoch 277/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0374 - auc: 0.9862 - f1_score: 0.8765 - val_loss: 0.3187 - val_auc: 0.8439 - val_f1_score: 0.6878\n","Epoch 278/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0351 - auc: 0.9871 - f1_score: 0.8796 - val_loss: 0.3307 - val_auc: 0.8397 - val_f1_score: 0.6856\n","Epoch 279/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0369 - auc: 0.9864 - f1_score: 0.8782 - val_loss: 0.3365 - val_auc: 0.8423 - val_f1_score: 0.6918\n","Epoch 280/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0359 - auc: 0.9865 - f1_score: 0.8783 - val_loss: 0.3527 - val_auc: 0.8448 - val_f1_score: 0.6901\n","Epoch 281/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0381 - auc: 0.9859 - f1_score: 0.8750 - val_loss: 0.3242 - val_auc: 0.8432 - val_f1_score: 0.6925\n","Epoch 282/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0407 - auc: 0.9847 - f1_score: 0.8684 - val_loss: 0.3114 - val_auc: 0.8417 - val_f1_score: 0.6907\n","Epoch 283/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0363 - auc: 0.9867 - f1_score: 0.8766 - val_loss: 0.3586 - val_auc: 0.8433 - val_f1_score: 0.6997\n","Epoch 284/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0388 - auc: 0.9853 - f1_score: 0.8702 - val_loss: 0.3416 - val_auc: 0.8476 - val_f1_score: 0.6981\n","Epoch 285/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0365 - auc: 0.9867 - f1_score: 0.8779 - val_loss: 0.3174 - val_auc: 0.8371 - val_f1_score: 0.6813\n","Epoch 286/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0367 - auc: 0.9863 - f1_score: 0.8755 - val_loss: 0.3511 - val_auc: 0.8434 - val_f1_score: 0.6941\n","Epoch 287/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0350 - auc: 0.9870 - f1_score: 0.8802 - val_loss: 0.3527 - val_auc: 0.8429 - val_f1_score: 0.6910\n","Epoch 288/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0400 - auc: 0.9845 - f1_score: 0.8677 - val_loss: 0.3153 - val_auc: 0.8406 - val_f1_score: 0.6903\n","Epoch 289/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0371 - auc: 0.9868 - f1_score: 0.8788 - val_loss: 0.3532 - val_auc: 0.8399 - val_f1_score: 0.6971\n","Epoch 290/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0383 - auc: 0.9859 - f1_score: 0.8744 - val_loss: 0.3411 - val_auc: 0.8431 - val_f1_score: 0.6966\n","Epoch 291/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0350 - auc: 0.9871 - f1_score: 0.8775 - val_loss: 0.3378 - val_auc: 0.8464 - val_f1_score: 0.6926\n","Epoch 292/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0378 - auc: 0.9859 - f1_score: 0.8749 - val_loss: 0.3366 - val_auc: 0.8393 - val_f1_score: 0.6997\n","Epoch 293/2000\n","123/123 [==============================] - 4s 37ms/step - loss: 0.0366 - auc: 0.9865 - f1_score: 0.8791 - val_loss: 0.3402 - val_auc: 0.8474 - val_f1_score: 0.6930\n","Epoch 294/2000\n","123/123 [==============================] - 4s 37ms/step - loss: 0.0361 - auc: 0.9862 - f1_score: 0.8759 - val_loss: 0.3266 - val_auc: 0.8388 - val_f1_score: 0.6851\n","Epoch 295/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0374 - auc: 0.9858 - f1_score: 0.8743 - val_loss: 0.3137 - val_auc: 0.8422 - val_f1_score: 0.6893\n","Epoch 296/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0357 - auc: 0.9863 - f1_score: 0.8771 - val_loss: 0.3306 - val_auc: 0.8408 - val_f1_score: 0.6926\n","Epoch 297/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0352 - auc: 0.9875 - f1_score: 0.8799 - val_loss: 0.3550 - val_auc: 0.8477 - val_f1_score: 0.6956\n","Epoch 298/2000\n","123/123 [==============================] - 4s 37ms/step - loss: 0.0366 - auc: 0.9863 - f1_score: 0.8765 - val_loss: 0.3333 - val_auc: 0.8387 - val_f1_score: 0.6852\n","Epoch 299/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0367 - auc: 0.9865 - f1_score: 0.8779 - val_loss: 0.3433 - val_auc: 0.8399 - val_f1_score: 0.6946\n","Epoch 300/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0358 - auc: 0.9874 - f1_score: 0.8784 - val_loss: 0.3412 - val_auc: 0.8430 - val_f1_score: 0.6902\n","Epoch 301/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0364 - auc: 0.9871 - f1_score: 0.8800 - val_loss: 0.3470 - val_auc: 0.8439 - val_f1_score: 0.6943\n","Epoch 302/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0330 - auc: 0.9883 - f1_score: 0.8862 - val_loss: 0.3645 - val_auc: 0.8467 - val_f1_score: 0.6957\n","Epoch 303/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0349 - auc: 0.9878 - f1_score: 0.8826 - val_loss: 0.3416 - val_auc: 0.8443 - val_f1_score: 0.6968\n","Epoch 304/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0330 - auc: 0.9884 - f1_score: 0.8864 - val_loss: 0.3554 - val_auc: 0.8433 - val_f1_score: 0.7013\n","Epoch 305/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0355 - auc: 0.9873 - f1_score: 0.8800 - val_loss: 0.3732 - val_auc: 0.8422 - val_f1_score: 0.7006\n","Epoch 306/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0388 - auc: 0.9866 - f1_score: 0.8796 - val_loss: 0.3388 - val_auc: 0.8454 - val_f1_score: 0.6985\n","Epoch 307/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0369 - auc: 0.9877 - f1_score: 0.8846 - val_loss: 0.3806 - val_auc: 0.8429 - val_f1_score: 0.6994\n","Epoch 308/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0416 - auc: 0.9842 - f1_score: 0.8682 - val_loss: 0.3198 - val_auc: 0.8409 - val_f1_score: 0.6867\n","Epoch 309/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0400 - auc: 0.9849 - f1_score: 0.8705 - val_loss: 0.3482 - val_auc: 0.8415 - val_f1_score: 0.6967\n","Epoch 310/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0364 - auc: 0.9863 - f1_score: 0.8746 - val_loss: 0.3192 - val_auc: 0.8426 - val_f1_score: 0.6945\n","Epoch 311/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0347 - auc: 0.9876 - f1_score: 0.8816 - val_loss: 0.3400 - val_auc: 0.8426 - val_f1_score: 0.6949\n","Epoch 312/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0342 - auc: 0.9879 - f1_score: 0.8813 - val_loss: 0.3541 - val_auc: 0.8413 - val_f1_score: 0.6986\n","Epoch 313/2000\n","123/123 [==============================] - 4s 37ms/step - loss: 0.0351 - auc: 0.9875 - f1_score: 0.8810 - val_loss: 0.3430 - val_auc: 0.8437 - val_f1_score: 0.6924\n","Epoch 314/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0353 - auc: 0.9872 - f1_score: 0.8807 - val_loss: 0.3546 - val_auc: 0.8413 - val_f1_score: 0.6894\n","Epoch 315/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0360 - auc: 0.9869 - f1_score: 0.8785 - val_loss: 0.3524 - val_auc: 0.8470 - val_f1_score: 0.7030\n","Epoch 316/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0334 - auc: 0.9884 - f1_score: 0.8877 - val_loss: 0.3383 - val_auc: 0.8433 - val_f1_score: 0.7015\n","Epoch 317/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0351 - auc: 0.9879 - f1_score: 0.8849 - val_loss: 0.3661 - val_auc: 0.8418 - val_f1_score: 0.6966\n","Epoch 318/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0343 - auc: 0.9876 - f1_score: 0.8827 - val_loss: 0.3521 - val_auc: 0.8436 - val_f1_score: 0.6969\n","Epoch 319/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0342 - auc: 0.9873 - f1_score: 0.8803 - val_loss: 0.3738 - val_auc: 0.8469 - val_f1_score: 0.7031\n","Epoch 320/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0337 - auc: 0.9882 - f1_score: 0.8853 - val_loss: 0.3667 - val_auc: 0.8415 - val_f1_score: 0.6975\n","Epoch 321/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0342 - auc: 0.9882 - f1_score: 0.8836 - val_loss: 0.3738 - val_auc: 0.8404 - val_f1_score: 0.6965\n","Epoch 322/2000\n","123/123 [==============================] - 4s 37ms/step - loss: 0.0351 - auc: 0.9874 - f1_score: 0.8832 - val_loss: 0.3252 - val_auc: 0.8415 - val_f1_score: 0.6877\n","Epoch 323/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0408 - auc: 0.9869 - f1_score: 0.8795 - val_loss: 0.3673 - val_auc: 0.8405 - val_f1_score: 0.6991\n","Epoch 324/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0359 - auc: 0.9874 - f1_score: 0.8819 - val_loss: 0.3322 - val_auc: 0.8393 - val_f1_score: 0.6971\n","Epoch 325/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0345 - auc: 0.9879 - f1_score: 0.8828 - val_loss: 0.3566 - val_auc: 0.8388 - val_f1_score: 0.6964\n","Epoch 326/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0340 - auc: 0.9878 - f1_score: 0.8822 - val_loss: 0.3415 - val_auc: 0.8474 - val_f1_score: 0.6942\n","Epoch 327/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0355 - auc: 0.9875 - f1_score: 0.8812 - val_loss: 0.3635 - val_auc: 0.8395 - val_f1_score: 0.7003\n","Epoch 328/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0354 - auc: 0.9874 - f1_score: 0.8822 - val_loss: 0.3270 - val_auc: 0.8413 - val_f1_score: 0.6931\n","Epoch 329/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0335 - auc: 0.9882 - f1_score: 0.8857 - val_loss: 0.3512 - val_auc: 0.8451 - val_f1_score: 0.6966\n","Epoch 330/2000\n","123/123 [==============================] - 4s 37ms/step - loss: 0.0319 - auc: 0.9893 - f1_score: 0.8894 - val_loss: 0.3737 - val_auc: 0.8451 - val_f1_score: 0.6944\n","Epoch 331/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0340 - auc: 0.9879 - f1_score: 0.8844 - val_loss: 0.3708 - val_auc: 0.8413 - val_f1_score: 0.6951\n","Epoch 332/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0319 - auc: 0.9889 - f1_score: 0.8873 - val_loss: 0.3689 - val_auc: 0.8429 - val_f1_score: 0.6956\n","Epoch 333/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0335 - auc: 0.9883 - f1_score: 0.8854 - val_loss: 0.3508 - val_auc: 0.8453 - val_f1_score: 0.6878\n","Epoch 334/2000\n","123/123 [==============================] - 4s 37ms/step - loss: 0.0335 - auc: 0.9886 - f1_score: 0.8876 - val_loss: 0.3656 - val_auc: 0.8430 - val_f1_score: 0.7023\n","Epoch 335/2000\n","123/123 [==============================] - 4s 37ms/step - loss: 0.0449 - auc: 0.9820 - f1_score: 0.8593 - val_loss: 0.3052 - val_auc: 0.8390 - val_f1_score: 0.6787\n","Epoch 336/2000\n","123/123 [==============================] - 4s 37ms/step - loss: 0.0398 - auc: 0.9852 - f1_score: 0.8676 - val_loss: 0.3527 - val_auc: 0.8398 - val_f1_score: 0.6921\n","Epoch 337/2000\n","123/123 [==============================] - 4s 37ms/step - loss: 0.0371 - auc: 0.9859 - f1_score: 0.8758 - val_loss: 0.3265 - val_auc: 0.8448 - val_f1_score: 0.6860\n","Epoch 338/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0350 - auc: 0.9880 - f1_score: 0.8837 - val_loss: 0.3577 - val_auc: 0.8401 - val_f1_score: 0.6899\n","Epoch 339/2000\n","123/123 [==============================] - 4s 37ms/step - loss: 0.0343 - auc: 0.9881 - f1_score: 0.8839 - val_loss: 0.3609 - val_auc: 0.8418 - val_f1_score: 0.7000\n","Epoch 340/2000\n","123/123 [==============================] - 5s 39ms/step - loss: 0.0359 - auc: 0.9873 - f1_score: 0.8801 - val_loss: 0.3351 - val_auc: 0.8390 - val_f1_score: 0.6925\n","Epoch 341/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0335 - auc: 0.9886 - f1_score: 0.8872 - val_loss: 0.3530 - val_auc: 0.8417 - val_f1_score: 0.7024\n","Epoch 342/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0329 - auc: 0.9883 - f1_score: 0.8857 - val_loss: 0.3413 - val_auc: 0.8458 - val_f1_score: 0.6990\n","Epoch 343/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0325 - auc: 0.9892 - f1_score: 0.8885 - val_loss: 0.3595 - val_auc: 0.8444 - val_f1_score: 0.6994\n","Epoch 344/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0330 - auc: 0.9884 - f1_score: 0.8866 - val_loss: 0.3441 - val_auc: 0.8437 - val_f1_score: 0.6959\n","Epoch 345/2000\n","123/123 [==============================] - 5s 39ms/step - loss: 0.0317 - auc: 0.9897 - f1_score: 0.8920 - val_loss: 0.3760 - val_auc: 0.8388 - val_f1_score: 0.7085\n","Epoch 346/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0340 - auc: 0.9882 - f1_score: 0.8880 - val_loss: 0.3443 - val_auc: 0.8415 - val_f1_score: 0.6934\n","Epoch 347/2000\n","123/123 [==============================] - 4s 37ms/step - loss: 0.0351 - auc: 0.9879 - f1_score: 0.8822 - val_loss: 0.3522 - val_auc: 0.8413 - val_f1_score: 0.7035\n","Epoch 348/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0348 - auc: 0.9880 - f1_score: 0.8834 - val_loss: 0.3471 - val_auc: 0.8389 - val_f1_score: 0.6943\n","Epoch 349/2000\n","123/123 [==============================] - 4s 37ms/step - loss: 0.0330 - auc: 0.9884 - f1_score: 0.8851 - val_loss: 0.3660 - val_auc: 0.8424 - val_f1_score: 0.6998\n","Epoch 350/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0354 - auc: 0.9877 - f1_score: 0.8831 - val_loss: 0.3337 - val_auc: 0.8419 - val_f1_score: 0.7023\n","Epoch 351/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0335 - auc: 0.9882 - f1_score: 0.8871 - val_loss: 0.3664 - val_auc: 0.8392 - val_f1_score: 0.7021\n","Epoch 352/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0347 - auc: 0.9875 - f1_score: 0.8821 - val_loss: 0.3908 - val_auc: 0.8418 - val_f1_score: 0.6958\n","Epoch 353/2000\n","123/123 [==============================] - 4s 36ms/step - loss: 0.0336 - auc: 0.9881 - f1_score: 0.8831 - val_loss: 0.3551 - val_auc: 0.8456 - val_f1_score: 0.6942\n","Epoch 354/2000\n","123/123 [==============================] - 4s 37ms/step - loss: 0.0318 - auc: 0.9895 - f1_score: 0.8905 - val_loss: 0.3620 - val_auc: 0.8454 - val_f1_score: 0.7036\n","Epoch 355/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0320 - auc: 0.9895 - f1_score: 0.8920 - val_loss: 0.3554 - val_auc: 0.8436 - val_f1_score: 0.6990\n","Epoch 356/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0320 - auc: 0.9898 - f1_score: 0.8924 - val_loss: 0.3575 - val_auc: 0.8442 - val_f1_score: 0.7047\n","Epoch 357/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0329 - auc: 0.9890 - f1_score: 0.8908 - val_loss: 0.3470 - val_auc: 0.8434 - val_f1_score: 0.6927\n","Epoch 358/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0326 - auc: 0.9894 - f1_score: 0.8894 - val_loss: 0.3597 - val_auc: 0.8463 - val_f1_score: 0.6962\n","Epoch 359/2000\n","123/123 [==============================] - 5s 39ms/step - loss: 0.0320 - auc: 0.9892 - f1_score: 0.8913 - val_loss: 0.3719 - val_auc: 0.8426 - val_f1_score: 0.6906\n","Epoch 360/2000\n","123/123 [==============================] - 5s 40ms/step - loss: 0.0333 - auc: 0.9890 - f1_score: 0.8888 - val_loss: 0.3388 - val_auc: 0.8430 - val_f1_score: 0.6901\n","Epoch 361/2000\n","123/123 [==============================] - 5s 40ms/step - loss: 0.0326 - auc: 0.9888 - f1_score: 0.8901 - val_loss: 0.3691 - val_auc: 0.8434 - val_f1_score: 0.6990\n","Epoch 362/2000\n","123/123 [==============================] - 5s 39ms/step - loss: 0.0316 - auc: 0.9895 - f1_score: 0.8913 - val_loss: 0.3668 - val_auc: 0.8403 - val_f1_score: 0.7021\n","Epoch 363/2000\n","123/123 [==============================] - 5s 39ms/step - loss: 0.0306 - auc: 0.9900 - f1_score: 0.8921 - val_loss: 0.4055 - val_auc: 0.8440 - val_f1_score: 0.7000\n","Epoch 364/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0336 - auc: 0.9885 - f1_score: 0.8894 - val_loss: 0.3556 - val_auc: 0.8419 - val_f1_score: 0.6919\n","Epoch 365/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0318 - auc: 0.9897 - f1_score: 0.8914 - val_loss: 0.3656 - val_auc: 0.8409 - val_f1_score: 0.6963\n","Epoch 366/2000\n","123/123 [==============================] - 5s 39ms/step - loss: 0.0357 - auc: 0.9885 - f1_score: 0.8874 - val_loss: 0.3513 - val_auc: 0.8396 - val_f1_score: 0.7007\n","Epoch 367/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0333 - auc: 0.9891 - f1_score: 0.8898 - val_loss: 0.3596 - val_auc: 0.8396 - val_f1_score: 0.6987\n","Epoch 368/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0307 - auc: 0.9903 - f1_score: 0.8963 - val_loss: 0.3596 - val_auc: 0.8452 - val_f1_score: 0.6939\n","Epoch 369/2000\n","123/123 [==============================] - 5s 41ms/step - loss: 0.0311 - auc: 0.9897 - f1_score: 0.8942 - val_loss: 0.3799 - val_auc: 0.8441 - val_f1_score: 0.7078\n","Epoch 370/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0319 - auc: 0.9900 - f1_score: 0.8951 - val_loss: 0.3826 - val_auc: 0.8421 - val_f1_score: 0.6940\n","Epoch 371/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0306 - auc: 0.9901 - f1_score: 0.8945 - val_loss: 0.3663 - val_auc: 0.8404 - val_f1_score: 0.6960\n","Epoch 372/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0325 - auc: 0.9887 - f1_score: 0.8877 - val_loss: 0.3722 - val_auc: 0.8457 - val_f1_score: 0.6947\n","Epoch 373/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0322 - auc: 0.9895 - f1_score: 0.8886 - val_loss: 0.3620 - val_auc: 0.8395 - val_f1_score: 0.6940\n","Epoch 374/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0332 - auc: 0.9889 - f1_score: 0.8889 - val_loss: 0.3572 - val_auc: 0.8399 - val_f1_score: 0.6963\n","Epoch 375/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0325 - auc: 0.9893 - f1_score: 0.8889 - val_loss: 0.3864 - val_auc: 0.8402 - val_f1_score: 0.6966\n","Epoch 376/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0336 - auc: 0.9886 - f1_score: 0.8881 - val_loss: 0.3579 - val_auc: 0.8401 - val_f1_score: 0.6970\n","Epoch 377/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0342 - auc: 0.9880 - f1_score: 0.8820 - val_loss: 0.3577 - val_auc: 0.8452 - val_f1_score: 0.6857\n","Epoch 378/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0338 - auc: 0.9889 - f1_score: 0.8875 - val_loss: 0.3545 - val_auc: 0.8399 - val_f1_score: 0.6944\n","Epoch 379/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0307 - auc: 0.9901 - f1_score: 0.8930 - val_loss: 0.3678 - val_auc: 0.8433 - val_f1_score: 0.6956\n","Epoch 380/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0318 - auc: 0.9896 - f1_score: 0.8926 - val_loss: 0.3746 - val_auc: 0.8412 - val_f1_score: 0.6995\n","Epoch 381/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0318 - auc: 0.9894 - f1_score: 0.8902 - val_loss: 0.3631 - val_auc: 0.8382 - val_f1_score: 0.7008\n","Epoch 382/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0317 - auc: 0.9896 - f1_score: 0.8920 - val_loss: 0.3872 - val_auc: 0.8371 - val_f1_score: 0.6990\n","Epoch 383/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0305 - auc: 0.9904 - f1_score: 0.8964 - val_loss: 0.3905 - val_auc: 0.8412 - val_f1_score: 0.6971\n","Epoch 384/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0329 - auc: 0.9893 - f1_score: 0.8909 - val_loss: 0.3641 - val_auc: 0.8401 - val_f1_score: 0.6922\n","Epoch 385/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0329 - auc: 0.9887 - f1_score: 0.8879 - val_loss: 0.3550 - val_auc: 0.8409 - val_f1_score: 0.6866\n","Epoch 386/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0329 - auc: 0.9890 - f1_score: 0.8887 - val_loss: 0.3647 - val_auc: 0.8374 - val_f1_score: 0.6832\n","Epoch 387/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0355 - auc: 0.9881 - f1_score: 0.8824 - val_loss: 0.3676 - val_auc: 0.8429 - val_f1_score: 0.7036\n","Epoch 388/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0333 - auc: 0.9894 - f1_score: 0.8908 - val_loss: 0.3456 - val_auc: 0.8402 - val_f1_score: 0.6973\n","Epoch 389/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0323 - auc: 0.9894 - f1_score: 0.8900 - val_loss: 0.3916 - val_auc: 0.8404 - val_f1_score: 0.7082\n","Epoch 390/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0327 - auc: 0.9896 - f1_score: 0.8938 - val_loss: 0.3929 - val_auc: 0.8412 - val_f1_score: 0.7074\n","Epoch 391/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0308 - auc: 0.9895 - f1_score: 0.8923 - val_loss: 0.3710 - val_auc: 0.8410 - val_f1_score: 0.7016\n","Epoch 392/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0322 - auc: 0.9902 - f1_score: 0.8944 - val_loss: 0.3477 - val_auc: 0.8444 - val_f1_score: 0.6948\n","Epoch 393/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0330 - auc: 0.9891 - f1_score: 0.8902 - val_loss: 0.3599 - val_auc: 0.8407 - val_f1_score: 0.7063\n","Epoch 394/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0304 - auc: 0.9906 - f1_score: 0.8969 - val_loss: 0.3911 - val_auc: 0.8400 - val_f1_score: 0.7051\n","Epoch 395/2000\n","123/123 [==============================] - 4s 37ms/step - loss: 0.0305 - auc: 0.9905 - f1_score: 0.8959 - val_loss: 0.3655 - val_auc: 0.8413 - val_f1_score: 0.7008\n","Epoch 396/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0338 - auc: 0.9888 - f1_score: 0.8885 - val_loss: 0.3830 - val_auc: 0.8436 - val_f1_score: 0.7072\n","Epoch 397/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0306 - auc: 0.9903 - f1_score: 0.8955 - val_loss: 0.3709 - val_auc: 0.8423 - val_f1_score: 0.6987\n","Epoch 398/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0326 - auc: 0.9892 - f1_score: 0.8921 - val_loss: 0.3423 - val_auc: 0.8479 - val_f1_score: 0.6943\n","Epoch 399/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0319 - auc: 0.9899 - f1_score: 0.8910 - val_loss: 0.3999 - val_auc: 0.8395 - val_f1_score: 0.7015\n","Epoch 400/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0300 - auc: 0.9904 - f1_score: 0.8937 - val_loss: 0.3904 - val_auc: 0.8426 - val_f1_score: 0.7087\n","Epoch 401/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0308 - auc: 0.9898 - f1_score: 0.8935 - val_loss: 0.3815 - val_auc: 0.8406 - val_f1_score: 0.6928\n","Epoch 402/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0302 - auc: 0.9908 - f1_score: 0.8977 - val_loss: 0.4111 - val_auc: 0.8404 - val_f1_score: 0.7051\n","Epoch 403/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0355 - auc: 0.9892 - f1_score: 0.8917 - val_loss: 0.3812 - val_auc: 0.8432 - val_f1_score: 0.7049\n","Epoch 404/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0321 - auc: 0.9900 - f1_score: 0.8940 - val_loss: 0.3528 - val_auc: 0.8487 - val_f1_score: 0.7005\n","Epoch 405/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0323 - auc: 0.9893 - f1_score: 0.8903 - val_loss: 0.3692 - val_auc: 0.8455 - val_f1_score: 0.6944\n","Epoch 406/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0299 - auc: 0.9907 - f1_score: 0.8972 - val_loss: 0.3647 - val_auc: 0.8444 - val_f1_score: 0.7036\n","Epoch 407/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0305 - auc: 0.9899 - f1_score: 0.8949 - val_loss: 0.3823 - val_auc: 0.8413 - val_f1_score: 0.7037\n","Epoch 408/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0317 - auc: 0.9901 - f1_score: 0.8960 - val_loss: 0.3882 - val_auc: 0.8423 - val_f1_score: 0.6982\n","Epoch 409/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0301 - auc: 0.9900 - f1_score: 0.8940 - val_loss: 0.3921 - val_auc: 0.8415 - val_f1_score: 0.7007\n","Epoch 410/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0300 - auc: 0.9905 - f1_score: 0.8962 - val_loss: 0.3660 - val_auc: 0.8423 - val_f1_score: 0.6933\n","Epoch 411/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0309 - auc: 0.9903 - f1_score: 0.8951 - val_loss: 0.3868 - val_auc: 0.8432 - val_f1_score: 0.6982\n","Epoch 412/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0316 - auc: 0.9902 - f1_score: 0.8945 - val_loss: 0.3624 - val_auc: 0.8392 - val_f1_score: 0.7004\n","Epoch 413/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0311 - auc: 0.9897 - f1_score: 0.8944 - val_loss: 0.3864 - val_auc: 0.8396 - val_f1_score: 0.6946\n","Epoch 414/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0299 - auc: 0.9907 - f1_score: 0.8991 - val_loss: 0.3897 - val_auc: 0.8411 - val_f1_score: 0.7063\n","Epoch 415/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0303 - auc: 0.9902 - f1_score: 0.8966 - val_loss: 0.4076 - val_auc: 0.8397 - val_f1_score: 0.7036\n","Epoch 416/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0356 - auc: 0.9879 - f1_score: 0.8839 - val_loss: 0.3267 - val_auc: 0.8436 - val_f1_score: 0.6930\n","Epoch 417/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0325 - auc: 0.9896 - f1_score: 0.8919 - val_loss: 0.3633 - val_auc: 0.8399 - val_f1_score: 0.6924\n","Epoch 418/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0305 - auc: 0.9904 - f1_score: 0.8967 - val_loss: 0.3629 - val_auc: 0.8416 - val_f1_score: 0.6962\n","Epoch 419/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0304 - auc: 0.9904 - f1_score: 0.8955 - val_loss: 0.3725 - val_auc: 0.8373 - val_f1_score: 0.6962\n","Epoch 420/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0320 - auc: 0.9891 - f1_score: 0.8908 - val_loss: 0.3880 - val_auc: 0.8426 - val_f1_score: 0.7041\n","Epoch 421/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0307 - auc: 0.9908 - f1_score: 0.8996 - val_loss: 0.3905 - val_auc: 0.8381 - val_f1_score: 0.7056\n","Epoch 422/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0329 - auc: 0.9904 - f1_score: 0.8982 - val_loss: 0.3431 - val_auc: 0.8401 - val_f1_score: 0.6908\n","Epoch 423/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0296 - auc: 0.9906 - f1_score: 0.8979 - val_loss: 0.4062 - val_auc: 0.8387 - val_f1_score: 0.6992\n","Epoch 424/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0365 - auc: 0.9878 - f1_score: 0.8846 - val_loss: 0.3424 - val_auc: 0.8350 - val_f1_score: 0.6922\n","Epoch 425/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0316 - auc: 0.9895 - f1_score: 0.8910 - val_loss: 0.3529 - val_auc: 0.8414 - val_f1_score: 0.6945\n","Epoch 426/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0296 - auc: 0.9906 - f1_score: 0.8964 - val_loss: 0.3843 - val_auc: 0.8388 - val_f1_score: 0.7005\n","Epoch 427/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0298 - auc: 0.9907 - f1_score: 0.8999 - val_loss: 0.3834 - val_auc: 0.8396 - val_f1_score: 0.6963\n","Epoch 428/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0294 - auc: 0.9909 - f1_score: 0.8985 - val_loss: 0.3833 - val_auc: 0.8430 - val_f1_score: 0.7022\n","Epoch 429/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0319 - auc: 0.9898 - f1_score: 0.8940 - val_loss: 0.3934 - val_auc: 0.8386 - val_f1_score: 0.7063\n","Epoch 430/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0291 - auc: 0.9907 - f1_score: 0.8993 - val_loss: 0.3712 - val_auc: 0.8376 - val_f1_score: 0.6966\n","Epoch 431/2000\n","123/123 [==============================] - 5s 40ms/step - loss: 0.0306 - auc: 0.9904 - f1_score: 0.8982 - val_loss: 0.3765 - val_auc: 0.8420 - val_f1_score: 0.7010\n","Epoch 432/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0295 - auc: 0.9911 - f1_score: 0.8984 - val_loss: 0.3912 - val_auc: 0.8422 - val_f1_score: 0.7054\n","Epoch 433/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0287 - auc: 0.9910 - f1_score: 0.9037 - val_loss: 0.3887 - val_auc: 0.8391 - val_f1_score: 0.6991\n","Epoch 434/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0305 - auc: 0.9902 - f1_score: 0.8954 - val_loss: 0.3942 - val_auc: 0.8357 - val_f1_score: 0.6903\n","Epoch 435/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0300 - auc: 0.9904 - f1_score: 0.8955 - val_loss: 0.3949 - val_auc: 0.8400 - val_f1_score: 0.7029\n","Epoch 436/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0297 - auc: 0.9909 - f1_score: 0.9006 - val_loss: 0.3859 - val_auc: 0.8412 - val_f1_score: 0.7021\n","Epoch 437/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0297 - auc: 0.9908 - f1_score: 0.8997 - val_loss: 0.4166 - val_auc: 0.8393 - val_f1_score: 0.7115\n","Epoch 438/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0299 - auc: 0.9909 - f1_score: 0.8988 - val_loss: 0.3754 - val_auc: 0.8382 - val_f1_score: 0.6979\n","Epoch 439/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0315 - auc: 0.9900 - f1_score: 0.8956 - val_loss: 0.3610 - val_auc: 0.8399 - val_f1_score: 0.7008\n","Epoch 440/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0292 - auc: 0.9912 - f1_score: 0.9001 - val_loss: 0.3964 - val_auc: 0.8409 - val_f1_score: 0.7125\n","Epoch 441/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0306 - auc: 0.9902 - f1_score: 0.8970 - val_loss: 0.3834 - val_auc: 0.8398 - val_f1_score: 0.7024\n","Epoch 442/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0290 - auc: 0.9909 - f1_score: 0.9014 - val_loss: 0.4012 - val_auc: 0.8418 - val_f1_score: 0.7006\n","Epoch 443/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0299 - auc: 0.9905 - f1_score: 0.8964 - val_loss: 0.3788 - val_auc: 0.8371 - val_f1_score: 0.7041\n","Epoch 444/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0293 - auc: 0.9909 - f1_score: 0.9003 - val_loss: 0.3791 - val_auc: 0.8371 - val_f1_score: 0.6985\n","Epoch 445/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0282 - auc: 0.9919 - f1_score: 0.9040 - val_loss: 0.3857 - val_auc: 0.8406 - val_f1_score: 0.7032\n","Epoch 446/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0292 - auc: 0.9912 - f1_score: 0.9000 - val_loss: 0.4114 - val_auc: 0.8401 - val_f1_score: 0.7038\n","Epoch 447/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0292 - auc: 0.9910 - f1_score: 0.9000 - val_loss: 0.3790 - val_auc: 0.8397 - val_f1_score: 0.7067\n","Epoch 448/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0310 - auc: 0.9907 - f1_score: 0.9000 - val_loss: 0.3799 - val_auc: 0.8389 - val_f1_score: 0.7011\n","Epoch 449/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0300 - auc: 0.9909 - f1_score: 0.9000 - val_loss: 0.3813 - val_auc: 0.8386 - val_f1_score: 0.6983\n","Epoch 450/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0289 - auc: 0.9910 - f1_score: 0.9005 - val_loss: 0.3973 - val_auc: 0.8404 - val_f1_score: 0.7054\n","Epoch 451/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0294 - auc: 0.9913 - f1_score: 0.9026 - val_loss: 0.4211 - val_auc: 0.8386 - val_f1_score: 0.7027\n","Epoch 452/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0299 - auc: 0.9909 - f1_score: 0.9014 - val_loss: 0.3796 - val_auc: 0.8397 - val_f1_score: 0.7009\n","Epoch 453/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0287 - auc: 0.9912 - f1_score: 0.9024 - val_loss: 0.3933 - val_auc: 0.8415 - val_f1_score: 0.7023\n","Epoch 454/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0291 - auc: 0.9911 - f1_score: 0.8997 - val_loss: 0.3988 - val_auc: 0.8393 - val_f1_score: 0.7036\n","Epoch 455/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0280 - auc: 0.9918 - f1_score: 0.9044 - val_loss: 0.3932 - val_auc: 0.8426 - val_f1_score: 0.7074\n","Epoch 456/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0299 - auc: 0.9910 - f1_score: 0.9009 - val_loss: 0.3982 - val_auc: 0.8331 - val_f1_score: 0.7018\n","Epoch 457/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0324 - auc: 0.9904 - f1_score: 0.8983 - val_loss: 0.3584 - val_auc: 0.8433 - val_f1_score: 0.7036\n","Epoch 458/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0301 - auc: 0.9909 - f1_score: 0.8982 - val_loss: 0.3960 - val_auc: 0.8409 - val_f1_score: 0.7075\n","Epoch 459/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0292 - auc: 0.9910 - f1_score: 0.9001 - val_loss: 0.4025 - val_auc: 0.8407 - val_f1_score: 0.7057\n","Epoch 460/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0305 - auc: 0.9909 - f1_score: 0.8997 - val_loss: 0.3837 - val_auc: 0.8433 - val_f1_score: 0.6976\n","Epoch 461/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0276 - auc: 0.9917 - f1_score: 0.9025 - val_loss: 0.4280 - val_auc: 0.8456 - val_f1_score: 0.7008\n","Epoch 462/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0282 - auc: 0.9916 - f1_score: 0.9036 - val_loss: 0.4009 - val_auc: 0.8397 - val_f1_score: 0.7005\n","Epoch 463/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0303 - auc: 0.9907 - f1_score: 0.8967 - val_loss: 0.3947 - val_auc: 0.8361 - val_f1_score: 0.7029\n","Epoch 464/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0307 - auc: 0.9904 - f1_score: 0.8967 - val_loss: 0.3869 - val_auc: 0.8406 - val_f1_score: 0.7037\n","Epoch 465/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0298 - auc: 0.9908 - f1_score: 0.8981 - val_loss: 0.3854 - val_auc: 0.8352 - val_f1_score: 0.6954\n","Epoch 466/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0306 - auc: 0.9905 - f1_score: 0.8983 - val_loss: 0.3736 - val_auc: 0.8379 - val_f1_score: 0.6918\n","Epoch 467/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0285 - auc: 0.9915 - f1_score: 0.9020 - val_loss: 0.4313 - val_auc: 0.8425 - val_f1_score: 0.7093\n","Epoch 468/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0296 - auc: 0.9906 - f1_score: 0.8979 - val_loss: 0.3882 - val_auc: 0.8393 - val_f1_score: 0.6995\n","Epoch 469/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0289 - auc: 0.9915 - f1_score: 0.9019 - val_loss: 0.4023 - val_auc: 0.8393 - val_f1_score: 0.7009\n","Epoch 470/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0286 - auc: 0.9914 - f1_score: 0.9025 - val_loss: 0.4040 - val_auc: 0.8402 - val_f1_score: 0.7033\n","Epoch 471/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0285 - auc: 0.9915 - f1_score: 0.9043 - val_loss: 0.3877 - val_auc: 0.8388 - val_f1_score: 0.6950\n","Epoch 472/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0283 - auc: 0.9916 - f1_score: 0.9020 - val_loss: 0.4239 - val_auc: 0.8356 - val_f1_score: 0.7048\n","Epoch 473/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0288 - auc: 0.9915 - f1_score: 0.9021 - val_loss: 0.4127 - val_auc: 0.8357 - val_f1_score: 0.7079\n","Epoch 474/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0290 - auc: 0.9915 - f1_score: 0.9031 - val_loss: 0.4293 - val_auc: 0.8415 - val_f1_score: 0.7071\n","Epoch 475/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0292 - auc: 0.9914 - f1_score: 0.9036 - val_loss: 0.3914 - val_auc: 0.8399 - val_f1_score: 0.7025\n","Epoch 476/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0279 - auc: 0.9917 - f1_score: 0.9055 - val_loss: 0.3878 - val_auc: 0.8367 - val_f1_score: 0.7013\n","Epoch 477/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0282 - auc: 0.9915 - f1_score: 0.9051 - val_loss: 0.3941 - val_auc: 0.8374 - val_f1_score: 0.6938\n","Epoch 478/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0292 - auc: 0.9909 - f1_score: 0.8998 - val_loss: 0.3686 - val_auc: 0.8393 - val_f1_score: 0.6961\n","Epoch 479/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0284 - auc: 0.9917 - f1_score: 0.9031 - val_loss: 0.4070 - val_auc: 0.8371 - val_f1_score: 0.7062\n","Epoch 480/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0287 - auc: 0.9917 - f1_score: 0.9040 - val_loss: 0.3618 - val_auc: 0.8300 - val_f1_score: 0.6875\n","Epoch 481/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0295 - auc: 0.9909 - f1_score: 0.9004 - val_loss: 0.3698 - val_auc: 0.8437 - val_f1_score: 0.6957\n","Epoch 482/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0323 - auc: 0.9903 - f1_score: 0.8964 - val_loss: 0.3785 - val_auc: 0.8381 - val_f1_score: 0.6944\n","Epoch 483/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0299 - auc: 0.9911 - f1_score: 0.8987 - val_loss: 0.4008 - val_auc: 0.8370 - val_f1_score: 0.7086\n","Epoch 484/2000\n","123/123 [==============================] - 5s 37ms/step - loss: 0.0303 - auc: 0.9910 - f1_score: 0.8987 - val_loss: 0.4007 - val_auc: 0.8396 - val_f1_score: 0.7076\n","Epoch 485/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0280 - auc: 0.9920 - f1_score: 0.9067 - val_loss: 0.4078 - val_auc: 0.8384 - val_f1_score: 0.6965\n","Epoch 486/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0282 - auc: 0.9915 - f1_score: 0.9022 - val_loss: 0.4091 - val_auc: 0.8378 - val_f1_score: 0.7002\n","Epoch 487/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0278 - auc: 0.9919 - f1_score: 0.9043 - val_loss: 0.4134 - val_auc: 0.8353 - val_f1_score: 0.7067\n","Epoch 488/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0302 - auc: 0.9907 - f1_score: 0.8982 - val_loss: 0.3951 - val_auc: 0.8353 - val_f1_score: 0.7068\n","Epoch 489/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0292 - auc: 0.9914 - f1_score: 0.9028 - val_loss: 0.4137 - val_auc: 0.8436 - val_f1_score: 0.7050\n","Epoch 490/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0272 - auc: 0.9922 - f1_score: 0.9075 - val_loss: 0.4112 - val_auc: 0.8358 - val_f1_score: 0.7030\n","Epoch 491/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0279 - auc: 0.9918 - f1_score: 0.9058 - val_loss: 0.4200 - val_auc: 0.8428 - val_f1_score: 0.7074\n","Epoch 492/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0269 - auc: 0.9925 - f1_score: 0.9092 - val_loss: 0.4081 - val_auc: 0.8366 - val_f1_score: 0.6985\n","Epoch 493/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0300 - auc: 0.9908 - f1_score: 0.8999 - val_loss: 0.3847 - val_auc: 0.8383 - val_f1_score: 0.6870\n","Epoch 494/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0281 - auc: 0.9915 - f1_score: 0.9038 - val_loss: 0.4001 - val_auc: 0.8395 - val_f1_score: 0.7020\n","Epoch 495/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0271 - auc: 0.9920 - f1_score: 0.9056 - val_loss: 0.4711 - val_auc: 0.8410 - val_f1_score: 0.7022\n","Epoch 496/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0276 - auc: 0.9917 - f1_score: 0.9047 - val_loss: 0.4286 - val_auc: 0.8405 - val_f1_score: 0.6974\n","Epoch 497/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0293 - auc: 0.9909 - f1_score: 0.9011 - val_loss: 0.4013 - val_auc: 0.8373 - val_f1_score: 0.6999\n","Epoch 498/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0261 - auc: 0.9928 - f1_score: 0.9084 - val_loss: 0.4397 - val_auc: 0.8396 - val_f1_score: 0.7091\n","Epoch 499/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0280 - auc: 0.9917 - f1_score: 0.9071 - val_loss: 0.4005 - val_auc: 0.8400 - val_f1_score: 0.6981\n","Epoch 500/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0314 - auc: 0.9901 - f1_score: 0.8943 - val_loss: 0.3949 - val_auc: 0.8415 - val_f1_score: 0.7038\n","Epoch 501/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0295 - auc: 0.9912 - f1_score: 0.9011 - val_loss: 0.3972 - val_auc: 0.8355 - val_f1_score: 0.7021\n","Epoch 502/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0275 - auc: 0.9918 - f1_score: 0.9050 - val_loss: 0.4053 - val_auc: 0.8426 - val_f1_score: 0.7016\n","Epoch 503/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0287 - auc: 0.9917 - f1_score: 0.9026 - val_loss: 0.4135 - val_auc: 0.8377 - val_f1_score: 0.7073\n","Epoch 504/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0267 - auc: 0.9922 - f1_score: 0.9081 - val_loss: 0.4129 - val_auc: 0.8316 - val_f1_score: 0.6970\n","Epoch 505/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0288 - auc: 0.9914 - f1_score: 0.9025 - val_loss: 0.3970 - val_auc: 0.8337 - val_f1_score: 0.6910\n","Epoch 506/2000\n","123/123 [==============================] - 5s 39ms/step - loss: 0.0288 - auc: 0.9915 - f1_score: 0.9027 - val_loss: 0.4302 - val_auc: 0.8402 - val_f1_score: 0.7040\n","Epoch 507/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0267 - auc: 0.9924 - f1_score: 0.9082 - val_loss: 0.4175 - val_auc: 0.8375 - val_f1_score: 0.7061\n","Epoch 508/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0282 - auc: 0.9916 - f1_score: 0.9053 - val_loss: 0.4064 - val_auc: 0.8414 - val_f1_score: 0.7027\n","Epoch 509/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0279 - auc: 0.9919 - f1_score: 0.9039 - val_loss: 0.3841 - val_auc: 0.8379 - val_f1_score: 0.6982\n","Epoch 510/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0283 - auc: 0.9916 - f1_score: 0.9051 - val_loss: 0.4180 - val_auc: 0.8381 - val_f1_score: 0.7005\n","Epoch 511/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0275 - auc: 0.9920 - f1_score: 0.9054 - val_loss: 0.4258 - val_auc: 0.8338 - val_f1_score: 0.7130\n","Epoch 512/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0268 - auc: 0.9925 - f1_score: 0.9108 - val_loss: 0.4215 - val_auc: 0.8393 - val_f1_score: 0.7080\n","Epoch 513/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0278 - auc: 0.9919 - f1_score: 0.9061 - val_loss: 0.4314 - val_auc: 0.8376 - val_f1_score: 0.7132\n","Epoch 514/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0297 - auc: 0.9912 - f1_score: 0.9015 - val_loss: 0.4109 - val_auc: 0.8374 - val_f1_score: 0.7117\n","Epoch 515/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0273 - auc: 0.9919 - f1_score: 0.9052 - val_loss: 0.4084 - val_auc: 0.8321 - val_f1_score: 0.6971\n","Epoch 516/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0304 - auc: 0.9907 - f1_score: 0.8984 - val_loss: 0.4106 - val_auc: 0.8367 - val_f1_score: 0.6973\n","Epoch 517/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0280 - auc: 0.9921 - f1_score: 0.9048 - val_loss: 0.4397 - val_auc: 0.8349 - val_f1_score: 0.7100\n","Epoch 518/2000\n","123/123 [==============================] - 5s 40ms/step - loss: 0.0276 - auc: 0.9924 - f1_score: 0.9068 - val_loss: 0.3986 - val_auc: 0.8366 - val_f1_score: 0.7026\n","Epoch 519/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0280 - auc: 0.9916 - f1_score: 0.9042 - val_loss: 0.4250 - val_auc: 0.8406 - val_f1_score: 0.7039\n","Epoch 520/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0270 - auc: 0.9923 - f1_score: 0.9077 - val_loss: 0.4286 - val_auc: 0.8419 - val_f1_score: 0.7031\n","Epoch 521/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0317 - auc: 0.9896 - f1_score: 0.8946 - val_loss: 0.3844 - val_auc: 0.8369 - val_f1_score: 0.6984\n","Epoch 522/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0319 - auc: 0.9901 - f1_score: 0.8947 - val_loss: 0.3780 - val_auc: 0.8404 - val_f1_score: 0.6989\n","Epoch 523/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0268 - auc: 0.9920 - f1_score: 0.9052 - val_loss: 0.4303 - val_auc: 0.8381 - val_f1_score: 0.7064\n","Epoch 524/2000\n","123/123 [==============================] - 5s 39ms/step - loss: 0.0278 - auc: 0.9918 - f1_score: 0.9048 - val_loss: 0.3624 - val_auc: 0.8409 - val_f1_score: 0.7018\n","Epoch 525/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0272 - auc: 0.9920 - f1_score: 0.9036 - val_loss: 0.4080 - val_auc: 0.8395 - val_f1_score: 0.6970\n","Epoch 526/2000\n","123/123 [==============================] - 5s 39ms/step - loss: 0.0302 - auc: 0.9907 - f1_score: 0.8987 - val_loss: 0.4135 - val_auc: 0.8359 - val_f1_score: 0.6989\n","Epoch 527/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0275 - auc: 0.9917 - f1_score: 0.9027 - val_loss: 0.3904 - val_auc: 0.8410 - val_f1_score: 0.7013\n","Epoch 528/2000\n","123/123 [==============================] - 5s 39ms/step - loss: 0.0347 - auc: 0.9887 - f1_score: 0.8856 - val_loss: 0.3979 - val_auc: 0.8369 - val_f1_score: 0.6967\n","Epoch 529/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0341 - auc: 0.9896 - f1_score: 0.8903 - val_loss: 0.3682 - val_auc: 0.8404 - val_f1_score: 0.6832\n","Epoch 530/2000\n","123/123 [==============================] - 5s 38ms/step - loss: 0.0339 - auc: 0.9890 - f1_score: 0.8852 - val_loss: 0.3991 - val_auc: 0.8372 - val_f1_score: 0.6897\n","Epoch 00530: early stopping\n","WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Year': <tf.Tensor 'ExpandDims_56:0' shape=(None, 1) dtype=string>, 'N_of_SCI': <tf.Tensor 'ExpandDims_37:0' shape=(None, 1) dtype=float64>, 'N_of_Paper': <tf.Tensor 'ExpandDims_35:0' shape=(None, 1) dtype=float64>, 'N_Patent_App': <tf.Tensor 'ExpandDims_31:0' shape=(None, 1) dtype=float64>, 'N_Patent_Reg': <tf.Tensor 'ExpandDims_32:0' shape=(None, 1) dtype=float64>, 'N_of_Korean_Patent': <tf.Tensor 'ExpandDims_34:0' shape=(None, 1) dtype=float64>, 'N_of_Inter_Patent': <tf.Tensor 'ExpandDims_33:0' shape=(None, 1) dtype=float64>, 'N_of_Patent': <tf.Tensor 'ExpandDims_36:0' shape=(None, 1) dtype=float64>, 'Multi_Year': <tf.Tensor 'ExpandDims_30:0' shape=(None, 1) dtype=string>, 'RnD_Org': <tf.Tensor 'ExpandDims_41:0' shape=(None, 1) dtype=string>, 'Region': <tf.Tensor 'ExpandDims_39:0' shape=(None, 1) dtype=string>, 'STP_Code_11': <tf.Tensor 'ExpandDims_43:0' shape=(None, 1) dtype=string>, 'STP_Code_1_Weight': <tf.Tensor 'ExpandDims_44:0' shape=(None, 1) dtype=float64>, 'STP_Code_21': <tf.Tensor 'ExpandDims_45:0' shape=(None, 1) dtype=string>, 'STP_Code_2_Weight': <tf.Tensor 'ExpandDims_46:0' shape=(None, 1) dtype=float64>, 'Application_Area_1': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=string>, 'Application_Area_1_Weight': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float64>, 'Application_Area_2': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=string>, 'Application_Area_2_Weight': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float64>, 'Application_Area_3': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=string>, 'Application_Area_3_Weight': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float64>, 'Green_Tech': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=string>, 'SixT_2': <tf.Tensor 'ExpandDims_50:0' shape=(None, 1) dtype=string>, 'Econ_Social': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=string>, 'National_Strategy_2': <tf.Tensor 'ExpandDims_38:0' shape=(None, 1) dtype=string>, 'RnD_Stage': <tf.Tensor 'ExpandDims_42:0' shape=(None, 1) dtype=string>, 'Cowork_Cor': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=string>, 'Cowork_Uni': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=string>, 'Cowork_Inst': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=string>, 'Cowork_Abroad': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=string>, 'Log_RnD_Fund': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float64>, 'Log_Duration': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=float64>, 'Cowork_etc': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=string>, 'Sales': <tf.Tensor 'ExpandDims_47:0' shape=(None, 1) dtype=float64>, 'Income': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float64>, 'Asset': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float64>, 'Capital': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=float64>, 'Sales_Income_Ratio': <tf.Tensor 'ExpandDims_48:0' shape=(None, 1) dtype=float64>, 'Asset_Income_Ratio': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float64>, 'Sales_Operation_Ratio': <tf.Tensor 'ExpandDims_49:0' shape=(None, 1) dtype=float64>, 'Expense_Ratio': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float64>, 'Debt_Ratio': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float64>, 'IPO': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=string>, 'Comp_Type': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=string>, 'Listed_Market': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=string>, 'Administration': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=string>, 'External_Audit': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=string>, 'Survival': <tf.Tensor 'ExpandDims_51:0' shape=(None, 1) dtype=string>, 'Venture': <tf.Tensor 'ExpandDims_55:0' shape=(None, 1) dtype=string>, 'Innobiz': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=string>, 'Mainbiz': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=string>, 'Employees': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float64>, 'Closed': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=string>, 'Ten_Industry_1': <tf.Tensor 'ExpandDims_52:0' shape=(None, 1) dtype=string>, 'Ten_Industry_11': <tf.Tensor 'ExpandDims_53:0' shape=(None, 1) dtype=string>, 'Ten_Industry_111': <tf.Tensor 'ExpandDims_54:0' shape=(None, 1) dtype=string>, 'Researcher': <tf.Tensor 'ExpandDims_40:0' shape=(None, 1) dtype=string>}\n","Consider rewriting this model with the Functional API.\n","\n","\n","\n","-----------------------테스트 결과---------------------------\n","307/307 [==============================] - 3s 9ms/step - loss: 0.4503 - auc: 0.8221 - f1_score: 0.6854\n","   precision            recall               f1\n","(0.6207715619624867, 0.764937424303593, 0.6853551566668175, None)\n","\n","\n","\n","WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Year': <tf.Tensor 'Year:0' shape=(None, 1) dtype=string>, 'N_of_SCI': <tf.Tensor 'N_of_SCI:0' shape=(None, 1) dtype=float64>, 'N_of_Paper': <tf.Tensor 'N_of_Paper:0' shape=(None, 1) dtype=float64>, 'N_Patent_App': <tf.Tensor 'N_Patent_App:0' shape=(None, 1) dtype=float64>, 'N_Patent_Reg': <tf.Tensor 'N_Patent_Reg:0' shape=(None, 1) dtype=float64>, 'N_of_Korean_Patent': <tf.Tensor 'N_of_Korean_Patent:0' shape=(None, 1) dtype=float64>, 'N_of_Inter_Patent': <tf.Tensor 'N_of_Inter_Patent:0' shape=(None, 1) dtype=float64>, 'N_of_Patent': <tf.Tensor 'N_of_Patent:0' shape=(None, 1) dtype=float64>, 'Multi_Year': <tf.Tensor 'Multi_Year:0' shape=(None, 1) dtype=string>, 'RnD_Org': <tf.Tensor 'RnD_Org:0' shape=(None, 1) dtype=string>, 'Region': <tf.Tensor 'Region:0' shape=(None, 1) dtype=string>, 'STP_Code_11': <tf.Tensor 'STP_Code_11:0' shape=(None, 1) dtype=string>, 'STP_Code_1_Weight': <tf.Tensor 'STP_Code_1_Weight:0' shape=(None, 1) dtype=float64>, 'STP_Code_21': <tf.Tensor 'STP_Code_21:0' shape=(None, 1) dtype=string>, 'STP_Code_2_Weight': <tf.Tensor 'STP_Code_2_Weight:0' shape=(None, 1) dtype=float64>, 'Application_Area_1': <tf.Tensor 'Application_Area_1:0' shape=(None, 1) dtype=string>, 'Application_Area_1_Weight': <tf.Tensor 'Application_Area_1_Weight:0' shape=(None, 1) dtype=float64>, 'Application_Area_2': <tf.Tensor 'Application_Area_2:0' shape=(None, 1) dtype=string>, 'Application_Area_2_Weight': <tf.Tensor 'Application_Area_2_Weight:0' shape=(None, 1) dtype=float64>, 'Application_Area_3': <tf.Tensor 'Application_Area_3:0' shape=(None, 1) dtype=string>, 'Application_Area_3_Weight': <tf.Tensor 'Application_Area_3_Weight:0' shape=(None, 1) dtype=float64>, 'Green_Tech': <tf.Tensor 'Green_Tech:0' shape=(None, 1) dtype=string>, 'SixT_2': <tf.Tensor 'SixT_2:0' shape=(None, 1) dtype=string>, 'Econ_Social': <tf.Tensor 'Econ_Social:0' shape=(None, 1) dtype=string>, 'National_Strategy_2': <tf.Tensor 'National_Strategy_2:0' shape=(None, 1) dtype=string>, 'RnD_Stage': <tf.Tensor 'RnD_Stage:0' shape=(None, 1) dtype=string>, 'Cowork_Cor': <tf.Tensor 'Cowork_Cor:0' shape=(None, 1) dtype=string>, 'Cowork_Uni': <tf.Tensor 'Cowork_Uni:0' shape=(None, 1) dtype=string>, 'Cowork_Inst': <tf.Tensor 'Cowork_Inst:0' shape=(None, 1) dtype=string>, 'Cowork_Abroad': <tf.Tensor 'Cowork_Abroad:0' shape=(None, 1) dtype=string>, 'Log_RnD_Fund': <tf.Tensor 'Log_RnD_Fund:0' shape=(None, 1) dtype=float64>, 'Log_Duration': <tf.Tensor 'Log_Duration:0' shape=(None, 1) dtype=float64>, 'Cowork_etc': <tf.Tensor 'Cowork_etc:0' shape=(None, 1) dtype=string>, 'Sales': <tf.Tensor 'Sales:0' shape=(None, 1) dtype=float64>, 'Income': <tf.Tensor 'Income:0' shape=(None, 1) dtype=float64>, 'Asset': <tf.Tensor 'Asset:0' shape=(None, 1) dtype=float64>, 'Capital': <tf.Tensor 'Capital:0' shape=(None, 1) dtype=float64>, 'Sales_Income_Ratio': <tf.Tensor 'Sales_Income_Ratio:0' shape=(None, 1) dtype=float64>, 'Asset_Income_Ratio': <tf.Tensor 'Asset_Income_Ratio:0' shape=(None, 1) dtype=float64>, 'Sales_Operation_Ratio': <tf.Tensor 'Sales_Operation_Ratio:0' shape=(None, 1) dtype=float64>, 'Expense_Ratio': <tf.Tensor 'Expense_Ratio:0' shape=(None, 1) dtype=float64>, 'Debt_Ratio': <tf.Tensor 'Debt_Ratio:0' shape=(None, 1) dtype=float64>, 'IPO': <tf.Tensor 'IPO:0' shape=(None, 1) dtype=string>, 'Comp_Type': <tf.Tensor 'Comp_Type:0' shape=(None, 1) dtype=string>, 'Listed_Market': <tf.Tensor 'Listed_Market:0' shape=(None, 1) dtype=string>, 'Administration': <tf.Tensor 'Administration:0' shape=(None, 1) dtype=string>, 'External_Audit': <tf.Tensor 'External_Audit:0' shape=(None, 1) dtype=string>, 'Survival': <tf.Tensor 'Survival:0' shape=(None, 1) dtype=string>, 'Venture': <tf.Tensor 'Venture:0' shape=(None, 1) dtype=string>, 'Innobiz': <tf.Tensor 'Innobiz:0' shape=(None, 1) dtype=string>, 'Mainbiz': <tf.Tensor 'Mainbiz:0' shape=(None, 1) dtype=string>, 'Employees': <tf.Tensor 'Employees:0' shape=(None, 1) dtype=float64>, 'Closed': <tf.Tensor 'Closed:0' shape=(None, 1) dtype=string>, 'Ten_Industry_1': <tf.Tensor 'Ten_Industry_1:0' shape=(None, 1) dtype=string>, 'Ten_Industry_11': <tf.Tensor 'Ten_Industry_11:0' shape=(None, 1) dtype=string>, 'Ten_Industry_111': <tf.Tensor 'Ten_Industry_111:0' shape=(None, 1) dtype=string>, 'Researcher': <tf.Tensor 'Researcher:0' shape=(None, 1) dtype=string>}\n","Consider rewriting this model with the Functional API.\n","WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Year': <tf.Tensor 'inputs_56:0' shape=(None, 1) dtype=string>, 'N_of_SCI': <tf.Tensor 'inputs_37:0' shape=(None, 1) dtype=float64>, 'N_of_Paper': <tf.Tensor 'inputs_35:0' shape=(None, 1) dtype=float64>, 'N_Patent_App': <tf.Tensor 'inputs_31:0' shape=(None, 1) dtype=float64>, 'N_Patent_Reg': <tf.Tensor 'inputs_32:0' shape=(None, 1) dtype=float64>, 'N_of_Korean_Patent': <tf.Tensor 'inputs_34:0' shape=(None, 1) dtype=float64>, 'N_of_Inter_Patent': <tf.Tensor 'inputs_33:0' shape=(None, 1) dtype=float64>, 'N_of_Patent': <tf.Tensor 'inputs_36:0' shape=(None, 1) dtype=float64>, 'Multi_Year': <tf.Tensor 'inputs_30:0' shape=(None, 1) dtype=string>, 'RnD_Org': <tf.Tensor 'inputs_41:0' shape=(None, 1) dtype=string>, 'Region': <tf.Tensor 'inputs_39:0' shape=(None, 1) dtype=string>, 'STP_Code_11': <tf.Tensor 'inputs_43:0' shape=(None, 1) dtype=string>, 'STP_Code_1_Weight': <tf.Tensor 'inputs_44:0' shape=(None, 1) dtype=float64>, 'STP_Code_21': <tf.Tensor 'inputs_45:0' shape=(None, 1) dtype=string>, 'STP_Code_2_Weight': <tf.Tensor 'inputs_46:0' shape=(None, 1) dtype=float64>, 'Application_Area_1': <tf.Tensor 'inputs_1:0' shape=(None, 1) dtype=string>, 'Application_Area_1_Weight': <tf.Tensor 'inputs_2:0' shape=(None, 1) dtype=float64>, 'Application_Area_2': <tf.Tensor 'inputs_3:0' shape=(None, 1) dtype=string>, 'Application_Area_2_Weight': <tf.Tensor 'inputs_4:0' shape=(None, 1) dtype=float64>, 'Application_Area_3': <tf.Tensor 'inputs_5:0' shape=(None, 1) dtype=string>, 'Application_Area_3_Weight': <tf.Tensor 'inputs_6:0' shape=(None, 1) dtype=float64>, 'Green_Tech': <tf.Tensor 'inputs_22:0' shape=(None, 1) dtype=string>, 'SixT_2': <tf.Tensor 'inputs_50:0' shape=(None, 1) dtype=string>, 'Econ_Social': <tf.Tensor 'inputs_18:0' shape=(None, 1) dtype=string>, 'National_Strategy_2': <tf.Tensor 'inputs_38:0' shape=(None, 1) dtype=string>, 'RnD_Stage': <tf.Tensor 'inputs_42:0' shape=(None, 1) dtype=string>, 'Cowork_Cor': <tf.Tensor 'inputs_13:0' shape=(None, 1) dtype=string>, 'Cowork_Uni': <tf.Tensor 'inputs_15:0' shape=(None, 1) dtype=string>, 'Cowork_Inst': <tf.Tensor 'inputs_14:0' shape=(None, 1) dtype=string>, 'Cowork_Abroad': <tf.Tensor 'inputs_12:0' shape=(None, 1) dtype=string>, 'Log_RnD_Fund': <tf.Tensor 'inputs_28:0' shape=(None, 1) dtype=float64>, 'Log_Duration': <tf.Tensor 'inputs_27:0' shape=(None, 1) dtype=float64>, 'Cowork_etc': <tf.Tensor 'inputs_16:0' shape=(None, 1) dtype=string>, 'Sales': <tf.Tensor 'inputs_47:0' shape=(None, 1) dtype=float64>, 'Income': <tf.Tensor 'inputs_24:0' shape=(None, 1) dtype=float64>, 'Asset': <tf.Tensor 'inputs_7:0' shape=(None, 1) dtype=float64>, 'Capital': <tf.Tensor 'inputs_9:0' shape=(None, 1) dtype=float64>, 'Sales_Income_Ratio': <tf.Tensor 'inputs_48:0' shape=(None, 1) dtype=float64>, 'Asset_Income_Ratio': <tf.Tensor 'inputs_8:0' shape=(None, 1) dtype=float64>, 'Sales_Operation_Ratio': <tf.Tensor 'inputs_49:0' shape=(None, 1) dtype=float64>, 'Expense_Ratio': <tf.Tensor 'inputs_20:0' shape=(None, 1) dtype=float64>, 'Debt_Ratio': <tf.Tensor 'inputs_17:0' shape=(None, 1) dtype=float64>, 'IPO': <tf.Tensor 'inputs_23:0' shape=(None, 1) dtype=string>, 'Comp_Type': <tf.Tensor 'inputs_11:0' shape=(None, 1) dtype=string>, 'Listed_Market': <tf.Tensor 'inputs_26:0' shape=(None, 1) dtype=string>, 'Administration': <tf.Tensor 'inputs:0' shape=(None, 1) dtype=string>, 'External_Audit': <tf.Tensor 'inputs_21:0' shape=(None, 1) dtype=string>, 'Survival': <tf.Tensor 'inputs_51:0' shape=(None, 1) dtype=string>, 'Venture': <tf.Tensor 'inputs_55:0' shape=(None, 1) dtype=string>, 'Innobiz': <tf.Tensor 'inputs_25:0' shape=(None, 1) dtype=string>, 'Mainbiz': <tf.Tensor 'inputs_29:0' shape=(None, 1) dtype=string>, 'Employees': <tf.Tensor 'inputs_19:0' shape=(None, 1) dtype=float64>, 'Closed': <tf.Tensor 'inputs_10:0' shape=(None, 1) dtype=string>, 'Ten_Industry_1': <tf.Tensor 'inputs_52:0' shape=(None, 1) dtype=string>, 'Ten_Industry_11': <tf.Tensor 'inputs_53:0' shape=(None, 1) dtype=string>, 'Ten_Industry_111': <tf.Tensor 'inputs_54:0' shape=(None, 1) dtype=string>, 'Researcher': <tf.Tensor 'inputs_40:0' shape=(None, 1) dtype=string>}\n","Consider rewriting this model with the Functional API.\n","WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Year': <tf.Tensor 'inputs_56:0' shape=(None, 1) dtype=string>, 'N_of_SCI': <tf.Tensor 'inputs_37:0' shape=(None, 1) dtype=float64>, 'N_of_Paper': <tf.Tensor 'inputs_35:0' shape=(None, 1) dtype=float64>, 'N_Patent_App': <tf.Tensor 'inputs_31:0' shape=(None, 1) dtype=float64>, 'N_Patent_Reg': <tf.Tensor 'inputs_32:0' shape=(None, 1) dtype=float64>, 'N_of_Korean_Patent': <tf.Tensor 'inputs_34:0' shape=(None, 1) dtype=float64>, 'N_of_Inter_Patent': <tf.Tensor 'inputs_33:0' shape=(None, 1) dtype=float64>, 'N_of_Patent': <tf.Tensor 'inputs_36:0' shape=(None, 1) dtype=float64>, 'Multi_Year': <tf.Tensor 'inputs_30:0' shape=(None, 1) dtype=string>, 'RnD_Org': <tf.Tensor 'inputs_41:0' shape=(None, 1) dtype=string>, 'Region': <tf.Tensor 'inputs_39:0' shape=(None, 1) dtype=string>, 'STP_Code_11': <tf.Tensor 'inputs_43:0' shape=(None, 1) dtype=string>, 'STP_Code_1_Weight': <tf.Tensor 'inputs_44:0' shape=(None, 1) dtype=float64>, 'STP_Code_21': <tf.Tensor 'inputs_45:0' shape=(None, 1) dtype=string>, 'STP_Code_2_Weight': <tf.Tensor 'inputs_46:0' shape=(None, 1) dtype=float64>, 'Application_Area_1': <tf.Tensor 'inputs_1:0' shape=(None, 1) dtype=string>, 'Application_Area_1_Weight': <tf.Tensor 'inputs_2:0' shape=(None, 1) dtype=float64>, 'Application_Area_2': <tf.Tensor 'inputs_3:0' shape=(None, 1) dtype=string>, 'Application_Area_2_Weight': <tf.Tensor 'inputs_4:0' shape=(None, 1) dtype=float64>, 'Application_Area_3': <tf.Tensor 'inputs_5:0' shape=(None, 1) dtype=string>, 'Application_Area_3_Weight': <tf.Tensor 'inputs_6:0' shape=(None, 1) dtype=float64>, 'Green_Tech': <tf.Tensor 'inputs_22:0' shape=(None, 1) dtype=string>, 'SixT_2': <tf.Tensor 'inputs_50:0' shape=(None, 1) dtype=string>, 'Econ_Social': <tf.Tensor 'inputs_18:0' shape=(None, 1) dtype=string>, 'National_Strategy_2': <tf.Tensor 'inputs_38:0' shape=(None, 1) dtype=string>, 'RnD_Stage': <tf.Tensor 'inputs_42:0' shape=(None, 1) dtype=string>, 'Cowork_Cor': <tf.Tensor 'inputs_13:0' shape=(None, 1) dtype=string>, 'Cowork_Uni': <tf.Tensor 'inputs_15:0' shape=(None, 1) dtype=string>, 'Cowork_Inst': <tf.Tensor 'inputs_14:0' shape=(None, 1) dtype=string>, 'Cowork_Abroad': <tf.Tensor 'inputs_12:0' shape=(None, 1) dtype=string>, 'Log_RnD_Fund': <tf.Tensor 'inputs_28:0' shape=(None, 1) dtype=float64>, 'Log_Duration': <tf.Tensor 'inputs_27:0' shape=(None, 1) dtype=float64>, 'Cowork_etc': <tf.Tensor 'inputs_16:0' shape=(None, 1) dtype=string>, 'Sales': <tf.Tensor 'inputs_47:0' shape=(None, 1) dtype=float64>, 'Income': <tf.Tensor 'inputs_24:0' shape=(None, 1) dtype=float64>, 'Asset': <tf.Tensor 'inputs_7:0' shape=(None, 1) dtype=float64>, 'Capital': <tf.Tensor 'inputs_9:0' shape=(None, 1) dtype=float64>, 'Sales_Income_Ratio': <tf.Tensor 'inputs_48:0' shape=(None, 1) dtype=float64>, 'Asset_Income_Ratio': <tf.Tensor 'inputs_8:0' shape=(None, 1) dtype=float64>, 'Sales_Operation_Ratio': <tf.Tensor 'inputs_49:0' shape=(None, 1) dtype=float64>, 'Expense_Ratio': <tf.Tensor 'inputs_20:0' shape=(None, 1) dtype=float64>, 'Debt_Ratio': <tf.Tensor 'inputs_17:0' shape=(None, 1) dtype=float64>, 'IPO': <tf.Tensor 'inputs_23:0' shape=(None, 1) dtype=string>, 'Comp_Type': <tf.Tensor 'inputs_11:0' shape=(None, 1) dtype=string>, 'Listed_Market': <tf.Tensor 'inputs_26:0' shape=(None, 1) dtype=string>, 'Administration': <tf.Tensor 'inputs:0' shape=(None, 1) dtype=string>, 'External_Audit': <tf.Tensor 'inputs_21:0' shape=(None, 1) dtype=string>, 'Survival': <tf.Tensor 'inputs_51:0' shape=(None, 1) dtype=string>, 'Venture': <tf.Tensor 'inputs_55:0' shape=(None, 1) dtype=string>, 'Innobiz': <tf.Tensor 'inputs_25:0' shape=(None, 1) dtype=string>, 'Mainbiz': <tf.Tensor 'inputs_29:0' shape=(None, 1) dtype=string>, 'Employees': <tf.Tensor 'inputs_19:0' shape=(None, 1) dtype=float64>, 'Closed': <tf.Tensor 'inputs_10:0' shape=(None, 1) dtype=string>, 'Ten_Industry_1': <tf.Tensor 'inputs_52:0' shape=(None, 1) dtype=string>, 'Ten_Industry_11': <tf.Tensor 'inputs_53:0' shape=(None, 1) dtype=string>, 'Ten_Industry_111': <tf.Tensor 'inputs_54:0' shape=(None, 1) dtype=string>, 'Researcher': <tf.Tensor 'inputs_40:0' shape=(None, 1) dtype=string>}\n","Consider rewriting this model with the Functional API.\n","WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Year': <tf.Tensor 'Year:0' shape=(None, 1) dtype=string>, 'N_of_SCI': <tf.Tensor 'N_of_SCI:0' shape=(None, 1) dtype=float64>, 'N_of_Paper': <tf.Tensor 'N_of_Paper:0' shape=(None, 1) dtype=float64>, 'N_Patent_App': <tf.Tensor 'N_Patent_App:0' shape=(None, 1) dtype=float64>, 'N_Patent_Reg': <tf.Tensor 'N_Patent_Reg:0' shape=(None, 1) dtype=float64>, 'N_of_Korean_Patent': <tf.Tensor 'N_of_Korean_Patent:0' shape=(None, 1) dtype=float64>, 'N_of_Inter_Patent': <tf.Tensor 'N_of_Inter_Patent:0' shape=(None, 1) dtype=float64>, 'N_of_Patent': <tf.Tensor 'N_of_Patent:0' shape=(None, 1) dtype=float64>, 'Multi_Year': <tf.Tensor 'Multi_Year:0' shape=(None, 1) dtype=string>, 'RnD_Org': <tf.Tensor 'RnD_Org:0' shape=(None, 1) dtype=string>, 'Region': <tf.Tensor 'Region:0' shape=(None, 1) dtype=string>, 'STP_Code_11': <tf.Tensor 'STP_Code_11:0' shape=(None, 1) dtype=string>, 'STP_Code_1_Weight': <tf.Tensor 'STP_Code_1_Weight:0' shape=(None, 1) dtype=float64>, 'STP_Code_21': <tf.Tensor 'STP_Code_21:0' shape=(None, 1) dtype=string>, 'STP_Code_2_Weight': <tf.Tensor 'STP_Code_2_Weight:0' shape=(None, 1) dtype=float64>, 'Application_Area_1': <tf.Tensor 'Application_Area_1:0' shape=(None, 1) dtype=string>, 'Application_Area_1_Weight': <tf.Tensor 'Application_Area_1_Weight:0' shape=(None, 1) dtype=float64>, 'Application_Area_2': <tf.Tensor 'Application_Area_2:0' shape=(None, 1) dtype=string>, 'Application_Area_2_Weight': <tf.Tensor 'Application_Area_2_Weight:0' shape=(None, 1) dtype=float64>, 'Application_Area_3': <tf.Tensor 'Application_Area_3:0' shape=(None, 1) dtype=string>, 'Application_Area_3_Weight': <tf.Tensor 'Application_Area_3_Weight:0' shape=(None, 1) dtype=float64>, 'Green_Tech': <tf.Tensor 'Green_Tech:0' shape=(None, 1) dtype=string>, 'SixT_2': <tf.Tensor 'SixT_2:0' shape=(None, 1) dtype=string>, 'Econ_Social': <tf.Tensor 'Econ_Social:0' shape=(None, 1) dtype=string>, 'National_Strategy_2': <tf.Tensor 'National_Strategy_2:0' shape=(None, 1) dtype=string>, 'RnD_Stage': <tf.Tensor 'RnD_Stage:0' shape=(None, 1) dtype=string>, 'Cowork_Cor': <tf.Tensor 'Cowork_Cor:0' shape=(None, 1) dtype=string>, 'Cowork_Uni': <tf.Tensor 'Cowork_Uni:0' shape=(None, 1) dtype=string>, 'Cowork_Inst': <tf.Tensor 'Cowork_Inst:0' shape=(None, 1) dtype=string>, 'Cowork_Abroad': <tf.Tensor 'Cowork_Abroad:0' shape=(None, 1) dtype=string>, 'Log_RnD_Fund': <tf.Tensor 'Log_RnD_Fund:0' shape=(None, 1) dtype=float64>, 'Log_Duration': <tf.Tensor 'Log_Duration:0' shape=(None, 1) dtype=float64>, 'Cowork_etc': <tf.Tensor 'Cowork_etc:0' shape=(None, 1) dtype=string>, 'Sales': <tf.Tensor 'Sales:0' shape=(None, 1) dtype=float64>, 'Income': <tf.Tensor 'Income:0' shape=(None, 1) dtype=float64>, 'Asset': <tf.Tensor 'Asset:0' shape=(None, 1) dtype=float64>, 'Capital': <tf.Tensor 'Capital:0' shape=(None, 1) dtype=float64>, 'Sales_Income_Ratio': <tf.Tensor 'Sales_Income_Ratio:0' shape=(None, 1) dtype=float64>, 'Asset_Income_Ratio': <tf.Tensor 'Asset_Income_Ratio:0' shape=(None, 1) dtype=float64>, 'Sales_Operation_Ratio': <tf.Tensor 'Sales_Operation_Ratio:0' shape=(None, 1) dtype=float64>, 'Expense_Ratio': <tf.Tensor 'Expense_Ratio:0' shape=(None, 1) dtype=float64>, 'Debt_Ratio': <tf.Tensor 'Debt_Ratio:0' shape=(None, 1) dtype=float64>, 'IPO': <tf.Tensor 'IPO:0' shape=(None, 1) dtype=string>, 'Comp_Type': <tf.Tensor 'Comp_Type:0' shape=(None, 1) dtype=string>, 'Listed_Market': <tf.Tensor 'Listed_Market:0' shape=(None, 1) dtype=string>, 'Administration': <tf.Tensor 'Administration:0' shape=(None, 1) dtype=string>, 'External_Audit': <tf.Tensor 'External_Audit:0' shape=(None, 1) dtype=string>, 'Survival': <tf.Tensor 'Survival:0' shape=(None, 1) dtype=string>, 'Venture': <tf.Tensor 'Venture:0' shape=(None, 1) dtype=string>, 'Innobiz': <tf.Tensor 'Innobiz:0' shape=(None, 1) dtype=string>, 'Mainbiz': <tf.Tensor 'Mainbiz:0' shape=(None, 1) dtype=string>, 'Employees': <tf.Tensor 'Employees:0' shape=(None, 1) dtype=float64>, 'Closed': <tf.Tensor 'Closed:0' shape=(None, 1) dtype=string>, 'Ten_Industry_1': <tf.Tensor 'Ten_Industry_1:0' shape=(None, 1) dtype=string>, 'Ten_Industry_11': <tf.Tensor 'Ten_Industry_11:0' shape=(None, 1) dtype=string>, 'Ten_Industry_111': <tf.Tensor 'Ten_Industry_111:0' shape=(None, 1) dtype=string>, 'Researcher': <tf.Tensor 'Researcher:0' shape=(None, 1) dtype=string>}\n","Consider rewriting this model with the Functional API.\n","WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Year': <tf.Tensor 'Year:0' shape=(None, 1) dtype=string>, 'N_of_SCI': <tf.Tensor 'N_of_SCI:0' shape=(None, 1) dtype=float64>, 'N_of_Paper': <tf.Tensor 'N_of_Paper:0' shape=(None, 1) dtype=float64>, 'N_Patent_App': <tf.Tensor 'N_Patent_App:0' shape=(None, 1) dtype=float64>, 'N_Patent_Reg': <tf.Tensor 'N_Patent_Reg:0' shape=(None, 1) dtype=float64>, 'N_of_Korean_Patent': <tf.Tensor 'N_of_Korean_Patent:0' shape=(None, 1) dtype=float64>, 'N_of_Inter_Patent': <tf.Tensor 'N_of_Inter_Patent:0' shape=(None, 1) dtype=float64>, 'N_of_Patent': <tf.Tensor 'N_of_Patent:0' shape=(None, 1) dtype=float64>, 'Multi_Year': <tf.Tensor 'Multi_Year:0' shape=(None, 1) dtype=string>, 'RnD_Org': <tf.Tensor 'RnD_Org:0' shape=(None, 1) dtype=string>, 'Region': <tf.Tensor 'Region:0' shape=(None, 1) dtype=string>, 'STP_Code_11': <tf.Tensor 'STP_Code_11:0' shape=(None, 1) dtype=string>, 'STP_Code_1_Weight': <tf.Tensor 'STP_Code_1_Weight:0' shape=(None, 1) dtype=float64>, 'STP_Code_21': <tf.Tensor 'STP_Code_21:0' shape=(None, 1) dtype=string>, 'STP_Code_2_Weight': <tf.Tensor 'STP_Code_2_Weight:0' shape=(None, 1) dtype=float64>, 'Application_Area_1': <tf.Tensor 'Application_Area_1:0' shape=(None, 1) dtype=string>, 'Application_Area_1_Weight': <tf.Tensor 'Application_Area_1_Weight:0' shape=(None, 1) dtype=float64>, 'Application_Area_2': <tf.Tensor 'Application_Area_2:0' shape=(None, 1) dtype=string>, 'Application_Area_2_Weight': <tf.Tensor 'Application_Area_2_Weight:0' shape=(None, 1) dtype=float64>, 'Application_Area_3': <tf.Tensor 'Application_Area_3:0' shape=(None, 1) dtype=string>, 'Application_Area_3_Weight': <tf.Tensor 'Application_Area_3_Weight:0' shape=(None, 1) dtype=float64>, 'Green_Tech': <tf.Tensor 'Green_Tech:0' shape=(None, 1) dtype=string>, 'SixT_2': <tf.Tensor 'SixT_2:0' shape=(None, 1) dtype=string>, 'Econ_Social': <tf.Tensor 'Econ_Social:0' shape=(None, 1) dtype=string>, 'National_Strategy_2': <tf.Tensor 'National_Strategy_2:0' shape=(None, 1) dtype=string>, 'RnD_Stage': <tf.Tensor 'RnD_Stage:0' shape=(None, 1) dtype=string>, 'Cowork_Cor': <tf.Tensor 'Cowork_Cor:0' shape=(None, 1) dtype=string>, 'Cowork_Uni': <tf.Tensor 'Cowork_Uni:0' shape=(None, 1) dtype=string>, 'Cowork_Inst': <tf.Tensor 'Cowork_Inst:0' shape=(None, 1) dtype=string>, 'Cowork_Abroad': <tf.Tensor 'Cowork_Abroad:0' shape=(None, 1) dtype=string>, 'Log_RnD_Fund': <tf.Tensor 'Log_RnD_Fund:0' shape=(None, 1) dtype=float64>, 'Log_Duration': <tf.Tensor 'Log_Duration:0' shape=(None, 1) dtype=float64>, 'Cowork_etc': <tf.Tensor 'Cowork_etc:0' shape=(None, 1) dtype=string>, 'Sales': <tf.Tensor 'Sales:0' shape=(None, 1) dtype=float64>, 'Income': <tf.Tensor 'Income:0' shape=(None, 1) dtype=float64>, 'Asset': <tf.Tensor 'Asset:0' shape=(None, 1) dtype=float64>, 'Capital': <tf.Tensor 'Capital:0' shape=(None, 1) dtype=float64>, 'Sales_Income_Ratio': <tf.Tensor 'Sales_Income_Ratio:0' shape=(None, 1) dtype=float64>, 'Asset_Income_Ratio': <tf.Tensor 'Asset_Income_Ratio:0' shape=(None, 1) dtype=float64>, 'Sales_Operation_Ratio': <tf.Tensor 'Sales_Operation_Ratio:0' shape=(None, 1) dtype=float64>, 'Expense_Ratio': <tf.Tensor 'Expense_Ratio:0' shape=(None, 1) dtype=float64>, 'Debt_Ratio': <tf.Tensor 'Debt_Ratio:0' shape=(None, 1) dtype=float64>, 'IPO': <tf.Tensor 'IPO:0' shape=(None, 1) dtype=string>, 'Comp_Type': <tf.Tensor 'Comp_Type:0' shape=(None, 1) dtype=string>, 'Listed_Market': <tf.Tensor 'Listed_Market:0' shape=(None, 1) dtype=string>, 'Administration': <tf.Tensor 'Administration:0' shape=(None, 1) dtype=string>, 'External_Audit': <tf.Tensor 'External_Audit:0' shape=(None, 1) dtype=string>, 'Survival': <tf.Tensor 'Survival:0' shape=(None, 1) dtype=string>, 'Venture': <tf.Tensor 'Venture:0' shape=(None, 1) dtype=string>, 'Innobiz': <tf.Tensor 'Innobiz:0' shape=(None, 1) dtype=string>, 'Mainbiz': <tf.Tensor 'Mainbiz:0' shape=(None, 1) dtype=string>, 'Employees': <tf.Tensor 'Employees:0' shape=(None, 1) dtype=float64>, 'Closed': <tf.Tensor 'Closed:0' shape=(None, 1) dtype=string>, 'Ten_Industry_1': <tf.Tensor 'Ten_Industry_1:0' shape=(None, 1) dtype=string>, 'Ten_Industry_11': <tf.Tensor 'Ten_Industry_11:0' shape=(None, 1) dtype=string>, 'Ten_Industry_111': <tf.Tensor 'Ten_Industry_111:0' shape=(None, 1) dtype=string>, 'Researcher': <tf.Tensor 'Researcher:0' shape=(None, 1) dtype=string>}\n","Consider rewriting this model with the Functional API.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Function `_wrapped_model` contains input name(s) Administration, Application_Area_1, Application_Area_1_Weight, Application_Area_2, Application_Area_2_Weight, Application_Area_3, Application_Area_3_Weight, Asset, Asset_Income_Ratio, Capital, Closed, Comp_Type, Cowork_Abroad, Cowork_Cor, Cowork_Inst, Cowork_Uni, Cowork_etc, Debt_Ratio, Econ_Social, Employees, Expense_Ratio, External_Audit, Green_Tech, IPO, Income, Innobiz, Listed_Market, Log_Duration, Log_RnD_Fund, Mainbiz, Multi_Year, N_Patent_App, N_Patent_Reg, N_of_Inter_Patent, N_of_Korean_Patent, N_of_Paper, N_of_Patent, N_of_SCI, National_Strategy_2, Region, Researcher, RnD_Org, RnD_Stage, STP_Code_11, STP_Code_1_Weight, STP_Code_21, STP_Code_2_Weight, Sales, Sales_Income_Ratio, Sales_Operation_Ratio, SixT_2, Survival, Ten_Industry_1, Ten_Industry_11, Ten_Industry_111, Venture, Year with unsupported characters which will be renamed to administration, application_area_1, application_area_1_weight, application_area_2, application_area_2_weight, application_area_3, application_area_3_weight, asset, asset_income_ratio, capital, closed, comp_type, cowork_abroad, cowork_cor, cowork_inst, cowork_uni, cowork_etc, debt_ratio, econ_social, employees, expense_ratio, external_audit, green_tech, ipo, income, innobiz, listed_market, log_duration, log_rnd_fund, mainbiz, multi_year, n_patent_app, n_patent_reg, n_of_inter_patent, n_of_korean_patent, n_of_paper, n_of_patent, n_of_sci, national_strategy_2, region, researcher, rnd_org, rnd_stage, stp_code_11, stp_code_1_weight, stp_code_21, stp_code_2_weight, sales, sales_income_ratio, sales_operation_ratio, sixt_2, survival, ten_industry_1, ten_industry_11, ten_industry_111, venture, year in the SavedModel.\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Year': <tf.Tensor 'inputs/Year:0' shape=(None, 1) dtype=string>, 'N_of_SCI': <tf.Tensor 'inputs/N_of_SCI:0' shape=(None, 1) dtype=float64>, 'N_of_Paper': <tf.Tensor 'inputs/N_of_Paper:0' shape=(None, 1) dtype=float64>, 'N_Patent_App': <tf.Tensor 'inputs/N_Patent_App:0' shape=(None, 1) dtype=float64>, 'N_Patent_Reg': <tf.Tensor 'inputs/N_Patent_Reg:0' shape=(None, 1) dtype=float64>, 'N_of_Korean_Patent': <tf.Tensor 'inputs/N_of_Korean_Patent:0' shape=(None, 1) dtype=float64>, 'N_of_Inter_Patent': <tf.Tensor 'inputs/N_of_Inter_Patent:0' shape=(None, 1) dtype=float64>, 'N_of_Patent': <tf.Tensor 'inputs/N_of_Patent:0' shape=(None, 1) dtype=float64>, 'Multi_Year': <tf.Tensor 'inputs/Multi_Year:0' shape=(None, 1) dtype=string>, 'RnD_Org': <tf.Tensor 'inputs/RnD_Org:0' shape=(None, 1) dtype=string>, 'Region': <tf.Tensor 'inputs/Region:0' shape=(None, 1) dtype=string>, 'STP_Code_11': <tf.Tensor 'inputs/STP_Code_11:0' shape=(None, 1) dtype=string>, 'STP_Code_1_Weight': <tf.Tensor 'inputs/STP_Code_1_Weight:0' shape=(None, 1) dtype=float64>, 'STP_Code_21': <tf.Tensor 'inputs/STP_Code_21:0' shape=(None, 1) dtype=string>, 'STP_Code_2_Weight': <tf.Tensor 'inputs/STP_Code_2_Weight:0' shape=(None, 1) dtype=float64>, 'Application_Area_1': <tf.Tensor 'inputs/Application_Area_1:0' shape=(None, 1) dtype=string>, 'Application_Area_1_Weight': <tf.Tensor 'inputs/Application_Area_1_Weight:0' shape=(None, 1) dtype=float64>, 'Application_Area_2': <tf.Tensor 'inputs/Application_Area_2:0' shape=(None, 1) dtype=string>, 'Application_Area_2_Weight': <tf.Tensor 'inputs/Application_Area_2_Weight:0' shape=(None, 1) dtype=float64>, 'Application_Area_3': <tf.Tensor 'inputs/Application_Area_3:0' shape=(None, 1) dtype=string>, 'Application_Area_3_Weight': <tf.Tensor 'inputs/Application_Area_3_Weight:0' shape=(None, 1) dtype=float64>, 'Green_Tech': <tf.Tensor 'inputs/Green_Tech:0' shape=(None, 1) dtype=string>, 'SixT_2': <tf.Tensor 'inputs/SixT_2:0' shape=(None, 1) dtype=string>, 'Econ_Social': <tf.Tensor 'inputs/Econ_Social:0' shape=(None, 1) dtype=string>, 'National_Strategy_2': <tf.Tensor 'inputs/National_Strategy_2:0' shape=(None, 1) dtype=string>, 'RnD_Stage': <tf.Tensor 'inputs/RnD_Stage:0' shape=(None, 1) dtype=string>, 'Cowork_Cor': <tf.Tensor 'inputs/Cowork_Cor:0' shape=(None, 1) dtype=string>, 'Cowork_Uni': <tf.Tensor 'inputs/Cowork_Uni:0' shape=(None, 1) dtype=string>, 'Cowork_Inst': <tf.Tensor 'inputs/Cowork_Inst:0' shape=(None, 1) dtype=string>, 'Cowork_Abroad': <tf.Tensor 'inputs/Cowork_Abroad:0' shape=(None, 1) dtype=string>, 'Log_RnD_Fund': <tf.Tensor 'inputs/Log_RnD_Fund:0' shape=(None, 1) dtype=float64>, 'Log_Duration': <tf.Tensor 'inputs/Log_Duration:0' shape=(None, 1) dtype=float64>, 'Cowork_etc': <tf.Tensor 'inputs/Cowork_etc:0' shape=(None, 1) dtype=string>, 'Sales': <tf.Tensor 'inputs/Sales:0' shape=(None, 1) dtype=float64>, 'Income': <tf.Tensor 'inputs/Income:0' shape=(None, 1) dtype=float64>, 'Asset': <tf.Tensor 'inputs/Asset:0' shape=(None, 1) dtype=float64>, 'Capital': <tf.Tensor 'inputs/Capital:0' shape=(None, 1) dtype=float64>, 'Sales_Income_Ratio': <tf.Tensor 'inputs/Sales_Income_Ratio:0' shape=(None, 1) dtype=float64>, 'Asset_Income_Ratio': <tf.Tensor 'inputs/Asset_Income_Ratio:0' shape=(None, 1) dtype=float64>, 'Sales_Operation_Ratio': <tf.Tensor 'inputs/Sales_Operation_Ratio:0' shape=(None, 1) dtype=float64>, 'Expense_Ratio': <tf.Tensor 'inputs/Expense_Ratio:0' shape=(None, 1) dtype=float64>, 'Debt_Ratio': <tf.Tensor 'inputs/Debt_Ratio:0' shape=(None, 1) dtype=float64>, 'IPO': <tf.Tensor 'inputs/IPO:0' shape=(None, 1) dtype=string>, 'Comp_Type': <tf.Tensor 'inputs/Comp_Type:0' shape=(None, 1) dtype=string>, 'Listed_Market': <tf.Tensor 'inputs/Listed_Market:0' shape=(None, 1) dtype=string>, 'Administration': <tf.Tensor 'inputs/Administration:0' shape=(None, 1) dtype=string>, 'External_Audit': <tf.Tensor 'inputs/External_Audit:0' shape=(None, 1) dtype=string>, 'Survival': <tf.Tensor 'inputs/Survival:0' shape=(None, 1) dtype=string>, 'Venture': <tf.Tensor 'inputs/Venture:0' shape=(None, 1) dtype=string>, 'Innobiz': <tf.Tensor 'inputs/Innobiz:0' shape=(None, 1) dtype=string>, 'Mainbiz': <tf.Tensor 'inputs/Mainbiz:0' shape=(None, 1) dtype=string>, 'Employees': <tf.Tensor 'inputs/Employees:0' shape=(None, 1) dtype=float64>, 'Closed': <tf.Tensor 'inputs/Closed:0' shape=(None, 1) dtype=string>, 'Ten_Industry_1': <tf.Tensor 'inputs/Ten_Industry_1:0' shape=(None, 1) dtype=string>, 'Ten_Industry_11': <tf.Tensor 'inputs/Ten_Industry_11:0' shape=(None, 1) dtype=string>, 'Ten_Industry_111': <tf.Tensor 'inputs/Ten_Industry_111:0' shape=(None, 1) dtype=string>, 'Researcher': <tf.Tensor 'inputs/Researcher:0' shape=(None, 1) dtype=string>}\n","Consider rewriting this model with the Functional API.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Year': <tf.Tensor 'inputs/Year:0' shape=(None, 1) dtype=string>, 'N_of_SCI': <tf.Tensor 'inputs/N_of_SCI:0' shape=(None, 1) dtype=float64>, 'N_of_Paper': <tf.Tensor 'inputs/N_of_Paper:0' shape=(None, 1) dtype=float64>, 'N_Patent_App': <tf.Tensor 'inputs/N_Patent_App:0' shape=(None, 1) dtype=float64>, 'N_Patent_Reg': <tf.Tensor 'inputs/N_Patent_Reg:0' shape=(None, 1) dtype=float64>, 'N_of_Korean_Patent': <tf.Tensor 'inputs/N_of_Korean_Patent:0' shape=(None, 1) dtype=float64>, 'N_of_Inter_Patent': <tf.Tensor 'inputs/N_of_Inter_Patent:0' shape=(None, 1) dtype=float64>, 'N_of_Patent': <tf.Tensor 'inputs/N_of_Patent:0' shape=(None, 1) dtype=float64>, 'Multi_Year': <tf.Tensor 'inputs/Multi_Year:0' shape=(None, 1) dtype=string>, 'RnD_Org': <tf.Tensor 'inputs/RnD_Org:0' shape=(None, 1) dtype=string>, 'Region': <tf.Tensor 'inputs/Region:0' shape=(None, 1) dtype=string>, 'STP_Code_11': <tf.Tensor 'inputs/STP_Code_11:0' shape=(None, 1) dtype=string>, 'STP_Code_1_Weight': <tf.Tensor 'inputs/STP_Code_1_Weight:0' shape=(None, 1) dtype=float64>, 'STP_Code_21': <tf.Tensor 'inputs/STP_Code_21:0' shape=(None, 1) dtype=string>, 'STP_Code_2_Weight': <tf.Tensor 'inputs/STP_Code_2_Weight:0' shape=(None, 1) dtype=float64>, 'Application_Area_1': <tf.Tensor 'inputs/Application_Area_1:0' shape=(None, 1) dtype=string>, 'Application_Area_1_Weight': <tf.Tensor 'inputs/Application_Area_1_Weight:0' shape=(None, 1) dtype=float64>, 'Application_Area_2': <tf.Tensor 'inputs/Application_Area_2:0' shape=(None, 1) dtype=string>, 'Application_Area_2_Weight': <tf.Tensor 'inputs/Application_Area_2_Weight:0' shape=(None, 1) dtype=float64>, 'Application_Area_3': <tf.Tensor 'inputs/Application_Area_3:0' shape=(None, 1) dtype=string>, 'Application_Area_3_Weight': <tf.Tensor 'inputs/Application_Area_3_Weight:0' shape=(None, 1) dtype=float64>, 'Green_Tech': <tf.Tensor 'inputs/Green_Tech:0' shape=(None, 1) dtype=string>, 'SixT_2': <tf.Tensor 'inputs/SixT_2:0' shape=(None, 1) dtype=string>, 'Econ_Social': <tf.Tensor 'inputs/Econ_Social:0' shape=(None, 1) dtype=string>, 'National_Strategy_2': <tf.Tensor 'inputs/National_Strategy_2:0' shape=(None, 1) dtype=string>, 'RnD_Stage': <tf.Tensor 'inputs/RnD_Stage:0' shape=(None, 1) dtype=string>, 'Cowork_Cor': <tf.Tensor 'inputs/Cowork_Cor:0' shape=(None, 1) dtype=string>, 'Cowork_Uni': <tf.Tensor 'inputs/Cowork_Uni:0' shape=(None, 1) dtype=string>, 'Cowork_Inst': <tf.Tensor 'inputs/Cowork_Inst:0' shape=(None, 1) dtype=string>, 'Cowork_Abroad': <tf.Tensor 'inputs/Cowork_Abroad:0' shape=(None, 1) dtype=string>, 'Log_RnD_Fund': <tf.Tensor 'inputs/Log_RnD_Fund:0' shape=(None, 1) dtype=float64>, 'Log_Duration': <tf.Tensor 'inputs/Log_Duration:0' shape=(None, 1) dtype=float64>, 'Cowork_etc': <tf.Tensor 'inputs/Cowork_etc:0' shape=(None, 1) dtype=string>, 'Sales': <tf.Tensor 'inputs/Sales:0' shape=(None, 1) dtype=float64>, 'Income': <tf.Tensor 'inputs/Income:0' shape=(None, 1) dtype=float64>, 'Asset': <tf.Tensor 'inputs/Asset:0' shape=(None, 1) dtype=float64>, 'Capital': <tf.Tensor 'inputs/Capital:0' shape=(None, 1) dtype=float64>, 'Sales_Income_Ratio': <tf.Tensor 'inputs/Sales_Income_Ratio:0' shape=(None, 1) dtype=float64>, 'Asset_Income_Ratio': <tf.Tensor 'inputs/Asset_Income_Ratio:0' shape=(None, 1) dtype=float64>, 'Sales_Operation_Ratio': <tf.Tensor 'inputs/Sales_Operation_Ratio:0' shape=(None, 1) dtype=float64>, 'Expense_Ratio': <tf.Tensor 'inputs/Expense_Ratio:0' shape=(None, 1) dtype=float64>, 'Debt_Ratio': <tf.Tensor 'inputs/Debt_Ratio:0' shape=(None, 1) dtype=float64>, 'IPO': <tf.Tensor 'inputs/IPO:0' shape=(None, 1) dtype=string>, 'Comp_Type': <tf.Tensor 'inputs/Comp_Type:0' shape=(None, 1) dtype=string>, 'Listed_Market': <tf.Tensor 'inputs/Listed_Market:0' shape=(None, 1) dtype=string>, 'Administration': <tf.Tensor 'inputs/Administration:0' shape=(None, 1) dtype=string>, 'External_Audit': <tf.Tensor 'inputs/External_Audit:0' shape=(None, 1) dtype=string>, 'Survival': <tf.Tensor 'inputs/Survival:0' shape=(None, 1) dtype=string>, 'Venture': <tf.Tensor 'inputs/Venture:0' shape=(None, 1) dtype=string>, 'Innobiz': <tf.Tensor 'inputs/Innobiz:0' shape=(None, 1) dtype=string>, 'Mainbiz': <tf.Tensor 'inputs/Mainbiz:0' shape=(None, 1) dtype=string>, 'Employees': <tf.Tensor 'inputs/Employees:0' shape=(None, 1) dtype=float64>, 'Closed': <tf.Tensor 'inputs/Closed:0' shape=(None, 1) dtype=string>, 'Ten_Industry_1': <tf.Tensor 'inputs/Ten_Industry_1:0' shape=(None, 1) dtype=string>, 'Ten_Industry_11': <tf.Tensor 'inputs/Ten_Industry_11:0' shape=(None, 1) dtype=string>, 'Ten_Industry_111': <tf.Tensor 'inputs/Ten_Industry_111:0' shape=(None, 1) dtype=string>, 'Researcher': <tf.Tensor 'inputs/Researcher:0' shape=(None, 1) dtype=string>}\n","Consider rewriting this model with the Functional API.\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Year': <tf.Tensor 'inputs/Year:0' shape=(None, 1) dtype=string>, 'N_of_SCI': <tf.Tensor 'inputs/N_of_SCI:0' shape=(None, 1) dtype=float64>, 'N_of_Paper': <tf.Tensor 'inputs/N_of_Paper:0' shape=(None, 1) dtype=float64>, 'N_Patent_App': <tf.Tensor 'inputs/N_Patent_App:0' shape=(None, 1) dtype=float64>, 'N_Patent_Reg': <tf.Tensor 'inputs/N_Patent_Reg:0' shape=(None, 1) dtype=float64>, 'N_of_Korean_Patent': <tf.Tensor 'inputs/N_of_Korean_Patent:0' shape=(None, 1) dtype=float64>, 'N_of_Inter_Patent': <tf.Tensor 'inputs/N_of_Inter_Patent:0' shape=(None, 1) dtype=float64>, 'N_of_Patent': <tf.Tensor 'inputs/N_of_Patent:0' shape=(None, 1) dtype=float64>, 'Multi_Year': <tf.Tensor 'inputs/Multi_Year:0' shape=(None, 1) dtype=string>, 'RnD_Org': <tf.Tensor 'inputs/RnD_Org:0' shape=(None, 1) dtype=string>, 'Region': <tf.Tensor 'inputs/Region:0' shape=(None, 1) dtype=string>, 'STP_Code_11': <tf.Tensor 'inputs/STP_Code_11:0' shape=(None, 1) dtype=string>, 'STP_Code_1_Weight': <tf.Tensor 'inputs/STP_Code_1_Weight:0' shape=(None, 1) dtype=float64>, 'STP_Code_21': <tf.Tensor 'inputs/STP_Code_21:0' shape=(None, 1) dtype=string>, 'STP_Code_2_Weight': <tf.Tensor 'inputs/STP_Code_2_Weight:0' shape=(None, 1) dtype=float64>, 'Application_Area_1': <tf.Tensor 'inputs/Application_Area_1:0' shape=(None, 1) dtype=string>, 'Application_Area_1_Weight': <tf.Tensor 'inputs/Application_Area_1_Weight:0' shape=(None, 1) dtype=float64>, 'Application_Area_2': <tf.Tensor 'inputs/Application_Area_2:0' shape=(None, 1) dtype=string>, 'Application_Area_2_Weight': <tf.Tensor 'inputs/Application_Area_2_Weight:0' shape=(None, 1) dtype=float64>, 'Application_Area_3': <tf.Tensor 'inputs/Application_Area_3:0' shape=(None, 1) dtype=string>, 'Application_Area_3_Weight': <tf.Tensor 'inputs/Application_Area_3_Weight:0' shape=(None, 1) dtype=float64>, 'Green_Tech': <tf.Tensor 'inputs/Green_Tech:0' shape=(None, 1) dtype=string>, 'SixT_2': <tf.Tensor 'inputs/SixT_2:0' shape=(None, 1) dtype=string>, 'Econ_Social': <tf.Tensor 'inputs/Econ_Social:0' shape=(None, 1) dtype=string>, 'National_Strategy_2': <tf.Tensor 'inputs/National_Strategy_2:0' shape=(None, 1) dtype=string>, 'RnD_Stage': <tf.Tensor 'inputs/RnD_Stage:0' shape=(None, 1) dtype=string>, 'Cowork_Cor': <tf.Tensor 'inputs/Cowork_Cor:0' shape=(None, 1) dtype=string>, 'Cowork_Uni': <tf.Tensor 'inputs/Cowork_Uni:0' shape=(None, 1) dtype=string>, 'Cowork_Inst': <tf.Tensor 'inputs/Cowork_Inst:0' shape=(None, 1) dtype=string>, 'Cowork_Abroad': <tf.Tensor 'inputs/Cowork_Abroad:0' shape=(None, 1) dtype=string>, 'Log_RnD_Fund': <tf.Tensor 'inputs/Log_RnD_Fund:0' shape=(None, 1) dtype=float64>, 'Log_Duration': <tf.Tensor 'inputs/Log_Duration:0' shape=(None, 1) dtype=float64>, 'Cowork_etc': <tf.Tensor 'inputs/Cowork_etc:0' shape=(None, 1) dtype=string>, 'Sales': <tf.Tensor 'inputs/Sales:0' shape=(None, 1) dtype=float64>, 'Income': <tf.Tensor 'inputs/Income:0' shape=(None, 1) dtype=float64>, 'Asset': <tf.Tensor 'inputs/Asset:0' shape=(None, 1) dtype=float64>, 'Capital': <tf.Tensor 'inputs/Capital:0' shape=(None, 1) dtype=float64>, 'Sales_Income_Ratio': <tf.Tensor 'inputs/Sales_Income_Ratio:0' shape=(None, 1) dtype=float64>, 'Asset_Income_Ratio': <tf.Tensor 'inputs/Asset_Income_Ratio:0' shape=(None, 1) dtype=float64>, 'Sales_Operation_Ratio': <tf.Tensor 'inputs/Sales_Operation_Ratio:0' shape=(None, 1) dtype=float64>, 'Expense_Ratio': <tf.Tensor 'inputs/Expense_Ratio:0' shape=(None, 1) dtype=float64>, 'Debt_Ratio': <tf.Tensor 'inputs/Debt_Ratio:0' shape=(None, 1) dtype=float64>, 'IPO': <tf.Tensor 'inputs/IPO:0' shape=(None, 1) dtype=string>, 'Comp_Type': <tf.Tensor 'inputs/Comp_Type:0' shape=(None, 1) dtype=string>, 'Listed_Market': <tf.Tensor 'inputs/Listed_Market:0' shape=(None, 1) dtype=string>, 'Administration': <tf.Tensor 'inputs/Administration:0' shape=(None, 1) dtype=string>, 'External_Audit': <tf.Tensor 'inputs/External_Audit:0' shape=(None, 1) dtype=string>, 'Survival': <tf.Tensor 'inputs/Survival:0' shape=(None, 1) dtype=string>, 'Venture': <tf.Tensor 'inputs/Venture:0' shape=(None, 1) dtype=string>, 'Innobiz': <tf.Tensor 'inputs/Innobiz:0' shape=(None, 1) dtype=string>, 'Mainbiz': <tf.Tensor 'inputs/Mainbiz:0' shape=(None, 1) dtype=string>, 'Employees': <tf.Tensor 'inputs/Employees:0' shape=(None, 1) dtype=float64>, 'Closed': <tf.Tensor 'inputs/Closed:0' shape=(None, 1) dtype=string>, 'Ten_Industry_1': <tf.Tensor 'inputs/Ten_Industry_1:0' shape=(None, 1) dtype=string>, 'Ten_Industry_11': <tf.Tensor 'inputs/Ten_Industry_11:0' shape=(None, 1) dtype=string>, 'Ten_Industry_111': <tf.Tensor 'inputs/Ten_Industry_111:0' shape=(None, 1) dtype=string>, 'Researcher': <tf.Tensor 'inputs/Researcher:0' shape=(None, 1) dtype=string>}\n","Consider rewriting this model with the Functional API.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Year': <tf.Tensor 'inputs/Year:0' shape=(None, 1) dtype=string>, 'N_of_SCI': <tf.Tensor 'inputs/N_of_SCI:0' shape=(None, 1) dtype=float64>, 'N_of_Paper': <tf.Tensor 'inputs/N_of_Paper:0' shape=(None, 1) dtype=float64>, 'N_Patent_App': <tf.Tensor 'inputs/N_Patent_App:0' shape=(None, 1) dtype=float64>, 'N_Patent_Reg': <tf.Tensor 'inputs/N_Patent_Reg:0' shape=(None, 1) dtype=float64>, 'N_of_Korean_Patent': <tf.Tensor 'inputs/N_of_Korean_Patent:0' shape=(None, 1) dtype=float64>, 'N_of_Inter_Patent': <tf.Tensor 'inputs/N_of_Inter_Patent:0' shape=(None, 1) dtype=float64>, 'N_of_Patent': <tf.Tensor 'inputs/N_of_Patent:0' shape=(None, 1) dtype=float64>, 'Multi_Year': <tf.Tensor 'inputs/Multi_Year:0' shape=(None, 1) dtype=string>, 'RnD_Org': <tf.Tensor 'inputs/RnD_Org:0' shape=(None, 1) dtype=string>, 'Region': <tf.Tensor 'inputs/Region:0' shape=(None, 1) dtype=string>, 'STP_Code_11': <tf.Tensor 'inputs/STP_Code_11:0' shape=(None, 1) dtype=string>, 'STP_Code_1_Weight': <tf.Tensor 'inputs/STP_Code_1_Weight:0' shape=(None, 1) dtype=float64>, 'STP_Code_21': <tf.Tensor 'inputs/STP_Code_21:0' shape=(None, 1) dtype=string>, 'STP_Code_2_Weight': <tf.Tensor 'inputs/STP_Code_2_Weight:0' shape=(None, 1) dtype=float64>, 'Application_Area_1': <tf.Tensor 'inputs/Application_Area_1:0' shape=(None, 1) dtype=string>, 'Application_Area_1_Weight': <tf.Tensor 'inputs/Application_Area_1_Weight:0' shape=(None, 1) dtype=float64>, 'Application_Area_2': <tf.Tensor 'inputs/Application_Area_2:0' shape=(None, 1) dtype=string>, 'Application_Area_2_Weight': <tf.Tensor 'inputs/Application_Area_2_Weight:0' shape=(None, 1) dtype=float64>, 'Application_Area_3': <tf.Tensor 'inputs/Application_Area_3:0' shape=(None, 1) dtype=string>, 'Application_Area_3_Weight': <tf.Tensor 'inputs/Application_Area_3_Weight:0' shape=(None, 1) dtype=float64>, 'Green_Tech': <tf.Tensor 'inputs/Green_Tech:0' shape=(None, 1) dtype=string>, 'SixT_2': <tf.Tensor 'inputs/SixT_2:0' shape=(None, 1) dtype=string>, 'Econ_Social': <tf.Tensor 'inputs/Econ_Social:0' shape=(None, 1) dtype=string>, 'National_Strategy_2': <tf.Tensor 'inputs/National_Strategy_2:0' shape=(None, 1) dtype=string>, 'RnD_Stage': <tf.Tensor 'inputs/RnD_Stage:0' shape=(None, 1) dtype=string>, 'Cowork_Cor': <tf.Tensor 'inputs/Cowork_Cor:0' shape=(None, 1) dtype=string>, 'Cowork_Uni': <tf.Tensor 'inputs/Cowork_Uni:0' shape=(None, 1) dtype=string>, 'Cowork_Inst': <tf.Tensor 'inputs/Cowork_Inst:0' shape=(None, 1) dtype=string>, 'Cowork_Abroad': <tf.Tensor 'inputs/Cowork_Abroad:0' shape=(None, 1) dtype=string>, 'Log_RnD_Fund': <tf.Tensor 'inputs/Log_RnD_Fund:0' shape=(None, 1) dtype=float64>, 'Log_Duration': <tf.Tensor 'inputs/Log_Duration:0' shape=(None, 1) dtype=float64>, 'Cowork_etc': <tf.Tensor 'inputs/Cowork_etc:0' shape=(None, 1) dtype=string>, 'Sales': <tf.Tensor 'inputs/Sales:0' shape=(None, 1) dtype=float64>, 'Income': <tf.Tensor 'inputs/Income:0' shape=(None, 1) dtype=float64>, 'Asset': <tf.Tensor 'inputs/Asset:0' shape=(None, 1) dtype=float64>, 'Capital': <tf.Tensor 'inputs/Capital:0' shape=(None, 1) dtype=float64>, 'Sales_Income_Ratio': <tf.Tensor 'inputs/Sales_Income_Ratio:0' shape=(None, 1) dtype=float64>, 'Asset_Income_Ratio': <tf.Tensor 'inputs/Asset_Income_Ratio:0' shape=(None, 1) dtype=float64>, 'Sales_Operation_Ratio': <tf.Tensor 'inputs/Sales_Operation_Ratio:0' shape=(None, 1) dtype=float64>, 'Expense_Ratio': <tf.Tensor 'inputs/Expense_Ratio:0' shape=(None, 1) dtype=float64>, 'Debt_Ratio': <tf.Tensor 'inputs/Debt_Ratio:0' shape=(None, 1) dtype=float64>, 'IPO': <tf.Tensor 'inputs/IPO:0' shape=(None, 1) dtype=string>, 'Comp_Type': <tf.Tensor 'inputs/Comp_Type:0' shape=(None, 1) dtype=string>, 'Listed_Market': <tf.Tensor 'inputs/Listed_Market:0' shape=(None, 1) dtype=string>, 'Administration': <tf.Tensor 'inputs/Administration:0' shape=(None, 1) dtype=string>, 'External_Audit': <tf.Tensor 'inputs/External_Audit:0' shape=(None, 1) dtype=string>, 'Survival': <tf.Tensor 'inputs/Survival:0' shape=(None, 1) dtype=string>, 'Venture': <tf.Tensor 'inputs/Venture:0' shape=(None, 1) dtype=string>, 'Innobiz': <tf.Tensor 'inputs/Innobiz:0' shape=(None, 1) dtype=string>, 'Mainbiz': <tf.Tensor 'inputs/Mainbiz:0' shape=(None, 1) dtype=string>, 'Employees': <tf.Tensor 'inputs/Employees:0' shape=(None, 1) dtype=float64>, 'Closed': <tf.Tensor 'inputs/Closed:0' shape=(None, 1) dtype=string>, 'Ten_Industry_1': <tf.Tensor 'inputs/Ten_Industry_1:0' shape=(None, 1) dtype=string>, 'Ten_Industry_11': <tf.Tensor 'inputs/Ten_Industry_11:0' shape=(None, 1) dtype=string>, 'Ten_Industry_111': <tf.Tensor 'inputs/Ten_Industry_111:0' shape=(None, 1) dtype=string>, 'Researcher': <tf.Tensor 'inputs/Researcher:0' shape=(None, 1) dtype=string>}\n","Consider rewriting this model with the Functional API.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: /gdrive/MyDrive/Colab Notebooks/DNN/최종본/모델저장/기업_최종/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: /gdrive/MyDrive/Colab Notebooks/DNN/최종본/모델저장/기업_최종/assets\n"]}]},{"cell_type":"code","metadata":{"id":"0HMQTOkBSdGl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634283482116,"user_tz":-540,"elapsed":11,"user":{"displayName":"현준","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06235385304799063880"}},"outputId":"a92f7bd1-cd1f-4323-a11e-1fcb3602a1d1"},"source":["y_pred = pd.DataFrame(y_pred)\n","y_true = pd.DataFrame(y_true)\n","\n","y_true.columns = ['Comm_Success', 'Comm_Success_Code1_4', 'Comm_Success_Code2_5','Comm_Success_Code3_6']\n","y_pred.columns = ['predict', 'predict1_4', 'predict2_5','predict3_6']\n","\n","\n","df_result = pd.concat([y_true, y_pred], axis=1)\n","\n","from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n","\n","\n","\n","labels1 = df_result['Comm_Success']\t# 실제 labels\n","guesses1 = df_result['predict']\t# 에측된 결과\n","\n","\n","labels4 = df_result['Comm_Success_Code1_4']\t# 실제 labels\n","guesses4 = df_result['predict1_4']\t# 에측된 결과\n","\n","labels5 = df_result['Comm_Success_Code2_5']\t# 실제 labels\n","guesses5 = df_result['predict2_5']\t# 에측된 결과\n","\n","labels6 = df_result['Comm_Success_Code3_6']\t# 실제 labels\n","guesses6 = df_result['predict3_6']\t# 에측된 결과\n","\n","print('------------------------Comm_Success-----------------')\n","print('정확도', accuracy_score(labels1, guesses1))\t\n","print('recall',recall_score(labels1, guesses1))\t\n","print('precision',precision_score(labels1, guesses1))\n","print('f1', f1_score(labels1, guesses1))\n","print('예측_실제 순')\n","print('True_True', len(df_result[(df_result.predict == 1) & (df_result.Comm_Success == 1)]))\n","print('True_Falses', len(df_result[(df_result.predict == 1) & (df_result.Comm_Success == 0)]))\n","print('False_True', len(df_result[(df_result.predict == 0) & (df_result.Comm_Success == 1)]))\n","print('False_False', len(df_result[(df_result.predict == 0) & (df_result.Comm_Success == 0)]))\n","\n","print('')\n","print('')\n","print('')\n","\n","\n","print('------------------------Comm_Success_Code1_4-----------------')\n","print('정확도', accuracy_score(labels4, guesses4))\t\n","print('recall',recall_score(labels4, guesses4))\t\n","print('precision',precision_score(labels4, guesses4))\n","print('f1', f1_score(labels4, guesses4))\n","print('예측_실제 순')\n","print('True_True', len(df_result[(df_result.predict1_4 == 1) & (df_result.Comm_Success_Code1_4 == 1)]))\n","print('True_Falses', len(df_result[(df_result.predict1_4 == 1) & (df_result.Comm_Success_Code1_4 == 0)]))\n","print('False_True', len(df_result[(df_result.predict1_4 == 0) & (df_result.Comm_Success_Code1_4 == 1)]))\n","print('False_False', len(df_result[(df_result.predict1_4 == 0) & (df_result.Comm_Success_Code1_4 == 0)]))\n","\n","print('')\n","print('')\n","print('')\n","\n","print('---------------Comm_Success_Code2_5--------------------')\n","print('정확도', accuracy_score(labels5, guesses5))\t\n","print('recall',recall_score(labels5, guesses5))\t\n","print('precision',precision_score(labels5, guesses5))\n","print('f1', f1_score(labels5, guesses5))\n","print('예측_실제 순')\n","print('True_True', len(df_result[(df_result.predict2_5 == 1) & (df_result.Comm_Success_Code2_5 == 1)]))\n","print('True_Falses', len(df_result[(df_result.predict2_5 == 1) & (df_result.Comm_Success_Code2_5 == 0)]))\n","print('False_True', len(df_result[(df_result.predict2_5 == 0) & (df_result.Comm_Success_Code2_5 == 1)]))\n","print('False_False', len(df_result[(df_result.predict2_5 == 0) & (df_result.Comm_Success_Code2_5 == 0)]))\n","\n","\n","print('')\n","print('')\n","print('')\n","\n","print('-----------------------Comm_Success_Code3_6-------------------------')\n","print('정확도', accuracy_score(labels6, guesses6))\t\n","print('recall',recall_score(labels6, guesses6))\t\n","print('precision',precision_score(labels6, guesses6))\n","print('f1', f1_score(labels6, guesses6))\n","print('예측_실제 순')\n","print('True_True', len(df_result[(df_result.predict3_6 == 1) & (df_result.Comm_Success_Code3_6 == 1)]))\n","print('True_Falses', len(df_result[(df_result.predict3_6 == 1) & (df_result.Comm_Success_Code3_6 == 0)]))\n","print('False_True', len(df_result[(df_result.predict3_6 == 0) & (df_result.Comm_Success_Code3_6 == 1)]))\n","print('False_False', len(df_result[(df_result.predict3_6 == 0) & (df_result.Comm_Success_Code3_6 == 0)]))"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["------------------------Comm_Success-----------------\n","정확도 0.8399714780482835\n","recall 0.8467904723455794\n","precision 0.8378270421410026\n","f1 0.8422849111534986\n","예측_실제 순\n","True_True 4195\n","True_Falses 812\n","False_True 759\n","False_False 4051\n","\n","\n","\n","------------------------Comm_Success_Code1_4-----------------\n","정확도 0.8658449628195987\n","recall 0.40483383685800606\n","precision 0.10685805422647528\n","f1 0.16908517350157728\n","예측_실제 순\n","True_True 134\n","True_Falses 1120\n","False_True 197\n","False_False 8366\n","\n","\n","\n","---------------Comm_Success_Code2_5--------------------\n","정확도 0.7553223999185087\n","recall 0.7342842049656629\n","precision 0.6657088122605364\n","f1 0.6983170057774427\n","예측_실제 순\n","True_True 2780\n","True_Falses 1396\n","False_True 1006\n","False_False 4635\n","\n","\n","\n","-----------------------Comm_Success_Code3_6-------------------------\n","정확도 0.82998879494754\n","recall 0.5615292712066906\n","precision 0.2652370203160271\n","f1 0.36029129934840937\n","예측_실제 순\n","True_True 470\n","True_Falses 1302\n","False_True 367\n","False_False 7678\n"]}]}]}